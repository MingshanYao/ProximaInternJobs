{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# definite data generator from liver box (overlap cube) with weighted dice loss \n",
    "\n",
    "\n",
    "# choose one specific GPU\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data/AlgProj/liuzhsh/deeplearning/')\n",
    "from gpu_allocation import set_gpu\n",
    "\n",
    "num_gpu = 1\n",
    "set_gpu(num_gpu, gpu_list = [0,1,2,3,4,5,6,7])\n",
    "\n",
    "\n",
    "# import libs and initialization\n",
    "\n",
    "from keras.layers import Input, merge, Conv3D, MaxPooling3D, UpSampling3D, Dropout, BatchNormalization, Activation\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import SimpleITK as sitk\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "image_rows = 64\n",
    "image_cols = 64\n",
    "image_deps = 64\n",
    "\n",
    "image_vmin = 0.\n",
    "image_vmax = 400.\n",
    "\n",
    "\n",
    "# define loss funtion\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1e-3):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.-dice_coef(y_true, y_pred)\n",
    "\n",
    "def focal_loss_v1(y_true, y_pred, gamma=2.0, alpha=0.25):\n",
    "    # Define epsilon so that the backpropagation will not result in NaN\n",
    "    # for 0 divisor case\n",
    "    epsilon = K.epsilon()\n",
    "    # Add the epsilon to prediction value\n",
    "    #y_pred = y_pred + epsilon\n",
    "    # Clip the prediciton value\n",
    "    y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "    # Calculate p_t\n",
    "    p_t = tf.where(K.equal(y_true, 1), y_pred, 1-y_pred)\n",
    "    # Calculate alpha_t\n",
    "    alpha_factor = K.ones_like(y_true)*alpha\n",
    "    alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1-alpha_factor)\n",
    "    # Calculate cross entropy\n",
    "    cross_entropy = -K.log(p_t)\n",
    "    weight = alpha_t * K.pow((1-p_t), gamma)\n",
    "    # Calculate focal loss\n",
    "    loss = weight * cross_entropy\n",
    "    # Sum the losses in mini_batch\n",
    "    loss = K.sum(loss, axis=1)\n",
    "    return loss\n",
    "\n",
    "def focal_loss_v2(y_true, y_pred):    \n",
    "    gamma=0.75    \n",
    "    alpha=0.25    \n",
    "    \n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))    \n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))  \n",
    "    \n",
    "    pt_1 = K.clip(pt_1, 1e-3, .999)    \n",
    "    pt_0 = K.clip(pt_0, 1e-3, .999)     \n",
    "    \n",
    "    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "#  build elegant unet3d model\n",
    "\n",
    "def unet3d(input_shape, lr=1e-5, depth=5, n_base_filters=32, pool_size=(2, 2, 2), batch_normalization=True):\n",
    "    inputs = Input(input_shape)\n",
    "    current_layer = inputs\n",
    "    levels = list()\n",
    "\n",
    "    for layer_depth in range(depth):\n",
    "        layer1 = conv_block(input_layer=current_layer, n_filters=n_base_filters*(2**layer_depth),\n",
    "                            batch_normalization=batch_normalization)\n",
    "        layer2 = conv_block(input_layer=layer1, n_filters=n_base_filters*(2**layer_depth),\n",
    "                            batch_normalization=batch_normalization)\n",
    "        if layer_depth < depth-1:\n",
    "            current_layer = MaxPooling3D(pool_size=pool_size)(layer2)\n",
    "            levels.append([layer1, layer2, current_layer])\n",
    "        else:\n",
    "            current_layer = layer2\n",
    "            levels.append([layer1, layer2])\n",
    "\n",
    "    for layer_depth in range(depth-2, -1, -1):\n",
    "        up_layer = up_conv(input_layer=current_layer, n_filters=levels[layer_depth][1]._keras_shape[-1], pool_size=pool_size)\n",
    "        concat = concatenate([up_layer, levels[layer_depth][1]], axis=-1)\n",
    "        current_layer = conv_block(input_layer=concat, n_filters=levels[layer_depth][1]._keras_shape[-1],\n",
    "                                   batch_normalization=batch_normalization)\n",
    "        current_layer = conv_block(input_layer=current_layer, n_filters=levels[layer_depth][1]._keras_shape[-1],\n",
    "                                   batch_normalization=batch_normalization)\n",
    "\n",
    "    final_layer = Conv3D(1, 1, activation='sigmoid')(current_layer)\n",
    "    model = Model(inputs=inputs, outputs=final_layer)\n",
    "    model.compile(optimizer=Adam(lr=lr), loss=focal_loss_v1, metrics=[dice_coef])\n",
    "    return model\n",
    "\n",
    "def conv_block(input_layer, n_filters, batch_normalization=True, kernel=3, padding='same', strides=(1, 1, 1)):\n",
    "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(input_layer)\n",
    "    if batch_normalization:\n",
    "        layer = BatchNormalization(axis=-1)(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "def up_conv(input_layer, n_filters, pool_size=(2, 2, 2), batch_normalization=True, kernel=2, padding='same', strides=(1, 1, 1)):\n",
    "    layer = UpSampling3D(size=pool_size)(input_layer)\n",
    "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(layer)\n",
    "    if batch_normalization:\n",
    "        layer = BatchNormalization(axis=-1)(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    return layer\n",
    "\n",
    "\n",
    "# create data generator to yeild definite batch\n",
    "\n",
    "def data_generator(batch_size, image_path_list, mask_path_list, is_train):\n",
    "\n",
    "    # image_path_list, mask_path_list: path list of cubic image and mask (npy)\n",
    "\n",
    "    while True:\n",
    "        image_group = []\n",
    "        mask_group = []\n",
    "        data_list = np.arange(len(image_path_list))\n",
    "\n",
    "        if is_train:\n",
    "            np.random.shuffle(data_list)\n",
    "\n",
    "        for data_i, data_list_i in enumerate(data_list):\n",
    "            image = np.load(image_path_list[data_list_i])\n",
    "            mask = np.load(mask_path_list[data_list_i])\n",
    "\n",
    "            image = (image-image_vmin)/(image_vmax-image_vmin)\n",
    "            image[image>1] = 1\n",
    "            image[image<0] = 0\n",
    "\n",
    "            image_group.append(image)\n",
    "            mask_group.append(mask)\n",
    "\n",
    "            if (data_i+1) % batch_size == 0:\n",
    "                image_generated = np.ndarray([batch_size, image_deps, image_rows, image_cols, 1], dtype=np.float32)\n",
    "                mask_generated = np.ndarray([batch_size, image_deps, image_rows, image_cols, 1], dtype=np.float32)\n",
    "\n",
    "                for cube_i in range(batch_size):\n",
    "                    image_generated[cube_i, :, :, :, 0] = image_group[cube_i]\n",
    "                    mask_generated[cube_i, :, :, :, 0] = mask_group[cube_i]\n",
    "\n",
    "                yield image_generated, mask_generated\n",
    "\n",
    "                image_group = []\n",
    "                mask_group = []\n",
    "\n",
    "\n",
    "# train model\n",
    "\n",
    "def main():\n",
    "\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument('-l', '--lr', required=True, type=float, default=1e-5, help='learning rate')\n",
    "    ap.add_argument('-e', '--epochs', required=True, type=int, default=100, help='epochs')\n",
    "    ap.add_argument('-b', '--batchsize', required=True, type=int, default=4, help='batch size')\n",
    "    ap.add_argument('-s', '--study', required=True, type=int, default=0, help='study number')\n",
    "    args = vars(ap.parse_args())\n",
    "\n",
    "    lr = args['lr']\n",
    "    epochs = args['epochs']\n",
    "    batch_size = args['batchsize']\n",
    "    study = args['study']\n",
    "\n",
    "    print('unet3d_v10 study:%d, lr:%s, epochs:%d, batchsize:%d' % (study, lr, epochs, batch_size))\n",
    "\n",
    "    input_shape = (image_rows, image_cols, image_deps, 1)\n",
    "\n",
    "    model = unet3d(input_shape, lr, depth=5, n_base_filters=32, pool_size=(2, 2, 2), batch_normalization=True)\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint('/data/AlgProj/guxl/model_unet3d/unet3d_study%d_lr%s_epochs%d_batchsize%d_v10.hdf5' % (study, lr, epochs, batch_size),\n",
    "                                       monitor='val_loss',verbose=1, save_best_only=True)\n",
    "\n",
    "    image_train_path_list = np.load('/data/AlgProj/guxl/3Dircadb1_test/cubic_data_path_list_overlap/image_train_path_list.npy')\n",
    "    mask_train_path_list = np.load('/data/AlgProj/guxl/3Dircadb1_test/cubic_data_path_list_overlap/mask_train_path_list.npy')\n",
    "\n",
    "    image_val_path_list = np.load('/data/AlgProj/guxl/3Dircadb1_test/cubic_data_path_list_overlap/image_val_path_list.npy')\n",
    "    mask_val_path_list = np.load('/data/AlgProj/guxl/3Dircadb1_test/cubic_data_path_list_overlap/mask_val_path_list.npy')\n",
    "\n",
    "    train_steps = len(image_train_path_list)/batch_size\n",
    "    val_steps = len(image_val_path_list)/batch_size\n",
    "\n",
    "    train_generator = data_generator(batch_size=batch_size,\n",
    "                                     image_path_list=image_train_path_list,\n",
    "                                     mask_path_list=mask_train_path_list,\n",
    "                                     is_train=True)\n",
    "\n",
    "    val_generator = data_generator(batch_size=batch_size,\n",
    "                                   image_path_list=image_val_path_list,\n",
    "                                   mask_path_list=mask_val_path_list,\n",
    "                                   is_train=False)\n",
    "\n",
    "    H = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=train_steps,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            callbacks=[model_checkpoint],\n",
    "                            validation_data=val_generator,\n",
    "                            validation_steps=val_steps)\n",
    "\n",
    "    with open('history_unet3d_study%d_lr%s_epochs%d_batchsize%d.json' % (study, lr, epochs, batch_size), 'w')  as f:\n",
    "        json.dump(H.history, f)\n",
    "\n",
    "    print('unet3d_v10 study:%d, lr:%s, epochs:%d, batchsize:%d' % (study, lr, epochs, batch_size))\n",
    "\n",
    "\n",
    "# execute main function\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
