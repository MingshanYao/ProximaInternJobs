{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = r'../PapSmearData/smear2005/New database pictures'\n",
    "# dirs = os.listdir(train_dir)\n",
    "# os.mkdir(r'../PapSmearData/smear2005/test')\n",
    "# test_path = r'../PapSmearData/smear2005/test'\n",
    "\n",
    "# for d in dirs:\n",
    "#     os.mkdir(test_path +'/' + d)\n",
    "#     files = os.listdir(train_dir + '/' + d)\n",
    "#     idxes = np.arange(len(files))\n",
    "#     test_idx = random.choice(idx, int(len(files)*0.2), replace=False)\n",
    "#     for idx in test_idx:\n",
    "        \n",
    "#         a_path = train_dir + '/' + d + '/' + f\n",
    "#         b_path = test_path +'/' + d\n",
    "#         shutil.move(a_path, b_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                 transforms.RandomRotation((-180, 180)),\n",
    "                                 transforms.ToTensor()]\n",
    "                                )\n",
    "def default_loader(path):\n",
    "    img = Image.open(path).convert('RGB')\n",
    "#     print(type(img))\n",
    "#     img = np.transpose(img, (2,0,1))\n",
    "    return img\n",
    "mydataset = ImageFolder(img_dir, transform = transformer, loader = default_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = mydataset, batch_size=32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "CLASSES = 7\n",
    "LR = 0.0001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "model = resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "fc_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(fc_features, 7)\n",
    "\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=LR, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    print(device)\n",
    "    model.train()\n",
    "    for e in range(1, epoch+1):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print ('Train Epoch: {}\\t Loss: {:.6f}\\n'.format(e,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Train Epoch: 1\t Loss: 2.038768\n",
      "\n",
      "Train Epoch: 2\t Loss: 1.791988\n",
      "\n",
      "Train Epoch: 3\t Loss: 1.889584\n",
      "\n",
      "Train Epoch: 4\t Loss: 1.743307\n",
      "\n",
      "Train Epoch: 5\t Loss: 1.623642\n",
      "\n",
      "Train Epoch: 6\t Loss: 1.869009\n",
      "\n",
      "Train Epoch: 7\t Loss: 1.629328\n",
      "\n",
      "Train Epoch: 8\t Loss: 1.559858\n",
      "\n",
      "Train Epoch: 9\t Loss: 1.651184\n",
      "\n",
      "Train Epoch: 10\t Loss: 1.506958\n",
      "\n",
      "Train Epoch: 11\t Loss: 1.710099\n",
      "\n",
      "Train Epoch: 12\t Loss: 1.574031\n",
      "\n",
      "Train Epoch: 13\t Loss: 1.589331\n",
      "\n",
      "Train Epoch: 14\t Loss: 1.289456\n",
      "\n",
      "Train Epoch: 15\t Loss: 1.571893\n",
      "\n",
      "Train Epoch: 16\t Loss: 1.434971\n",
      "\n",
      "Train Epoch: 17\t Loss: 1.301118\n",
      "\n",
      "Train Epoch: 18\t Loss: 1.433402\n",
      "\n",
      "Train Epoch: 19\t Loss: 1.625088\n",
      "\n",
      "Train Epoch: 20\t Loss: 1.463424\n",
      "\n",
      "Train Epoch: 21\t Loss: 1.256392\n",
      "\n",
      "Train Epoch: 22\t Loss: 1.763113\n",
      "\n",
      "Train Epoch: 23\t Loss: 1.274398\n",
      "\n",
      "Train Epoch: 24\t Loss: 1.338274\n",
      "\n",
      "Train Epoch: 25\t Loss: 1.353962\n",
      "\n",
      "Train Epoch: 26\t Loss: 1.515621\n",
      "\n",
      "Train Epoch: 27\t Loss: 1.458176\n",
      "\n",
      "Train Epoch: 28\t Loss: 1.369100\n",
      "\n",
      "Train Epoch: 29\t Loss: 1.158111\n",
      "\n",
      "Train Epoch: 30\t Loss: 1.372669\n",
      "\n",
      "Train Epoch: 31\t Loss: 1.225918\n",
      "\n",
      "Train Epoch: 32\t Loss: 1.289256\n",
      "\n",
      "Train Epoch: 33\t Loss: 1.190460\n",
      "\n",
      "Train Epoch: 34\t Loss: 1.364156\n",
      "\n",
      "Train Epoch: 35\t Loss: 1.105271\n",
      "\n",
      "Train Epoch: 36\t Loss: 1.508134\n",
      "\n",
      "Train Epoch: 37\t Loss: 1.132079\n",
      "\n",
      "Train Epoch: 38\t Loss: 1.357361\n",
      "\n",
      "Train Epoch: 39\t Loss: 1.459631\n",
      "\n",
      "Train Epoch: 40\t Loss: 1.260036\n",
      "\n",
      "Train Epoch: 41\t Loss: 1.198797\n",
      "\n",
      "Train Epoch: 42\t Loss: 1.153247\n",
      "\n",
      "Train Epoch: 43\t Loss: 1.357931\n",
      "\n",
      "Train Epoch: 44\t Loss: 1.314184\n",
      "\n",
      "Train Epoch: 45\t Loss: 1.051349\n",
      "\n",
      "Train Epoch: 46\t Loss: 1.204938\n",
      "\n",
      "Train Epoch: 47\t Loss: 1.134146\n",
      "\n",
      "Train Epoch: 48\t Loss: 1.314344\n",
      "\n",
      "Train Epoch: 49\t Loss: 1.282923\n",
      "\n",
      "Train Epoch: 50\t Loss: 1.205577\n",
      "\n",
      "Train Epoch: 51\t Loss: 1.252697\n",
      "\n",
      "Train Epoch: 52\t Loss: 1.464702\n",
      "\n",
      "Train Epoch: 53\t Loss: 1.156578\n",
      "\n",
      "Train Epoch: 54\t Loss: 1.212820\n",
      "\n",
      "Train Epoch: 55\t Loss: 1.319133\n",
      "\n",
      "Train Epoch: 56\t Loss: 1.095450\n",
      "\n",
      "Train Epoch: 57\t Loss: 1.123289\n",
      "\n",
      "Train Epoch: 58\t Loss: 1.212329\n",
      "\n",
      "Train Epoch: 59\t Loss: 1.302500\n",
      "\n",
      "Train Epoch: 60\t Loss: 1.071457\n",
      "\n",
      "Train Epoch: 61\t Loss: 1.198347\n",
      "\n",
      "Train Epoch: 62\t Loss: 1.344611\n",
      "\n",
      "Train Epoch: 63\t Loss: 0.952889\n",
      "\n",
      "Train Epoch: 64\t Loss: 1.109145\n",
      "\n",
      "Train Epoch: 65\t Loss: 1.077197\n",
      "\n",
      "Train Epoch: 66\t Loss: 0.949572\n",
      "\n",
      "Train Epoch: 67\t Loss: 1.346529\n",
      "\n",
      "Train Epoch: 68\t Loss: 1.219290\n",
      "\n",
      "Train Epoch: 69\t Loss: 1.109365\n",
      "\n",
      "Train Epoch: 70\t Loss: 1.452417\n",
      "\n",
      "Train Epoch: 71\t Loss: 1.134714\n",
      "\n",
      "Train Epoch: 72\t Loss: 0.926683\n",
      "\n",
      "Train Epoch: 73\t Loss: 1.307796\n",
      "\n",
      "Train Epoch: 74\t Loss: 1.044597\n",
      "\n",
      "Train Epoch: 75\t Loss: 1.112937\n",
      "\n",
      "Train Epoch: 76\t Loss: 1.395517\n",
      "\n",
      "Train Epoch: 77\t Loss: 1.178204\n",
      "\n",
      "Train Epoch: 78\t Loss: 1.313134\n",
      "\n",
      "Train Epoch: 79\t Loss: 1.233672\n",
      "\n",
      "Train Epoch: 80\t Loss: 1.154560\n",
      "\n",
      "Train Epoch: 81\t Loss: 1.370724\n",
      "\n",
      "Train Epoch: 82\t Loss: 1.338465\n",
      "\n",
      "Train Epoch: 83\t Loss: 1.046902\n",
      "\n",
      "Train Epoch: 84\t Loss: 1.152498\n",
      "\n",
      "Train Epoch: 85\t Loss: 1.151202\n",
      "\n",
      "Train Epoch: 86\t Loss: 1.095083\n",
      "\n",
      "Train Epoch: 87\t Loss: 1.217309\n",
      "\n",
      "Train Epoch: 88\t Loss: 0.963606\n",
      "\n",
      "Train Epoch: 89\t Loss: 1.296718\n",
      "\n",
      "Train Epoch: 90\t Loss: 1.161657\n",
      "\n",
      "Train Epoch: 91\t Loss: 1.340530\n",
      "\n",
      "Train Epoch: 92\t Loss: 0.985633\n",
      "\n",
      "Train Epoch: 93\t Loss: 1.139498\n",
      "\n",
      "Train Epoch: 94\t Loss: 0.921266\n",
      "\n",
      "Train Epoch: 95\t Loss: 1.141496\n",
      "\n",
      "Train Epoch: 96\t Loss: 1.200651\n",
      "\n",
      "Train Epoch: 97\t Loss: 1.097151\n",
      "\n",
      "Train Epoch: 98\t Loss: 1.063142\n",
      "\n",
      "Train Epoch: 99\t Loss: 1.120581\n",
      "\n",
      "Train Epoch: 100\t Loss: 1.164485\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, DEVICE, train_loader, optimizer, EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.ipynb_checkpoints': 0,\n",
       " 'carcinoma_in_situ': 1,\n",
       " 'light_dysplastic': 2,\n",
       " 'moderate_dysplastic': 3,\n",
       " 'normal_columnar': 4,\n",
       " 'normal_intermediate': 5,\n",
       " 'normal_superficiel': 6,\n",
       " 'severe_dysplastic': 7}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
