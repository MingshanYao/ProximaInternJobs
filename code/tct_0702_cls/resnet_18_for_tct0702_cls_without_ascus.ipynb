{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Found 8 GPU(s) only 6 gpu below threshold\n",
      "Using GPU 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "sys.path.append(\"/home/shiyi/gpu/\")\n",
    "\n",
    "from gpu_allocation import set_gpu\n",
    "num_gpu = 1\n",
    "set_gpu(num_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters \n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 128\n",
    "CLASSES = 8\n",
    "EPOCH = 10\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3457"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir and path\n",
    "\n",
    "csv_path = '/data/AlgProj/tct_yaoms/data/tct_0702_preprocess_iou0.1_img_series/iou0.1dataaumentation.csv'\n",
    "csv = pd.read_csv(csv_path)\n",
    "csv = csv.loc[csv['label']!=1].reset_index(drop=True)\n",
    "len(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test dataset split\n",
    "#train val transforms definition\n",
    "\n",
    "def train_test_split(df, test_size, shuffle=True):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "    #split\n",
    "    length = len(df)\n",
    "    threspoint = int((1 - test_size)*length)\n",
    "    train_df = df.loc[:threspoint-1,:]\n",
    "    test_df = df.loc[threspoint:,:]\n",
    "    \n",
    "    d = {}\n",
    "    d['train'] = train_df\n",
    "    d['test'] = test_df.reset_index(drop=True)\n",
    "    return d\n",
    "\n",
    "train_transformer = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                 transforms.RandomRotation((-180, 180)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomResizedCrop((224,224)),  \n",
    "                                 transforms.ToTensor(),\n",
    "                                       transforms.Normalize(IMG_MEAN,IMG_STD)]\n",
    "                                )\n",
    "test_transformer = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                  transforms.CenterCrop((224,224)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                      transforms.Normalize(IMG_MEAN,IMG_STD)])\n",
    "train_test_transformer = {'train':train_transformer, 'test':test_transformer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "692"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_dict = train_test_split(csv, 0.2)\n",
    "len(train_test_dict['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCT_Dataset(Dataset):\n",
    "    def __init__(self, phase, transforms=True):\n",
    "        self.phase = phase\n",
    "        self.transforms = transforms\n",
    "        if phase == 'train':\n",
    "            self.df = train_test_dict['train']\n",
    "        else:\n",
    "            self.df = train_test_dict['test']\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path = self.df.loc[idx, 'img_path']\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        \n",
    "        if self.transforms:\n",
    "            if self.phase == 'train':\n",
    "                transformer = train_test_transformer['train']\n",
    "            else:\n",
    "                transformer = train_test_transformer['test']\n",
    "\n",
    "            img = transformer(img)\n",
    "        \n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TCT_Dataset('train')\n",
    "test_dataset = TCT_Dataset('test')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18\n",
    "model = resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "fc_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(fc_features, CLASSES)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([{'params':model.fc.parameters(), 'lr':0.004},\n",
    "                      {'params':model.layer4.parameters(), 'lr':0.001}])\n",
    "#                        {'params':model.layer4.parameters(),'lr':0.00001}\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Train Epoch: {}\\t Loss: {:.6f}\\n'.format(epoch,loss.item()))\n",
    "\n",
    "    \n",
    "def test(model, device, test_loader, optimizer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "#     pred_result = []\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):          \n",
    "            x,y= data\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            test_loss = criterion(y_hat, y).item() # sum up batch loss\n",
    "            pred = y_hat.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            \n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "    acc = 100. * correct / len(train_test_dict['test'])\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(train_test_dict['test']),\n",
    "        acc))\n",
    "    \n",
    "#     print('-----------------------')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\t Loss: 0.424450\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4064, Accuracy: 579/692 (84%)\n",
      "\n",
      "current best acc:  83.67052023121387\n",
      "-----------------------\n",
      "Train Epoch: 1\t Loss: 0.366303\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4202, Accuracy: 584/692 (84%)\n",
      "\n",
      "current best acc:  84.39306358381504\n",
      "-----------------------\n",
      "Train Epoch: 2\t Loss: 0.451552\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2491, Accuracy: 582/692 (84%)\n",
      "\n",
      "current best acc:  84.39306358381504\n",
      "-----------------------\n",
      "Train Epoch: 3\t Loss: 0.346555\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2896, Accuracy: 581/692 (84%)\n",
      "\n",
      "current best acc:  84.39306358381504\n",
      "-----------------------\n",
      "Train Epoch: 4\t Loss: 0.339532\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3629, Accuracy: 580/692 (84%)\n",
      "\n",
      "current best acc:  84.39306358381504\n",
      "-----------------------\n",
      "Train Epoch: 5\t Loss: 0.303298\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3134, Accuracy: 580/692 (84%)\n",
      "\n",
      "current best acc:  84.39306358381504\n",
      "-----------------------\n",
      "Train Epoch: 6\t Loss: 0.303017\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2757, Accuracy: 584/692 (84%)\n",
      "\n",
      "current best acc:  84.39306358381504\n",
      "-----------------------\n",
      "Train Epoch: 7\t Loss: 0.304043\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3122, Accuracy: 584/692 (84%)\n",
      "\n",
      "current best acc:  84.39306358381504\n",
      "-----------------------\n",
      "Train Epoch: 8\t Loss: 0.365797\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3060, Accuracy: 575/692 (83%)\n",
      "\n",
      "current best acc:  84.39306358381504\n",
      "-----------------------\n",
      "Train Epoch: 9\t Loss: 0.426614\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3550, Accuracy: 577/692 (83%)\n",
      "\n",
      "current best acc:  84.39306358381504\n",
      "-----------------------\n",
      "Result: at 7 epoch, achieved best acc: 84\n"
     ]
    }
   ],
   "source": [
    "max_acc = 0\n",
    "max_epoch = 0\n",
    "save_path = '/data/AlgProj/tct_yaoms/model/resnet-18_exclude_ascus_0716.pth'\n",
    "for epoch in range(EPOCH):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    acc = test(model, DEVICE, test_loader, optimizer)\n",
    "    if acc >= max_acc:\n",
    "        max_acc = acc\n",
    "        max_epoch = epoch\n",
    "        if os.path.exists(save_path):\n",
    "            os.remove(save_path)\n",
    "        torch.save(model, save_path)\n",
    "    print('current best acc: ', max_acc)\n",
    "    print('-----------------------')\n",
    "print('Result: at {} epoch, achieved best acc: {:.0f}'.format(max_epoch, max_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>label</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303152_1.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302246_1.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3481aaf5ac7642699d3151ebdb8c8520_59_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/3481aaf5ac764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304823_36.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285806_0.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    img_name  label  \\\n",
       "0                               303152_1.jpg      3   \n",
       "1                               302246_1.jpg      3   \n",
       "2  3481aaf5ac7642699d3151ebdb8c8520_59_0.jpg      0   \n",
       "3                              304823_36.jpg      6   \n",
       "4                               285806_0.jpg      2   \n",
       "\n",
       "                                            img_path  \n",
       "0  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "1  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "2  /data/AlgProj/tct_yaoms/data/neg/3481aaf5ac764...  \n",
       "3  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "4  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DataLoader in module torch.utils.data.dataloader object:\n",
      "\n",
      "class DataLoader(builtins.object)\n",
      " |  Data loader. Combines a dataset and a sampler, and provides\n",
      " |  single- or multi-process iterators over the dataset.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      dataset (Dataset): dataset from which to load the data.\n",
      " |      batch_size (int, optional): how many samples per batch to load\n",
      " |          (default: ``1``).\n",
      " |      shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      " |          at every epoch (default: ``False``).\n",
      " |      sampler (Sampler, optional): defines the strategy to draw samples from\n",
      " |          the dataset. If specified, ``shuffle`` must be False.\n",
      " |      batch_sampler (Sampler, optional): like sampler, but returns a batch of\n",
      " |          indices at a time. Mutually exclusive with :attr:`batch_size`,\n",
      " |          :attr:`shuffle`, :attr:`sampler`, and :attr:`drop_last`.\n",
      " |      num_workers (int, optional): how many subprocesses to use for data\n",
      " |          loading. 0 means that the data will be loaded in the main process.\n",
      " |          (default: ``0``)\n",
      " |      collate_fn (callable, optional): merges a list of samples to form a mini-batch.\n",
      " |      pin_memory (bool, optional): If ``True``, the data loader will copy tensors\n",
      " |          into CUDA pinned memory before returning them.  If your data elements\n",
      " |          are a custom type, or your ``collate_fn`` returns a batch that is a custom type\n",
      " |          see the example below.\n",
      " |      drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      " |          if the dataset size is not divisible by the batch size. If ``False`` and\n",
      " |          the size of dataset is not divisible by the batch size, then the last batch\n",
      " |          will be smaller. (default: ``False``)\n",
      " |      timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      " |          from workers. Should always be non-negative. (default: ``0``)\n",
      " |      worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
      " |          worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      " |          input, after seeding and before data loading. (default: ``None``)\n",
      " |  \n",
      " |  .. note:: When ``num_workers != 0``, the corresponding worker processes are created each time\n",
      " |            iterator for the DataLoader is obtained (as in when you call\n",
      " |            ``enumerate(dataloader,0)``).\n",
      " |            At this point, the dataset, ``collate_fn`` and ``worker_init_fn`` are passed to each\n",
      " |            worker, where they are used to access and initialize data based on the indices\n",
      " |            queued up from the main process. This means that dataset access together with\n",
      " |            its internal IO, transforms and collation runs in the worker, while any\n",
      " |            shuffle randomization is done in the main process which guides loading by assigning\n",
      " |            indices to load. Workers are shut down once the end of the iteration is reached.\n",
      " |  \n",
      " |            Since workers rely on Python multiprocessing, worker launch behavior is different\n",
      " |            on Windows compared to Unix. On Unix fork() is used as the default\n",
      " |            muliprocessing start method, so child workers typically can access the dataset and\n",
      " |            Python argument functions directly through the cloned address space. On Windows, another\n",
      " |            interpreter is launched which runs your main script, followed by the internal\n",
      " |            worker function that receives the dataset, collate_fn and other arguments\n",
      " |            through Pickle serialization.\n",
      " |  \n",
      " |            This separate serialization means that you should take two steps to ensure you\n",
      " |            are compatible with Windows while using workers\n",
      " |            (this also works equally well on Unix):\n",
      " |  \n",
      " |            - Wrap most of you main script's code within ``if __name__ == '__main__':`` block,\n",
      " |              to make sure it doesn't run again (most likely generating error) when each worker\n",
      " |              process is launched. You can place your dataset and DataLoader instance creation\n",
      " |              logic here, as it doesn't need to be re-executed in workers.\n",
      " |            - Make sure that ``collate_fn``, ``worker_init_fn`` or any custom dataset code\n",
      " |              is declared as a top level def, outside of that ``__main__`` check. This ensures\n",
      " |              they are available in workers as well\n",
      " |              (this is needed since functions are pickled as references only, not bytecode).\n",
      " |  \n",
      " |            By default, each worker will have its PyTorch seed set to\n",
      " |            ``base_seed + worker_id``, where ``base_seed`` is a long generated\n",
      " |            by main process using its RNG. However, seeds for other libraies\n",
      " |            may be duplicated upon initializing workers (w.g., NumPy), causing\n",
      " |            each worker to return identical random numbers. (See\n",
      " |            :ref:`dataloader-workers-random-seed` section in FAQ.) You may\n",
      " |            use :func:`torch.initial_seed()` to access the PyTorch seed for\n",
      " |            each worker in :attr:`worker_init_fn`, and use it to set other\n",
      " |            seeds before data loading.\n",
      " |  \n",
      " |  .. warning:: If ``spawn`` start method is used, :attr:`worker_init_fn` cannot be an\n",
      " |               unpicklable object, e.g., a lambda function.\n",
      " |  \n",
      " |  The default memory pinning logic only recognizes Tensors and maps and iterables\n",
      " |  containg Tensors.  By default, if the pinning logic sees a batch that is a custom type\n",
      " |  (which will occur if you have a ``collate_fn`` that returns a custom batch type),\n",
      " |  or if each element of your batch is a custom type, the pinning logic will not\n",
      " |  recognize them, and it will return that batch (or those elements)\n",
      " |  without pinning the memory.  To enable memory pinning for custom batch or data types,\n",
      " |  define a ``pin_memory`` method on your custom type(s).\n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      class SimpleCustomBatch:\n",
      " |          def __init__(self, data):\n",
      " |              transposed_data = list(zip(*data))\n",
      " |              self.inp = torch.stack(transposed_data[0], 0)\n",
      " |              self.tgt = torch.stack(transposed_data[1], 0)\n",
      " |  \n",
      " |          def pin_memory(self):\n",
      " |              self.inp = self.inp.pin_memory()\n",
      " |              self.tgt = self.tgt.pin_memory()\n",
      " |              return self\n",
      " |  \n",
      " |      def collate_wrapper(batch):\n",
      " |          return SimpleCustomBatch(batch)\n",
      " |  \n",
      " |      inps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
      " |      tgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\n",
      " |      dataset = TensorDataset(inps, tgts)\n",
      " |  \n",
      " |      loader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,\n",
      " |                          pin_memory=True)\n",
      " |  \n",
      " |      for batch_ndx, sample in enumerate(loader):\n",
      " |          print(sample.inp.is_pinned())\n",
      " |          print(sample.tgt.is_pinned())\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=<function default_collate at 0x7fa9c5ce1b70>, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __len__(self)\n",
      " |  \n",
      " |  __setattr__(self, attr, val)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred =[]\n",
    "y_true = []\n",
    "for i,data in enumerate(test_loader):\n",
    "    x, y = data\n",
    "    y = np.array(y.cpu())\n",
    "    y_true.append(y)\n",
    "    \n",
    "    x = x.to(DEVICE)\n",
    "    y_hat = model(x)\n",
    "    pred = y_hat.max(1, keepdim=True)[1]\n",
    "    pred = np.array(pred.cpu())\n",
    "    y_pred.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 2]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_list\n",
    "# y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "for i in range(len(y_pred)):\n",
    "    y_pred_list += list(y_pred[i].ravel())\n",
    "for i in range(len(y_true)):\n",
    "    y_true_list += list(y_true[i].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     ax.figure.colorbar(im, ax=ax)\n",
    "#     # We want to show all ticks...\n",
    "#     ax.set(xticks=np.arange(cm.shape[1]),\n",
    "#            yticks=np.arange(cm.shape[0]),\n",
    "#            # ... and label them with the respective list entries\n",
    "#            xticklabels=classes, yticklabels=classes,\n",
    "#            title=title,\n",
    "#            ylabel='True label',\n",
    "#            xlabel='Predicted label')\n",
    "\n",
    "#     # Rotate the tick labels and set their alignment.\n",
    "#     plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "#              rotation_mode=\"anchor\")\n",
    "\n",
    "#     # Loop over data dimensions and create text annotations.\n",
    "#     fmt = '.2f' if normalize else 'd'\n",
    "#     thresh = cm.max() / 2.\n",
    "#     for i in range(cm.shape[0]):\n",
    "#         for j in range(cm.shape[1]):\n",
    "#             ax.text(j, i, format(cm[i, j], fmt),\n",
    "#                     ha=\"center\", va=\"center\",\n",
    "#                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "#     fig.tight_layout()\n",
    "#     return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[246   0   2   0   0   0]\n",
      " [  0  81   9  11   3   0]\n",
      " [  0   7  68   1   6   0]\n",
      " [  0  61   1  25   5   0]\n",
      " [  1   0   2   2  76   1]\n",
      " [  0   1   0   0   2  81]]\n"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(y_true_list, y_pred_list, classes=np.array(['0','1','2', '3', '4', '5', '6', '7']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def show_mis_cls_picture(y_true, y_pred, test_dataset, cls, mis_cls):\n",
    "    mis_list = []\n",
    "    right_list = []\n",
    "    correct_img_path =[]\n",
    "    mis_cls_img_path = []\n",
    "    \n",
    "    for idx, y in enumerate(zip(y_true, y_pred)):\n",
    "        i, j = y\n",
    "        if (i == j) and (j == cls):\n",
    "            right_list.append(idx)\n",
    "        if (i == cls) and (j == mis_cls):\n",
    "            mis_list.append(idx)\n",
    "    \n",
    "    df = test_dataset.df\n",
    "#     figure1, ax1 = plt.subplots(2,5)\n",
    "#     plt.title('cls correct')\n",
    "    for i in range(10):\n",
    "        idx = right_list[i]\n",
    "        img_path = df.loc[idx, 'img_path']\n",
    "        correct_img_path.append(img_path)\n",
    "#         img = Image.open(img_path)\n",
    "#         img.show()\n",
    "#         ax1[i].imshow(img)\n",
    "#     plt.show()\n",
    "    print('-----------------')\n",
    "    \n",
    "    choice = random.sample(mis_list, 20)\n",
    "#     figure2, ax2 = plt.subplots(4,5)\n",
    "#     plt.title('mis cls')\n",
    "    for i in range(20):\n",
    "        idx = choice[i]\n",
    "        img_path = df.loc[idx, 'img_path']\n",
    "        mis_cls_img_path.append(img_path)\n",
    "#         img = Image.open(img_path)\n",
    "#         img.show()\n",
    "#         ax2[i].imshow(img)\n",
    "#     plt.show()\n",
    "    return correct_img_path, mis_cls_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>label</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303152_1.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302246_1.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3481aaf5ac7642699d3151ebdb8c8520_59_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/3481aaf5ac764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>304823_36.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>285806_0.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>c51d01dbe09b45ca868f18d10f15e8a0_226_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/c51d01dbe09b4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>286454_2.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>302231_32.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>304918_0.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>305325_0.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300723_2.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>291624_2.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>291739_0.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>302287_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>291574_2.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>302016_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ac5db318a1f44b0f81f86ab1cca544d2_16_5.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/ac5db318a1f44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>305545_2.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>302637_79.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b363a210e7c04c11930b1badfaebf951_291_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/b363a210e7c04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4ca5258925e8471294d607a6aedea040_5_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/4ca5258925e84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>283174_1.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0ae67986288646ddb15b7b85c7e5cd5b_513_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/0ae6798628864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3481aaf5ac7642699d3151ebdb8c8520_43_2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/3481aaf5ac764...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bc3dc5e2ff894545b0a7ec2b330b1fca_220_7.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/bc3dc5e2ff894...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>300785_0.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>299642_92.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>305490_72.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>299642_13.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>299642_85.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>283270_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>291394_88.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>f5f30d7a2f4a40c0a694b30a6693b6bc_80_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/f5f30d7a2f4a4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>305572_2.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>281749_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>305490_98.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>07bcf318373c4579bf749a7377ac025d_347_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/07bcf318373c4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>302287_1.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0b559ea57e4142588161f60368c801b9_120_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/0b559ea57e414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>302810_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>4ca5258925e8471294d607a6aedea040_289_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/4ca5258925e84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>bd535ced6c384b99b9af961e082fd703_104_8.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/bd535ced6c384...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>b4151a4e95fb4c18adbcb5de19e08e30_436_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/b4151a4e95fb4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>286156_2.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>290451_2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>290493_2.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>302639_7.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>0ae67986288646ddb15b7b85c7e5cd5b_91_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/0ae6798628864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>305490_58.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>a35fa6fff505407e82c20a4b15d22b5c_17_0.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/a35fa6fff5054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>291394_4.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>302637_63.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>303881_2.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>291394_2.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>06829c3658de41c2b792b08d39c4453c_508_2.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/06829c3658de4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>291896_0.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>302648_0.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>3886a6625aaa43b38bbeb429c44e7640_82_1.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/neg/3886a6625aaa4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>299642_66.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>305452_1.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0702_preproce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       img_name  label  \\\n",
       "0                                  303152_1.jpg      3   \n",
       "1                                  302246_1.jpg      3   \n",
       "2     3481aaf5ac7642699d3151ebdb8c8520_59_0.jpg      0   \n",
       "3                                 304823_36.jpg      6   \n",
       "4                                  285806_0.jpg      2   \n",
       "5    c51d01dbe09b45ca868f18d10f15e8a0_226_0.jpg      0   \n",
       "6                                  286454_2.jpg      4   \n",
       "7                                 302231_32.jpg      6   \n",
       "8                                  304918_0.jpg      2   \n",
       "9                                  305325_0.jpg      4   \n",
       "10                                 300723_2.jpg      3   \n",
       "11                                 291624_2.jpg      3   \n",
       "12                                 291739_0.jpg      2   \n",
       "13                                 302287_2.jpg      2   \n",
       "14                                 291574_2.jpg      4   \n",
       "15                                 302016_2.jpg      2   \n",
       "16    ac5db318a1f44b0f81f86ab1cca544d2_16_5.jpg      0   \n",
       "17                                 305545_2.jpg      3   \n",
       "18                                302637_79.jpg      7   \n",
       "19   b363a210e7c04c11930b1badfaebf951_291_1.jpg      0   \n",
       "20     4ca5258925e8471294d607a6aedea040_5_0.jpg      0   \n",
       "21                                 283174_1.jpg      3   \n",
       "22   0ae67986288646ddb15b7b85c7e5cd5b_513_0.jpg      0   \n",
       "23    3481aaf5ac7642699d3151ebdb8c8520_43_2.jpg      0   \n",
       "24   bc3dc5e2ff894545b0a7ec2b330b1fca_220_7.jpg      0   \n",
       "25                                 300785_0.jpg      4   \n",
       "26                                299642_92.jpg      7   \n",
       "27                                305490_72.jpg      7   \n",
       "28                                299642_13.jpg      7   \n",
       "29                                299642_85.jpg      7   \n",
       "..                                          ...    ...   \n",
       "662                                283270_2.jpg      2   \n",
       "663                               291394_88.jpg      7   \n",
       "664   f5f30d7a2f4a40c0a694b30a6693b6bc_80_0.jpg      0   \n",
       "665                                305572_2.jpg      4   \n",
       "666                                281749_2.jpg      2   \n",
       "667                               305490_98.jpg      7   \n",
       "668  07bcf318373c4579bf749a7377ac025d_347_1.jpg      0   \n",
       "669                                302287_1.jpg      2   \n",
       "670  0b559ea57e4142588161f60368c801b9_120_1.jpg      0   \n",
       "671                                302810_2.jpg      2   \n",
       "672  4ca5258925e8471294d607a6aedea040_289_0.jpg      0   \n",
       "673  bd535ced6c384b99b9af961e082fd703_104_8.jpg      0   \n",
       "674  b4151a4e95fb4c18adbcb5de19e08e30_436_0.jpg      0   \n",
       "675                                286156_2.jpg      4   \n",
       "676                                290451_2.jpg      2   \n",
       "677                                290493_2.jpg      4   \n",
       "678                                302639_7.jpg      6   \n",
       "679   0ae67986288646ddb15b7b85c7e5cd5b_91_0.jpg      0   \n",
       "680                               305490_58.jpg      7   \n",
       "681   a35fa6fff505407e82c20a4b15d22b5c_17_0.jpg      0   \n",
       "682                                291394_4.jpg      7   \n",
       "683                               302637_63.jpg      7   \n",
       "684                                303881_2.jpg      4   \n",
       "685                                291394_2.jpg      7   \n",
       "686  06829c3658de41c2b792b08d39c4453c_508_2.jpg      0   \n",
       "687                                291896_0.jpg      6   \n",
       "688                                302648_0.jpg      4   \n",
       "689   3886a6625aaa43b38bbeb429c44e7640_82_1.jpg      0   \n",
       "690                               299642_66.jpg      7   \n",
       "691                                305452_1.jpg      4   \n",
       "\n",
       "                                              img_path  \n",
       "0    /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "1    /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "2    /data/AlgProj/tct_yaoms/data/neg/3481aaf5ac764...  \n",
       "3    /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "4    /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "5    /data/AlgProj/tct_yaoms/data/neg/c51d01dbe09b4...  \n",
       "6    /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "7    /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "8    /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "9    /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "10   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "11   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "12   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "13   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "14   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "15   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "16   /data/AlgProj/tct_yaoms/data/neg/ac5db318a1f44...  \n",
       "17   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "18   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "19   /data/AlgProj/tct_yaoms/data/neg/b363a210e7c04...  \n",
       "20   /data/AlgProj/tct_yaoms/data/neg/4ca5258925e84...  \n",
       "21   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "22   /data/AlgProj/tct_yaoms/data/neg/0ae6798628864...  \n",
       "23   /data/AlgProj/tct_yaoms/data/neg/3481aaf5ac764...  \n",
       "24   /data/AlgProj/tct_yaoms/data/neg/bc3dc5e2ff894...  \n",
       "25   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "26   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "27   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "28   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "29   /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "..                                                 ...  \n",
       "662  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "663  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "664  /data/AlgProj/tct_yaoms/data/neg/f5f30d7a2f4a4...  \n",
       "665  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "666  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "667  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "668  /data/AlgProj/tct_yaoms/data/neg/07bcf318373c4...  \n",
       "669  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "670  /data/AlgProj/tct_yaoms/data/neg/0b559ea57e414...  \n",
       "671  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "672  /data/AlgProj/tct_yaoms/data/neg/4ca5258925e84...  \n",
       "673  /data/AlgProj/tct_yaoms/data/neg/bd535ced6c384...  \n",
       "674  /data/AlgProj/tct_yaoms/data/neg/b4151a4e95fb4...  \n",
       "675  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "676  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "677  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "678  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "679  /data/AlgProj/tct_yaoms/data/neg/0ae6798628864...  \n",
       "680  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "681  /data/AlgProj/tct_yaoms/data/neg/a35fa6fff5054...  \n",
       "682  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "683  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "684  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "685  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "686  /data/AlgProj/tct_yaoms/data/neg/06829c3658de4...  \n",
       "687  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "688  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "689  /data/AlgProj/tct_yaoms/data/neg/3886a6625aaa4...  \n",
       "690  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "691  /data/AlgProj/tct_yaoms/data/tct_0702_preproce...  \n",
       "\n",
       "[692 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "path1, path2 = show_mis_cls_picture(y_true_list, y_pred_list, test_dataset, 4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = path1 + path2\n",
    "df = pd.DataFrame()\n",
    "df['img_path'] = path\n",
    "df.loc[:9, 'cls'] = 1\n",
    "df.loc[10:, 'cls'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/data/AlgProj/tct_yaoms/model/resnet18_0716_error_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
