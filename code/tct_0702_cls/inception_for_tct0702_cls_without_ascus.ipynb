{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 GPU(s) only 4 gpu below threshold\n",
      "Using GPU 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0,2'\n",
    "sys.path.append(\"/home/shiyi/gpu/\")\n",
    "\n",
    "from gpu_allocation import set_gpu\n",
    "num_gpu = 1\n",
    "set_gpu(num_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters \n",
    "\n",
    "IMG_SIZE = 299\n",
    "BATCH_SIZE = 128\n",
    "CLASSES = 8\n",
    "EPOCH = 200\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3457"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir and path\n",
    "\n",
    "csv_path = '/data/AlgProj/tct_yaoms/data/tct_0702_preprocess_iou0.1_img_series/iou0.1dataaumentation.csv'\n",
    "csv = pd.read_csv(csv_path)\n",
    "csv = csv.loc[csv['label']!=1].reset_index(drop=True)\n",
    "len(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train val transforms definition\n",
    "\n",
    "def train_test_split(df, test_size, shuffle=True):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "    #split\n",
    "    length = len(df)\n",
    "    threspoint = int((1 - test_size)*length)\n",
    "    train_df = df.loc[:threspoint-1,:]\n",
    "    test_df = df.loc[threspoint:,:]\n",
    "    \n",
    "    d = {}\n",
    "    d['train'] = train_df\n",
    "    d['test'] = test_df.reset_index(drop=True)\n",
    "    return d\n",
    "\n",
    "train_transformer = transforms.Compose([transforms.Resize((336,336)),\n",
    "                                 transforms.RandomRotation((-180, 180)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomResizedCrop((299,299)),  \n",
    "                                 transforms.ToTensor(),\n",
    "                                       transforms.Normalize(IMG_MEAN,IMG_STD)]\n",
    "                                )\n",
    "test_transformer = transforms.Compose([transforms.Resize((336,336)),\n",
    "                                  transforms.CenterCrop((299,299)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                      transforms.Normalize(IMG_MEAN,IMG_STD)])\n",
    "train_test_transformer = {'train':train_transformer, 'test':test_transformer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "692"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_dict = train_test_split(csv, 0.2)\n",
    "len(train_test_dict['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCT_Dataset(Dataset):\n",
    "    def __init__(self, phase, transforms=True):\n",
    "        self.phase = phase\n",
    "        self.transforms = transforms\n",
    "        if phase == 'train':\n",
    "            self.df = train_test_dict['train']\n",
    "        else:\n",
    "            self.df = train_test_dict['test']\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path = self.df.loc[idx, 'img_path']\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        \n",
    "        if self.transforms:\n",
    "            if self.phase == 'train':\n",
    "                transformer = train_test_transformer['train']\n",
    "            else:\n",
    "                transformer = train_test_transformer['test']\n",
    "\n",
    "            img = transformer(img)\n",
    "        \n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TCT_Dataset('train')\n",
    "test_dataset = TCT_Dataset('test')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2048, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import inception_v3\n",
    "model = inception_v3(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "fc_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(fc_features, CLASSES)\n",
    "model.aux_logits=False\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([{'params':model.fc.parameters(), 'lr':0.004},\n",
    "                      {'params':model.Mixed_7c.parameters(), 'lr':0.001}])\n",
    "#                        {'params':model.layer4.parameters(),'lr':0.00001}\n",
    "criterion =  nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         output = torch.tensor(output)\n",
    "        output = output.to(device)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Train Epoch: {}\\t Loss: {:.6f}\\n'.format(epoch,loss.item()))\n",
    "\n",
    "    \n",
    "def test(model, device, test_loader, optimizer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):          \n",
    "            x,y= data\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            test_loss = criterion(y_hat, y).item() # sum up batch loss\n",
    "            pred = y_hat.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "    acc = 100. * correct / len(train_test_dict['test'])\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(train_test_dict['test']),\n",
    "        acc))\n",
    "    \n",
    "#     print('-----------------------')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\t Loss: 0.552790\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6428, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  80.78034682080924\n",
      "-----------------------\n",
      "Train Epoch: 1\t Loss: 0.558916\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4483, Accuracy: 550/692 (79%)\n",
      "\n",
      "current best acc:  80.78034682080924\n",
      "-----------------------\n",
      "Train Epoch: 2\t Loss: 0.506376\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4809, Accuracy: 553/692 (80%)\n",
      "\n",
      "current best acc:  80.78034682080924\n",
      "-----------------------\n",
      "Train Epoch: 3\t Loss: 0.537170\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5734, Accuracy: 554/692 (80%)\n",
      "\n",
      "current best acc:  80.78034682080924\n",
      "-----------------------\n",
      "Train Epoch: 4\t Loss: 0.638581\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6833, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  80.78034682080924\n",
      "-----------------------\n",
      "Train Epoch: 5\t Loss: 0.584914\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4998, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  80.78034682080924\n",
      "-----------------------\n",
      "Train Epoch: 6\t Loss: 0.546624\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5078, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  80.78034682080924\n",
      "-----------------------\n",
      "Train Epoch: 7\t Loss: 0.489346\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4076, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  80.92485549132948\n",
      "-----------------------\n",
      "Train Epoch: 8\t Loss: 0.618579\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6358, Accuracy: 551/692 (80%)\n",
      "\n",
      "current best acc:  80.92485549132948\n",
      "-----------------------\n",
      "Train Epoch: 9\t Loss: 0.519191\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4650, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  80.92485549132948\n",
      "-----------------------\n",
      "Train Epoch: 10\t Loss: 0.678052\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5391, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.0693641618497\n",
      "-----------------------\n",
      "Train Epoch: 11\t Loss: 0.613006\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5094, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.0693641618497\n",
      "-----------------------\n",
      "Train Epoch: 12\t Loss: 0.771377\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4838, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 13\t Loss: 0.650738\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3575, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 14\t Loss: 0.735438\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4447, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 15\t Loss: 0.629634\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5206, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 16\t Loss: 0.639734\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3940, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 17\t Loss: 0.630331\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4361, Accuracy: 550/692 (79%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 18\t Loss: 0.521977\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5259, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 19\t Loss: 0.521578\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4640, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 20\t Loss: 0.543570\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3800, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 21\t Loss: 0.474643\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5429, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 22\t Loss: 0.683970\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3722, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 23\t Loss: 0.893873\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6440, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 24\t Loss: 0.664645\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4949, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 25\t Loss: 0.598981\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4781, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 26\t Loss: 0.616716\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4867, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 27\t Loss: 0.600226\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4586, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 28\t Loss: 0.543634\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6376, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 29\t Loss: 0.708406\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4486, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 30\t Loss: 0.435274\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4242, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 31\t Loss: 0.573128\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4575, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 32\t Loss: 0.682413\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5728, Accuracy: 553/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 33\t Loss: 0.666229\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6729, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 34\t Loss: 0.507719\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4670, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 35\t Loss: 0.632871\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3982, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 36\t Loss: 0.491916\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4422, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 37\t Loss: 0.533935\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5376, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 38\t Loss: 0.592444\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4315, Accuracy: 554/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 39\t Loss: 0.563459\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2926, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 40\t Loss: 0.649433\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3575, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 41\t Loss: 0.569201\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7183, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 42\t Loss: 0.582412\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4378, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 43\t Loss: 0.567813\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4265, Accuracy: 554/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 44\t Loss: 0.795867\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5415, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 45\t Loss: 0.569173\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6626, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 46\t Loss: 0.584921\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4984, Accuracy: 553/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 47\t Loss: 0.447757\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5536, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 48\t Loss: 0.594041\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4197, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 49\t Loss: 0.515828\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5029, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 50\t Loss: 0.693590\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3414, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 51\t Loss: 0.637196\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5949, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 52\t Loss: 0.715447\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4485, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 53\t Loss: 0.469074\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5176, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 54\t Loss: 0.584177\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5064, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 55\t Loss: 0.485601\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4809, Accuracy: 562/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 56\t Loss: 0.644733\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5071, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 57\t Loss: 0.628785\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4574, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 58\t Loss: 0.581467\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4702, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 59\t Loss: 0.577271\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4352, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 60\t Loss: 0.634538\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4878, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 61\t Loss: 0.666748\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3746, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 62\t Loss: 0.569370\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4933, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 63\t Loss: 0.557919\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4982, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 64\t Loss: 0.729691\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5911, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 65\t Loss: 0.573847\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4516, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 66\t Loss: 0.599202\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5101, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 67\t Loss: 0.561989\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4544, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 68\t Loss: 0.665661\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5134, Accuracy: 562/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 69\t Loss: 0.503987\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5667, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 70\t Loss: 0.596746\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5185, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 71\t Loss: 0.482135\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5332, Accuracy: 553/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 72\t Loss: 0.607241\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5241, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 73\t Loss: 0.772669\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3568, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 74\t Loss: 0.444300\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3495, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 75\t Loss: 0.528577\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4653, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 76\t Loss: 0.423909\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5819, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 77\t Loss: 0.450012\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4672, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 78\t Loss: 0.738672\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6002, Accuracy: 553/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 79\t Loss: 0.508302\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5508, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 80\t Loss: 0.689365\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4619, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 81\t Loss: 0.542131\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4411, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 82\t Loss: 0.816994\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3765, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 83\t Loss: 0.834495\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5524, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 84\t Loss: 0.609723\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4538, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 85\t Loss: 0.749168\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3877, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 86\t Loss: 0.493444\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4372, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 87\t Loss: 0.528936\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4825, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 88\t Loss: 0.554852\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4300, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 89\t Loss: 0.514615\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6091, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 90\t Loss: 0.576548\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4043, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 91\t Loss: 0.611373\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4597, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 92\t Loss: 0.584264\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4156, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 93\t Loss: 0.699344\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5741, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 94\t Loss: 0.443544\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6377, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 95\t Loss: 0.615237\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4468, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 96\t Loss: 0.529641\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5594, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 97\t Loss: 0.568881\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5647, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 98\t Loss: 0.468609\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3587, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 99\t Loss: 0.595859\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4844, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 100\t Loss: 0.693625\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3582, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 101\t Loss: 0.601004\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6288, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 102\t Loss: 0.692089\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3192, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 103\t Loss: 0.616438\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4237, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 104\t Loss: 0.469019\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3299, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 105\t Loss: 0.499530\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4091, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 106\t Loss: 0.638127\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5115, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 107\t Loss: 0.584840\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5674, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 108\t Loss: 0.679663\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4088, Accuracy: 554/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 109\t Loss: 0.688416\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5108, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 110\t Loss: 0.423965\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5223, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 111\t Loss: 0.659401\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5539, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 112\t Loss: 0.538301\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5253, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 113\t Loss: 0.457414\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5163, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 114\t Loss: 0.724541\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4851, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 115\t Loss: 0.564133\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3188, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 116\t Loss: 0.671158\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5467, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 117\t Loss: 0.772371\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4609, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 118\t Loss: 0.710538\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5843, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 119\t Loss: 0.522064\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4433, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 120\t Loss: 0.537156\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3691, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 121\t Loss: 0.611961\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3603, Accuracy: 554/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 122\t Loss: 0.410671\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6718, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 123\t Loss: 0.639206\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4550, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 124\t Loss: 0.802432\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3816, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.35838150289017\n",
      "-----------------------\n",
      "Train Epoch: 125\t Loss: 0.641750\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6755, Accuracy: 564/692 (82%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 126\t Loss: 0.550925\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4982, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 127\t Loss: 0.628946\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4452, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 128\t Loss: 0.499100\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5240, Accuracy: 553/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 129\t Loss: 0.548582\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5371, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 130\t Loss: 0.681193\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5711, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 131\t Loss: 0.630632\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4051, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 132\t Loss: 0.536106\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4237, Accuracy: 564/692 (82%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 133\t Loss: 0.552096\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5071, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 134\t Loss: 0.518952\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5590, Accuracy: 562/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 135\t Loss: 0.509115\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4735, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 136\t Loss: 0.569418\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3834, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 137\t Loss: 0.560106\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4034, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 138\t Loss: 0.738361\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4827, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 139\t Loss: 0.625420\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4137, Accuracy: 564/692 (82%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 140\t Loss: 0.625488\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4484, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 141\t Loss: 0.729768\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3778, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 142\t Loss: 0.852572\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4881, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 143\t Loss: 0.580692\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4407, Accuracy: 562/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 144\t Loss: 0.686569\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4020, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 145\t Loss: 0.576435\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5816, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 146\t Loss: 0.501654\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4768, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 147\t Loss: 0.553170\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4088, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 148\t Loss: 0.507951\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4325, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 149\t Loss: 0.708230\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5293, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 150\t Loss: 0.585320\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5229, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 151\t Loss: 0.504382\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5192, Accuracy: 552/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 152\t Loss: 0.581970\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4593, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 153\t Loss: 0.458253\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4445, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 154\t Loss: 0.670090\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6998, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 155\t Loss: 0.539810\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4015, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 156\t Loss: 0.613109\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5265, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 157\t Loss: 0.585468\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5046, Accuracy: 562/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 158\t Loss: 0.659142\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5361, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 159\t Loss: 0.576696\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5731, Accuracy: 562/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 160\t Loss: 0.460991\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3836, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 161\t Loss: 0.705311\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3907, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 162\t Loss: 0.455403\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4116, Accuracy: 562/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 163\t Loss: 0.735122\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5304, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 164\t Loss: 0.593845\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4580, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 165\t Loss: 0.671317\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5610, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 166\t Loss: 0.636722\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4059, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 167\t Loss: 0.517622\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6283, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 168\t Loss: 0.497276\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3265, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 169\t Loss: 0.772500\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6642, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 170\t Loss: 0.517424\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6393, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 171\t Loss: 0.643350\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5157, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 172\t Loss: 0.661452\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3097, Accuracy: 553/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 173\t Loss: 0.698425\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5968, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 174\t Loss: 0.705487\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3395, Accuracy: 564/692 (82%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 175\t Loss: 0.564277\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4042, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 176\t Loss: 0.658423\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3704, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 177\t Loss: 0.476397\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5306, Accuracy: 554/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 178\t Loss: 0.533709\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5105, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 179\t Loss: 0.604256\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5982, Accuracy: 557/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 180\t Loss: 0.559660\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4806, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 181\t Loss: 0.528623\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5805, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 182\t Loss: 0.568161\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5130, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 183\t Loss: 0.627234\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5924, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 184\t Loss: 0.657133\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6056, Accuracy: 553/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 185\t Loss: 0.463041\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4088, Accuracy: 555/692 (80%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 186\t Loss: 0.412780\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5507, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.5028901734104\n",
      "-----------------------\n",
      "Train Epoch: 187\t Loss: 0.485393\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6184, Accuracy: 567/692 (82%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 188\t Loss: 0.692868\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5237, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 189\t Loss: 0.739226\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4657, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 190\t Loss: 0.573486\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3571, Accuracy: 559/692 (81%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 191\t Loss: 0.507320\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4186, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 192\t Loss: 0.648299\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3903, Accuracy: 563/692 (81%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 193\t Loss: 0.490465\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4647, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 194\t Loss: 0.604589\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.3520, Accuracy: 560/692 (81%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 195\t Loss: 0.730311\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5077, Accuracy: 561/692 (81%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 196\t Loss: 0.614612\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4600, Accuracy: 565/692 (82%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 197\t Loss: 0.491119\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.6124, Accuracy: 558/692 (81%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 198\t Loss: 0.600462\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.5122, Accuracy: 556/692 (80%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Train Epoch: 199\t Loss: 0.655646\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.4344, Accuracy: 562/692 (81%)\n",
      "\n",
      "current best acc:  81.9364161849711\n",
      "-----------------------\n",
      "Result: at 187 epoch, achieved best acc: 82\n"
     ]
    }
   ],
   "source": [
    "max_acc = 0\n",
    "max_epoch = 0\n",
    "for epoch in range(EPOCH):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    acc = test(model, DEVICE, test_loader, optimizer)\n",
    "    if acc >= max_acc:\n",
    "        max_acc = acc\n",
    "        max_epoch = epoch\n",
    "    print('current best acc: ', max_acc)\n",
    "    print('-----------------------')\n",
    "print('Result: at {} epoch, achieved best acc: {:.0f}'.format(max_epoch, max_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function save in module torch.serialization:\n",
      "\n",
      "save(obj, f, pickle_module=<module 'pickle' from '/home/yaoms/anaconda3/envs/PytorchEnv/lib/python3.5/pickle.py'>, pickle_protocol=2)\n",
      "    Saves an object to a disk file.\n",
      "    \n",
      "    See also: :ref:`recommend-saving-models`\n",
      "    \n",
      "    Args:\n",
      "        obj: saved object\n",
      "        f: a file-like object (has to implement write and flush) or a string\n",
      "           containing a file name\n",
      "        pickle_module: module used for pickling metadata and objects\n",
      "        pickle_protocol: can be specified to override the default protocol\n",
      "    \n",
      "    .. warning::\n",
      "        If you are using Python 2, torch.save does NOT support StringIO.StringIO\n",
      "        as a valid file-like object. This is because the write method should return\n",
      "        the number of bytes written; StringIO.write() does not do this.\n",
      "    \n",
      "        Please use something like io.BytesIO instead.\n",
      "    \n",
      "    Example:\n",
      "        >>> # Save to file\n",
      "        >>> x = torch.tensor([0, 1, 2, 3, 4])\n",
      "        >>> torch.save(x, 'tensor.pt')\n",
      "        >>> # Save to io.BytesIO buffer\n",
      "        >>> buffer = io.BytesIO()\n",
      "        >>> torch.save(x, buffer)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
