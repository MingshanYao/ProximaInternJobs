{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Found 8 GPU(s) only 3 gpu below threshold\n",
      "Using GPU 2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "sys.path.append(\"/home/shiyi/gpu/\")\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,5\"  # specify which GPU(s) to be used\n",
    "from gpu_allocation import set_gpu\n",
    "num_gpu = 1\n",
    "set_gpu(num_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters \n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "CLASSES = 8\n",
    "EPOCH = 100\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir and path\n",
    "\n",
    "csv_path = '/data/AlgProj/tct_yaoms/data/tct_0513/include_background_0723.csv'\n",
    "csv = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test dataset split\n",
    "#train val transforms definition\n",
    "\n",
    "# def train_test_split(df, test_size, shuffle=True):\n",
    "#     if shuffle:\n",
    "#         df = df.sample(frac=1).reset_index(drop=True)\n",
    "#     #split\n",
    "#     length = len(df)\n",
    "#     threspoint = int((1 - test_size)*length)\n",
    "#     train_df = df.loc[:threspoint-1,:]\n",
    "#     test_df = df.loc[threspoint:,:]\n",
    "    \n",
    "#     d = {}\n",
    "#     d['train'] = train_df\n",
    "#     d['test'] = test_df.reset_index(drop=True)\n",
    "#     return d\n",
    "\n",
    "train_transformer = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                 transforms.RandomRotation((-180, 180)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomResizedCrop((224,224)),  \n",
    "                                 transforms.ToTensor(),\n",
    "                                       transforms.Normalize(IMG_MEAN,IMG_STD)]\n",
    "                                )\n",
    "test_transformer = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                  transforms.CenterCrop((224,224)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                      transforms.Normalize(IMG_MEAN,IMG_STD)])\n",
    "train_test_transformer = {'train':train_transformer, 'test':test_transformer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1018"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_test_dict = train_test_split(csv, 0.2)\n",
    "# len(train_test_dict['test'])\n",
    "\n",
    "\n",
    "train_csv_path = '/data/AlgProj/tct_yaoms/data/tct_0513/train_df.csv'\n",
    "test_csv_path = '/data/AlgProj/tct_yaoms/data/tct_0513/test_df.csv'\n",
    "train_csv = pd.read_csv(train_csv_path)\n",
    "test_csv = pd.read_csv(test_csv_path)\n",
    "train_test_dict = {'train':train_csv, 'test': test_csv}\n",
    "len(train_test_dict['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCT_Dataset(Dataset):\n",
    "    def __init__(self, phase, transforms=True):\n",
    "        self.phase = phase\n",
    "        self.transforms = transforms\n",
    "        if phase == 'train':\n",
    "            self.df = train_test_dict['train']\n",
    "        else:\n",
    "            self.df = train_test_dict['test']\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path = self.df.loc[idx, 'img_path']\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        \n",
    "        if self.transforms:\n",
    "            if self.phase == 'train':\n",
    "                transformer = train_test_transformer['train']\n",
    "            else:\n",
    "                transformer = train_test_transformer['test']\n",
    "\n",
    "            img = transformer(img)\n",
    "        \n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = TCT_Dataset('train')\n",
    "# test_dataset = TCT_Dataset('test')\n",
    "\n",
    "# train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TCT_Dataset('train')\n",
    "test_dataset = TCT_Dataset('test')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU(inplace)\n",
       "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU(inplace)\n",
       "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import densenet121\n",
    "model = densenet121(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "fc_features = model.classifier.in_features\n",
    "model.classifier = torch.nn.Linear(fc_features, CLASSES)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([{'params':model.classifier.parameters(), 'lr':0.001}])\n",
    "#                        {'params':model.layer4.parameters(),'lr':0.00001}\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Train Epoch: {}\\t Loss: {:.6f}\\n'.format(epoch,loss.item()))\n",
    "\n",
    "    \n",
    "def test(model, device, test_loader, optimizer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "#     pred_result = []\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):          \n",
    "            x,y= data\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            test_loss = criterion(y_hat, y).item() # sum up batch loss\n",
    "            pred = y_hat.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            \n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "    acc = 100. * correct / len(train_test_dict['test'])\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(train_test_dict['test']),\n",
    "        acc))\n",
    "    \n",
    "#     print('-----------------------')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\t Loss: 1.676498\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0622, Accuracy: 651/1018 (64%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 1\t Loss: 1.385847\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0993, Accuracy: 649/1018 (64%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 2\t Loss: 1.431700\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1019, Accuracy: 634/1018 (62%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 3\t Loss: 1.896958\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0690, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 4\t Loss: 1.468286\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0941, Accuracy: 649/1018 (64%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 5\t Loss: 1.331373\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1476, Accuracy: 632/1018 (62%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 6\t Loss: 1.129837\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1529, Accuracy: 620/1018 (61%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 7\t Loss: 0.875106\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1049, Accuracy: 646/1018 (63%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 8\t Loss: 1.680920\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0768, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 9\t Loss: 0.915386\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1231, Accuracy: 621/1018 (61%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 10\t Loss: 1.350304\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1592, Accuracy: 633/1018 (62%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 11\t Loss: 1.330098\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1352, Accuracy: 633/1018 (62%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 12\t Loss: 0.756866\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0763, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 13\t Loss: 1.426069\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0895, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 14\t Loss: 0.991651\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0752, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  63.948919449901766\n",
      "-----------------------\n",
      "Train Epoch: 15\t Loss: 0.918660\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1307, Accuracy: 660/1018 (65%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 16\t Loss: 0.680416\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0594, Accuracy: 639/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 17\t Loss: 1.424843\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0785, Accuracy: 652/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 18\t Loss: 0.712080\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0797, Accuracy: 654/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 19\t Loss: 0.864214\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0564, Accuracy: 626/1018 (61%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 20\t Loss: 1.597000\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1649, Accuracy: 632/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 21\t Loss: 1.738287\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0659, Accuracy: 636/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 22\t Loss: 1.436695\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1504, Accuracy: 629/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 23\t Loss: 1.002339\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0968, Accuracy: 649/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 24\t Loss: 1.584804\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1629, Accuracy: 633/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 25\t Loss: 0.863503\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1005, Accuracy: 643/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 26\t Loss: 0.865202\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1106, Accuracy: 646/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 27\t Loss: 1.004556\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1153, Accuracy: 639/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 28\t Loss: 1.988682\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1027, Accuracy: 648/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 29\t Loss: 1.721822\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0770, Accuracy: 650/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 30\t Loss: 1.143507\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1178, Accuracy: 632/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 31\t Loss: 0.971546\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1374, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 32\t Loss: 1.963713\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0781, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 33\t Loss: 2.629770\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0974, Accuracy: 642/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 34\t Loss: 1.196157\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0402, Accuracy: 632/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 35\t Loss: 1.939382\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1360, Accuracy: 639/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 36\t Loss: 1.201247\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1080, Accuracy: 650/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 37\t Loss: 1.963447\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1342, Accuracy: 627/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 38\t Loss: 1.198723\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0897, Accuracy: 643/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 39\t Loss: 1.931841\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1436, Accuracy: 635/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 40\t Loss: 1.006317\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0719, Accuracy: 634/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 41\t Loss: 0.685562\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1141, Accuracy: 639/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 42\t Loss: 1.103621\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1370, Accuracy: 642/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 43\t Loss: 0.421627\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1157, Accuracy: 636/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 44\t Loss: 1.239454\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1242, Accuracy: 643/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 45\t Loss: 2.243508\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1519, Accuracy: 646/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 46\t Loss: 0.914792\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1491, Accuracy: 630/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 47\t Loss: 1.529206\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1019, Accuracy: 653/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 48\t Loss: 2.117219\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1882, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 49\t Loss: 1.564093\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0598, Accuracy: 635/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 50\t Loss: 1.250090\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0798, Accuracy: 651/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 51\t Loss: 1.561160\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0979, Accuracy: 647/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 52\t Loss: 0.943761\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1514, Accuracy: 650/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 53\t Loss: 0.459394\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1358, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 54\t Loss: 1.947496\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1307, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 55\t Loss: 0.594361\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.2169, Accuracy: 642/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 56\t Loss: 2.287879\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1176, Accuracy: 650/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 57\t Loss: 1.183013\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1440, Accuracy: 640/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 58\t Loss: 2.749703\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1744, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 59\t Loss: 1.374492\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1728, Accuracy: 637/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 60\t Loss: 1.483150\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.2007, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 61\t Loss: 1.662966\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1628, Accuracy: 651/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 62\t Loss: 0.474882\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1185, Accuracy: 647/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 63\t Loss: 1.063547\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1409, Accuracy: 648/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 64\t Loss: 0.744565\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1676, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 65\t Loss: 1.353342\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1305, Accuracy: 653/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 66\t Loss: 0.889771\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.2483, Accuracy: 632/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 67\t Loss: 1.310498\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1918, Accuracy: 654/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 68\t Loss: 1.787397\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1422, Accuracy: 649/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 69\t Loss: 1.231672\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1908, Accuracy: 646/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 70\t Loss: 1.034932\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1426, Accuracy: 639/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 71\t Loss: 1.105074\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.2307, Accuracy: 651/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 72\t Loss: 1.532130\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.2127, Accuracy: 646/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 73\t Loss: 1.101601\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1975, Accuracy: 643/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 74\t Loss: 1.428349\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1123, Accuracy: 648/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 75\t Loss: 1.074182\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1901, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 76\t Loss: 1.641792\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1537, Accuracy: 647/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 77\t Loss: 0.720399\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1618, Accuracy: 636/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 78\t Loss: 0.683201\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0570, Accuracy: 645/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 79\t Loss: 2.118705\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0705, Accuracy: 654/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 80\t Loss: 1.405354\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1791, Accuracy: 656/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 81\t Loss: 1.244087\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1928, Accuracy: 635/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 82\t Loss: 1.795427\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1500, Accuracy: 646/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 83\t Loss: 1.398299\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1566, Accuracy: 639/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 84\t Loss: 0.565860\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0600, Accuracy: 647/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 85\t Loss: 1.649380\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1491, Accuracy: 643/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 86\t Loss: 1.846036\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0984, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 87\t Loss: 1.328696\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1367, Accuracy: 634/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 88\t Loss: 1.287453\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1984, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 89\t Loss: 0.384414\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1353, Accuracy: 650/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 90\t Loss: 0.862176\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1544, Accuracy: 646/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 91\t Loss: 0.865846\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1713, Accuracy: 650/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 92\t Loss: 1.209815\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.2087, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 93\t Loss: 0.691727\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0885, Accuracy: 637/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 94\t Loss: 0.853903\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0485, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 95\t Loss: 1.339706\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.2392, Accuracy: 643/1018 (63%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 96\t Loss: 1.486915\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.1072, Accuracy: 652/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 97\t Loss: 1.290969\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0777, Accuracy: 659/1018 (65%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 98\t Loss: 1.409188\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.2036, Accuracy: 650/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Train Epoch: 99\t Loss: 1.554871\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.0941, Accuracy: 650/1018 (64%)\n",
      "\n",
      "current best acc:  64.83300589390963\n",
      "-----------------------\n",
      "Result: at 15 epoch, achieved best acc: 65\n"
     ]
    }
   ],
   "source": [
    "max_acc = 0\n",
    "max_epoch = 0\n",
    "max_acc = 0.63\n",
    "save_path = '/data/AlgProj/tct_yaoms/model/densenet-121_include_ascus_0722.pth'\n",
    "for epoch in range(EPOCH):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    acc = test(model, DEVICE, test_loader, optimizer)\n",
    "    if acc >= max_acc:\n",
    "        max_acc = acc\n",
    "        max_epoch = epoch\n",
    "        if os.path.exists(save_path):\n",
    "            os.remove(save_path)\n",
    "        torch.save(model, save_path)\n",
    "    print('current best acc: ', max_acc)\n",
    "    print('-----------------------')\n",
    "print('Result: at {} epoch, achieved best acc: {:.0f}'.format(max_epoch, max_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def error_analysis(model, test_loader, classes, DEVICE=DEVICE):\n",
    "    y_pred =[]\n",
    "    y_true = []\n",
    "    for i,data in enumerate(test_loader):\n",
    "        x, y = data\n",
    "        y = np.array(y.cpu())\n",
    "        y_true.append(y)\n",
    "\n",
    "        x = x.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        pred = y_hat.max(1, keepdim=True)[1]\n",
    "        pred = np.array(pred.cpu())\n",
    "        y_pred.append(pred)\n",
    "    \n",
    "    y_pred_list = []\n",
    "    y_true_list = []\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred_list += list(y_pred[i].ravel())\n",
    "    for i in range(len(y_true)):\n",
    "        y_true_list += list(y_true[i].ravel())\n",
    "        \n",
    "    plot_confusion_matrix(y_true_list, y_pred_list, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[126  66   3  21  10   9   3   0]\n",
      " [ 17 162   4  31   4   5  15   0]\n",
      " [  3  16  25   3  23   6  15   0]\n",
      " [ 12  43   0  63   3   1   7   3]\n",
      " [  2   3   5   1  46   4  14   0]\n",
      " [  1  10   1   2   3  51   8   0]\n",
      " [  3   1   0   0   1   1  89   0]\n",
      " [  0   0   0   0   1   0   0  72]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = np.array(['0', '1', '2', '3', '4', '5', '6', '7'])\n",
    "error_analysis(model, test_loader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
