{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Found 8 GPU(s) only 2 gpu below threshold\n",
      "Using GPU 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "sys.path.append(\"/home/shiyi/gpu/\")\n",
    "\n",
    "from gpu_allocation import set_gpu\n",
    "num_gpu = 1\n",
    "set_gpu(num_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters \n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 128\n",
    "CLASSES = 8\n",
    "EPOCH = 200\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir and path\n",
    "\n",
    "csv_path = '/data/AlgProj/tct_yaoms/data/tct_0513/augmentation_label.csv'\n",
    "csv = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test dataset split\n",
    "#train val transforms definition\n",
    "\n",
    "def train_test_split(df, test_size, shuffle=True):\n",
    "    if shuffle:\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "    #split\n",
    "    length = len(df)\n",
    "    threspoint = int((1 - test_size)*length)\n",
    "    train_df = df.loc[:threspoint-1,:]\n",
    "    test_df = df.loc[threspoint:,:]\n",
    "    \n",
    "    d = {}\n",
    "    d['train'] = train_df\n",
    "    d['test'] = test_df.reset_index(drop=True)\n",
    "    return d\n",
    "\n",
    "train_transformer = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                 transforms.RandomRotation((-180, 180)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomResizedCrop((224,224)),  \n",
    "                                 transforms.ToTensor(),\n",
    "                                       transforms.Normalize(IMG_MEAN,IMG_STD)]\n",
    "                                )\n",
    "test_transformer = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                  transforms.CenterCrop((224,224)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                      transforms.Normalize(IMG_MEAN,IMG_STD)])\n",
    "train_test_transformer = {'train':train_transformer, 'test':test_transformer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "954"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_dict = train_test_split(csv, 0.2)\n",
    "len(train_test_dict['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCT_Dataset(Dataset):\n",
    "    def __init__(self, phase, transforms=True):\n",
    "        self.phase = phase\n",
    "        self.transforms = transforms\n",
    "        if phase == 'train':\n",
    "            self.df = train_test_dict['train']\n",
    "        else:\n",
    "            self.df = train_test_dict['test']\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path = self.df.loc[idx, 'img_path']\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        \n",
    "        if self.transforms:\n",
    "            if self.phase == 'train':\n",
    "                transformer = train_test_transformer['train']\n",
    "            else:\n",
    "                transformer = train_test_transformer['test']\n",
    "\n",
    "            img = transformer(img)\n",
    "        \n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TCT_Dataset('train')\n",
    "test_dataset = TCT_Dataset('test')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet121\n",
    "model = densenet121(pretrained=True)\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# fc_features = model.fc.in_features\n",
    "# model.fc = torch.nn.Linear(fc_features, CLASSES)\n",
    "\n",
    "# model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "       BatchNorm2d-5           [-1, 64, 56, 56]             128\n",
      "              ReLU-6           [-1, 64, 56, 56]               0\n",
      "            Conv2d-7          [-1, 128, 56, 56]           8,192\n",
      "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
      "              ReLU-9          [-1, 128, 56, 56]               0\n",
      "           Conv2d-10           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-11           [-1, 96, 56, 56]             192\n",
      "             ReLU-12           [-1, 96, 56, 56]               0\n",
      "           Conv2d-13          [-1, 128, 56, 56]          12,288\n",
      "      BatchNorm2d-14          [-1, 128, 56, 56]             256\n",
      "             ReLU-15          [-1, 128, 56, 56]               0\n",
      "           Conv2d-16           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-17          [-1, 128, 56, 56]             256\n",
      "             ReLU-18          [-1, 128, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 56, 56]          16,384\n",
      "      BatchNorm2d-20          [-1, 128, 56, 56]             256\n",
      "             ReLU-21          [-1, 128, 56, 56]               0\n",
      "           Conv2d-22           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-23          [-1, 160, 56, 56]             320\n",
      "             ReLU-24          [-1, 160, 56, 56]               0\n",
      "           Conv2d-25          [-1, 128, 56, 56]          20,480\n",
      "      BatchNorm2d-26          [-1, 128, 56, 56]             256\n",
      "             ReLU-27          [-1, 128, 56, 56]               0\n",
      "           Conv2d-28           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-29          [-1, 192, 56, 56]             384\n",
      "             ReLU-30          [-1, 192, 56, 56]               0\n",
      "           Conv2d-31          [-1, 128, 56, 56]          24,576\n",
      "      BatchNorm2d-32          [-1, 128, 56, 56]             256\n",
      "             ReLU-33          [-1, 128, 56, 56]               0\n",
      "           Conv2d-34           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-35          [-1, 224, 56, 56]             448\n",
      "             ReLU-36          [-1, 224, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          28,672\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40           [-1, 32, 56, 56]          36,864\n",
      "      BatchNorm2d-41          [-1, 256, 56, 56]             512\n",
      "             ReLU-42          [-1, 256, 56, 56]               0\n",
      "           Conv2d-43          [-1, 128, 56, 56]          32,768\n",
      "        AvgPool2d-44          [-1, 128, 28, 28]               0\n",
      "      BatchNorm2d-45          [-1, 128, 28, 28]             256\n",
      "             ReLU-46          [-1, 128, 28, 28]               0\n",
      "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
      "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
      "             ReLU-49          [-1, 128, 28, 28]               0\n",
      "           Conv2d-50           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-51          [-1, 160, 28, 28]             320\n",
      "             ReLU-52          [-1, 160, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]          20,480\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-57          [-1, 192, 28, 28]             384\n",
      "             ReLU-58          [-1, 192, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          24,576\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-63          [-1, 224, 28, 28]             448\n",
      "             ReLU-64          [-1, 224, 28, 28]               0\n",
      "           Conv2d-65          [-1, 128, 28, 28]          28,672\n",
      "      BatchNorm2d-66          [-1, 128, 28, 28]             256\n",
      "             ReLU-67          [-1, 128, 28, 28]               0\n",
      "           Conv2d-68           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-69          [-1, 256, 28, 28]             512\n",
      "             ReLU-70          [-1, 256, 28, 28]               0\n",
      "           Conv2d-71          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-72          [-1, 128, 28, 28]             256\n",
      "             ReLU-73          [-1, 128, 28, 28]               0\n",
      "           Conv2d-74           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-75          [-1, 288, 28, 28]             576\n",
      "             ReLU-76          [-1, 288, 28, 28]               0\n",
      "           Conv2d-77          [-1, 128, 28, 28]          36,864\n",
      "      BatchNorm2d-78          [-1, 128, 28, 28]             256\n",
      "             ReLU-79          [-1, 128, 28, 28]               0\n",
      "           Conv2d-80           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-81          [-1, 320, 28, 28]             640\n",
      "             ReLU-82          [-1, 320, 28, 28]               0\n",
      "           Conv2d-83          [-1, 128, 28, 28]          40,960\n",
      "      BatchNorm2d-84          [-1, 128, 28, 28]             256\n",
      "             ReLU-85          [-1, 128, 28, 28]               0\n",
      "           Conv2d-86           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-87          [-1, 352, 28, 28]             704\n",
      "             ReLU-88          [-1, 352, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]          45,056\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-93          [-1, 384, 28, 28]             768\n",
      "             ReLU-94          [-1, 384, 28, 28]               0\n",
      "           Conv2d-95          [-1, 128, 28, 28]          49,152\n",
      "      BatchNorm2d-96          [-1, 128, 28, 28]             256\n",
      "             ReLU-97          [-1, 128, 28, 28]               0\n",
      "           Conv2d-98           [-1, 32, 28, 28]          36,864\n",
      "      BatchNorm2d-99          [-1, 416, 28, 28]             832\n",
      "            ReLU-100          [-1, 416, 28, 28]               0\n",
      "          Conv2d-101          [-1, 128, 28, 28]          53,248\n",
      "     BatchNorm2d-102          [-1, 128, 28, 28]             256\n",
      "            ReLU-103          [-1, 128, 28, 28]               0\n",
      "          Conv2d-104           [-1, 32, 28, 28]          36,864\n",
      "     BatchNorm2d-105          [-1, 448, 28, 28]             896\n",
      "            ReLU-106          [-1, 448, 28, 28]               0\n",
      "          Conv2d-107          [-1, 128, 28, 28]          57,344\n",
      "     BatchNorm2d-108          [-1, 128, 28, 28]             256\n",
      "            ReLU-109          [-1, 128, 28, 28]               0\n",
      "          Conv2d-110           [-1, 32, 28, 28]          36,864\n",
      "     BatchNorm2d-111          [-1, 480, 28, 28]             960\n",
      "            ReLU-112          [-1, 480, 28, 28]               0\n",
      "          Conv2d-113          [-1, 128, 28, 28]          61,440\n",
      "     BatchNorm2d-114          [-1, 128, 28, 28]             256\n",
      "            ReLU-115          [-1, 128, 28, 28]               0\n",
      "          Conv2d-116           [-1, 32, 28, 28]          36,864\n",
      "     BatchNorm2d-117          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 256, 28, 28]         131,072\n",
      "       AvgPool2d-120          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-121          [-1, 256, 14, 14]             512\n",
      "            ReLU-122          [-1, 256, 14, 14]               0\n",
      "          Conv2d-123          [-1, 128, 14, 14]          32,768\n",
      "     BatchNorm2d-124          [-1, 128, 14, 14]             256\n",
      "            ReLU-125          [-1, 128, 14, 14]               0\n",
      "          Conv2d-126           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-127          [-1, 288, 14, 14]             576\n",
      "            ReLU-128          [-1, 288, 14, 14]               0\n",
      "          Conv2d-129          [-1, 128, 14, 14]          36,864\n",
      "     BatchNorm2d-130          [-1, 128, 14, 14]             256\n",
      "            ReLU-131          [-1, 128, 14, 14]               0\n",
      "          Conv2d-132           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-133          [-1, 320, 14, 14]             640\n",
      "            ReLU-134          [-1, 320, 14, 14]               0\n",
      "          Conv2d-135          [-1, 128, 14, 14]          40,960\n",
      "     BatchNorm2d-136          [-1, 128, 14, 14]             256\n",
      "            ReLU-137          [-1, 128, 14, 14]               0\n",
      "          Conv2d-138           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-139          [-1, 352, 14, 14]             704\n",
      "            ReLU-140          [-1, 352, 14, 14]               0\n",
      "          Conv2d-141          [-1, 128, 14, 14]          45,056\n",
      "     BatchNorm2d-142          [-1, 128, 14, 14]             256\n",
      "            ReLU-143          [-1, 128, 14, 14]               0\n",
      "          Conv2d-144           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-145          [-1, 384, 14, 14]             768\n",
      "            ReLU-146          [-1, 384, 14, 14]               0\n",
      "          Conv2d-147          [-1, 128, 14, 14]          49,152\n",
      "     BatchNorm2d-148          [-1, 128, 14, 14]             256\n",
      "            ReLU-149          [-1, 128, 14, 14]               0\n",
      "          Conv2d-150           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-151          [-1, 416, 14, 14]             832\n",
      "            ReLU-152          [-1, 416, 14, 14]               0\n",
      "          Conv2d-153          [-1, 128, 14, 14]          53,248\n",
      "     BatchNorm2d-154          [-1, 128, 14, 14]             256\n",
      "            ReLU-155          [-1, 128, 14, 14]               0\n",
      "          Conv2d-156           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-157          [-1, 448, 14, 14]             896\n",
      "            ReLU-158          [-1, 448, 14, 14]               0\n",
      "          Conv2d-159          [-1, 128, 14, 14]          57,344\n",
      "     BatchNorm2d-160          [-1, 128, 14, 14]             256\n",
      "            ReLU-161          [-1, 128, 14, 14]               0\n",
      "          Conv2d-162           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-163          [-1, 480, 14, 14]             960\n",
      "            ReLU-164          [-1, 480, 14, 14]               0\n",
      "          Conv2d-165          [-1, 128, 14, 14]          61,440\n",
      "     BatchNorm2d-166          [-1, 128, 14, 14]             256\n",
      "            ReLU-167          [-1, 128, 14, 14]               0\n",
      "          Conv2d-168           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-169          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-170          [-1, 512, 14, 14]               0\n",
      "          Conv2d-171          [-1, 128, 14, 14]          65,536\n",
      "     BatchNorm2d-172          [-1, 128, 14, 14]             256\n",
      "            ReLU-173          [-1, 128, 14, 14]               0\n",
      "          Conv2d-174           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-175          [-1, 544, 14, 14]           1,088\n",
      "            ReLU-176          [-1, 544, 14, 14]               0\n",
      "          Conv2d-177          [-1, 128, 14, 14]          69,632\n",
      "     BatchNorm2d-178          [-1, 128, 14, 14]             256\n",
      "            ReLU-179          [-1, 128, 14, 14]               0\n",
      "          Conv2d-180           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-181          [-1, 576, 14, 14]           1,152\n",
      "            ReLU-182          [-1, 576, 14, 14]               0\n",
      "          Conv2d-183          [-1, 128, 14, 14]          73,728\n",
      "     BatchNorm2d-184          [-1, 128, 14, 14]             256\n",
      "            ReLU-185          [-1, 128, 14, 14]               0\n",
      "          Conv2d-186           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-187          [-1, 608, 14, 14]           1,216\n",
      "            ReLU-188          [-1, 608, 14, 14]               0\n",
      "          Conv2d-189          [-1, 128, 14, 14]          77,824\n",
      "     BatchNorm2d-190          [-1, 128, 14, 14]             256\n",
      "            ReLU-191          [-1, 128, 14, 14]               0\n",
      "          Conv2d-192           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-193          [-1, 640, 14, 14]           1,280\n",
      "            ReLU-194          [-1, 640, 14, 14]               0\n",
      "          Conv2d-195          [-1, 128, 14, 14]          81,920\n",
      "     BatchNorm2d-196          [-1, 128, 14, 14]             256\n",
      "            ReLU-197          [-1, 128, 14, 14]               0\n",
      "          Conv2d-198           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-199          [-1, 672, 14, 14]           1,344\n",
      "            ReLU-200          [-1, 672, 14, 14]               0\n",
      "          Conv2d-201          [-1, 128, 14, 14]          86,016\n",
      "     BatchNorm2d-202          [-1, 128, 14, 14]             256\n",
      "            ReLU-203          [-1, 128, 14, 14]               0\n",
      "          Conv2d-204           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-205          [-1, 704, 14, 14]           1,408\n",
      "            ReLU-206          [-1, 704, 14, 14]               0\n",
      "          Conv2d-207          [-1, 128, 14, 14]          90,112\n",
      "     BatchNorm2d-208          [-1, 128, 14, 14]             256\n",
      "            ReLU-209          [-1, 128, 14, 14]               0\n",
      "          Conv2d-210           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-211          [-1, 736, 14, 14]           1,472\n",
      "            ReLU-212          [-1, 736, 14, 14]               0\n",
      "          Conv2d-213          [-1, 128, 14, 14]          94,208\n",
      "     BatchNorm2d-214          [-1, 128, 14, 14]             256\n",
      "            ReLU-215          [-1, 128, 14, 14]               0\n",
      "          Conv2d-216           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-217          [-1, 768, 14, 14]           1,536\n",
      "            ReLU-218          [-1, 768, 14, 14]               0\n",
      "          Conv2d-219          [-1, 128, 14, 14]          98,304\n",
      "     BatchNorm2d-220          [-1, 128, 14, 14]             256\n",
      "            ReLU-221          [-1, 128, 14, 14]               0\n",
      "          Conv2d-222           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-223          [-1, 800, 14, 14]           1,600\n",
      "            ReLU-224          [-1, 800, 14, 14]               0\n",
      "          Conv2d-225          [-1, 128, 14, 14]         102,400\n",
      "     BatchNorm2d-226          [-1, 128, 14, 14]             256\n",
      "            ReLU-227          [-1, 128, 14, 14]               0\n",
      "          Conv2d-228           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-229          [-1, 832, 14, 14]           1,664\n",
      "            ReLU-230          [-1, 832, 14, 14]               0\n",
      "          Conv2d-231          [-1, 128, 14, 14]         106,496\n",
      "     BatchNorm2d-232          [-1, 128, 14, 14]             256\n",
      "            ReLU-233          [-1, 128, 14, 14]               0\n",
      "          Conv2d-234           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-235          [-1, 864, 14, 14]           1,728\n",
      "            ReLU-236          [-1, 864, 14, 14]               0\n",
      "          Conv2d-237          [-1, 128, 14, 14]         110,592\n",
      "     BatchNorm2d-238          [-1, 128, 14, 14]             256\n",
      "            ReLU-239          [-1, 128, 14, 14]               0\n",
      "          Conv2d-240           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-241          [-1, 896, 14, 14]           1,792\n",
      "            ReLU-242          [-1, 896, 14, 14]               0\n",
      "          Conv2d-243          [-1, 128, 14, 14]         114,688\n",
      "     BatchNorm2d-244          [-1, 128, 14, 14]             256\n",
      "            ReLU-245          [-1, 128, 14, 14]               0\n",
      "          Conv2d-246           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-247          [-1, 928, 14, 14]           1,856\n",
      "            ReLU-248          [-1, 928, 14, 14]               0\n",
      "          Conv2d-249          [-1, 128, 14, 14]         118,784\n",
      "     BatchNorm2d-250          [-1, 128, 14, 14]             256\n",
      "            ReLU-251          [-1, 128, 14, 14]               0\n",
      "          Conv2d-252           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-253          [-1, 960, 14, 14]           1,920\n",
      "            ReLU-254          [-1, 960, 14, 14]               0\n",
      "          Conv2d-255          [-1, 128, 14, 14]         122,880\n",
      "     BatchNorm2d-256          [-1, 128, 14, 14]             256\n",
      "            ReLU-257          [-1, 128, 14, 14]               0\n",
      "          Conv2d-258           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-259          [-1, 992, 14, 14]           1,984\n",
      "            ReLU-260          [-1, 992, 14, 14]               0\n",
      "          Conv2d-261          [-1, 128, 14, 14]         126,976\n",
      "     BatchNorm2d-262          [-1, 128, 14, 14]             256\n",
      "            ReLU-263          [-1, 128, 14, 14]               0\n",
      "          Conv2d-264           [-1, 32, 14, 14]          36,864\n",
      "     BatchNorm2d-265         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-266         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-267          [-1, 512, 14, 14]         524,288\n",
      "       AvgPool2d-268            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-269            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-270            [-1, 512, 7, 7]               0\n",
      "          Conv2d-271            [-1, 128, 7, 7]          65,536\n",
      "     BatchNorm2d-272            [-1, 128, 7, 7]             256\n",
      "            ReLU-273            [-1, 128, 7, 7]               0\n",
      "          Conv2d-274             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-275            [-1, 544, 7, 7]           1,088\n",
      "            ReLU-276            [-1, 544, 7, 7]               0\n",
      "          Conv2d-277            [-1, 128, 7, 7]          69,632\n",
      "     BatchNorm2d-278            [-1, 128, 7, 7]             256\n",
      "            ReLU-279            [-1, 128, 7, 7]               0\n",
      "          Conv2d-280             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-281            [-1, 576, 7, 7]           1,152\n",
      "            ReLU-282            [-1, 576, 7, 7]               0\n",
      "          Conv2d-283            [-1, 128, 7, 7]          73,728\n",
      "     BatchNorm2d-284            [-1, 128, 7, 7]             256\n",
      "            ReLU-285            [-1, 128, 7, 7]               0\n",
      "          Conv2d-286             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-287            [-1, 608, 7, 7]           1,216\n",
      "            ReLU-288            [-1, 608, 7, 7]               0\n",
      "          Conv2d-289            [-1, 128, 7, 7]          77,824\n",
      "     BatchNorm2d-290            [-1, 128, 7, 7]             256\n",
      "            ReLU-291            [-1, 128, 7, 7]               0\n",
      "          Conv2d-292             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-293            [-1, 640, 7, 7]           1,280\n",
      "            ReLU-294            [-1, 640, 7, 7]               0\n",
      "          Conv2d-295            [-1, 128, 7, 7]          81,920\n",
      "     BatchNorm2d-296            [-1, 128, 7, 7]             256\n",
      "            ReLU-297            [-1, 128, 7, 7]               0\n",
      "          Conv2d-298             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-299            [-1, 672, 7, 7]           1,344\n",
      "            ReLU-300            [-1, 672, 7, 7]               0\n",
      "          Conv2d-301            [-1, 128, 7, 7]          86,016\n",
      "     BatchNorm2d-302            [-1, 128, 7, 7]             256\n",
      "            ReLU-303            [-1, 128, 7, 7]               0\n",
      "          Conv2d-304             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-305            [-1, 704, 7, 7]           1,408\n",
      "            ReLU-306            [-1, 704, 7, 7]               0\n",
      "          Conv2d-307            [-1, 128, 7, 7]          90,112\n",
      "     BatchNorm2d-308            [-1, 128, 7, 7]             256\n",
      "            ReLU-309            [-1, 128, 7, 7]               0\n",
      "          Conv2d-310             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-311            [-1, 736, 7, 7]           1,472\n",
      "            ReLU-312            [-1, 736, 7, 7]               0\n",
      "          Conv2d-313            [-1, 128, 7, 7]          94,208\n",
      "     BatchNorm2d-314            [-1, 128, 7, 7]             256\n",
      "            ReLU-315            [-1, 128, 7, 7]               0\n",
      "          Conv2d-316             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-317            [-1, 768, 7, 7]           1,536\n",
      "            ReLU-318            [-1, 768, 7, 7]               0\n",
      "          Conv2d-319            [-1, 128, 7, 7]          98,304\n",
      "     BatchNorm2d-320            [-1, 128, 7, 7]             256\n",
      "            ReLU-321            [-1, 128, 7, 7]               0\n",
      "          Conv2d-322             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-323            [-1, 800, 7, 7]           1,600\n",
      "            ReLU-324            [-1, 800, 7, 7]               0\n",
      "          Conv2d-325            [-1, 128, 7, 7]         102,400\n",
      "     BatchNorm2d-326            [-1, 128, 7, 7]             256\n",
      "            ReLU-327            [-1, 128, 7, 7]               0\n",
      "          Conv2d-328             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-329            [-1, 832, 7, 7]           1,664\n",
      "            ReLU-330            [-1, 832, 7, 7]               0\n",
      "          Conv2d-331            [-1, 128, 7, 7]         106,496\n",
      "     BatchNorm2d-332            [-1, 128, 7, 7]             256\n",
      "            ReLU-333            [-1, 128, 7, 7]               0\n",
      "          Conv2d-334             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-335            [-1, 864, 7, 7]           1,728\n",
      "            ReLU-336            [-1, 864, 7, 7]               0\n",
      "          Conv2d-337            [-1, 128, 7, 7]         110,592\n",
      "     BatchNorm2d-338            [-1, 128, 7, 7]             256\n",
      "            ReLU-339            [-1, 128, 7, 7]               0\n",
      "          Conv2d-340             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-341            [-1, 896, 7, 7]           1,792\n",
      "            ReLU-342            [-1, 896, 7, 7]               0\n",
      "          Conv2d-343            [-1, 128, 7, 7]         114,688\n",
      "     BatchNorm2d-344            [-1, 128, 7, 7]             256\n",
      "            ReLU-345            [-1, 128, 7, 7]               0\n",
      "          Conv2d-346             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-347            [-1, 928, 7, 7]           1,856\n",
      "            ReLU-348            [-1, 928, 7, 7]               0\n",
      "          Conv2d-349            [-1, 128, 7, 7]         118,784\n",
      "     BatchNorm2d-350            [-1, 128, 7, 7]             256\n",
      "            ReLU-351            [-1, 128, 7, 7]               0\n",
      "          Conv2d-352             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-353            [-1, 960, 7, 7]           1,920\n",
      "            ReLU-354            [-1, 960, 7, 7]               0\n",
      "          Conv2d-355            [-1, 128, 7, 7]         122,880\n",
      "     BatchNorm2d-356            [-1, 128, 7, 7]             256\n",
      "            ReLU-357            [-1, 128, 7, 7]               0\n",
      "          Conv2d-358             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-359            [-1, 992, 7, 7]           1,984\n",
      "            ReLU-360            [-1, 992, 7, 7]               0\n",
      "          Conv2d-361            [-1, 128, 7, 7]         126,976\n",
      "     BatchNorm2d-362            [-1, 128, 7, 7]             256\n",
      "            ReLU-363            [-1, 128, 7, 7]               0\n",
      "          Conv2d-364             [-1, 32, 7, 7]          36,864\n",
      "     BatchNorm2d-365           [-1, 1024, 7, 7]           2,048\n",
      "          Linear-366                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 7,978,856\n",
      "Trainable params: 7,978,856\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 294.20\n",
      "Params size (MB): 30.44\n",
      "Estimated Total Size (MB): 325.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3,224,224), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function summary in module torchsummary.torchsummary:\n",
      "\n",
      "summary(model, input_size, batch_size=-1, device='cuda')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 19 14:23:11 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.37                 Driver Version: 396.37                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 41%   70C    P2   246W / 250W |  10753MiB / 11178MiB |     94%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 23%   30C    P8     8W / 250W |  10787MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 53%   84C    P2   210W / 250W |  10783MiB / 11178MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 33%   58C    P2    76W / 250W |   8561MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 31%   54C    P2    68W / 250W |  10442MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 50%   83C    P2   209W / 250W |  11032MiB / 11178MiB |     91%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 23%   28C    P8     9W / 250W |  10789MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 23%   28C    P8     9W / 250W |  10783MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      8266      C   /opt/anaconda2/bin/python                  10743MiB |\n",
      "|    1     16191      C   /opt/anaconda2/bin/python                  10773MiB |\n",
      "|    2     36135      C   python                                     10773MiB |\n",
      "|    3     22011      C   /home/jiapf/anaconda3/bin/python            8551MiB |\n",
      "|    4     12290      C   /home/jiapf/anaconda3/bin/python            8583MiB |\n",
      "|    4     30646      C   ...ms/anaconda3/envs/PytorchEnv/bin/python  1849MiB |\n",
      "|    5     17222      C   python                                      6027MiB |\n",
      "|    5     41030      C   python                                      4995MiB |\n",
      "|    6     18981      C   ...cheng/anaconda3/envs/spyder2/bin/python 10779MiB |\n",
      "|    7     33504      C   /opt/anaconda2/bin/python                  10773MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
