{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yaoms/anaconda3/envs/PytorchEnv/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 GPU(s) only 4 gpu below threshold\n",
      "Using GPU 5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %matplotlib inline\n",
    "sys.path.append(\"/home/shiyi/gpu/\")\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,2,5\"  # specify which GPU(s) to be used\n",
    "from gpu_allocation import set_gpu\n",
    "num_gpu = 1\n",
    "set_gpu(num_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters \n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "CLASSES = 8\n",
    "EPOCH = 200\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir and path\n",
    "\n",
    "csv_path ='/data/AlgProj/tct_yaoms/data/tct_0513/include_background_0723.csv'\n",
    "csv = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test dataset split\n",
    "#train val transforms definition\n",
    "\n",
    "# def train_test_split(df, test_size, shuffle=True):\n",
    "#     if shuffle:\n",
    "#         df = df.sample(frac=1).reset_index(drop=True)\n",
    "#     #split\n",
    "#     length = len(df)\n",
    "#     threspoint = int((1 - test_size)*length)\n",
    "#     train_df = df.loc[:threspoint-1,:]\n",
    "#     test_df = df.loc[threspoint:,:]\n",
    "    \n",
    "#     d = {}\n",
    "#     d['train'] = train_df\n",
    "#     d['test'] = test_df.reset_index(drop=True)\n",
    "#     return d\n",
    "\n",
    "train_transformer = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                 transforms.RandomRotation((-180, 180)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomResizedCrop((224,224)),  \n",
    "                                 transforms.ToTensor(),\n",
    "                                       transforms.Normalize(IMG_MEAN,IMG_STD)]\n",
    "                                )\n",
    "test_transformer = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                  transforms.CenterCrop((224,224)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                      transforms.Normalize(IMG_MEAN,IMG_STD)])\n",
    "train_test_transformer = {'train':train_transformer, 'test':test_transformer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1018"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_test_dict = train_test_split(csv, 0.2)\n",
    "train_csv_path = '/data/AlgProj/tct_yaoms/data/tct_0513/train_df.csv'\n",
    "test_csv_path = '/data/AlgProj/tct_yaoms/data/tct_0513/test_df.csv'\n",
    "train_csv = pd.read_csv(train_csv_path)\n",
    "test_csv = pd.read_csv(test_csv_path)\n",
    "train_test_dict = {'train':train_csv, 'test': test_csv}\n",
    "len(train_test_dict['test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCT_Dataset(Dataset):\n",
    "    def __init__(self, phase, transforms=True):\n",
    "        self.phase = phase\n",
    "        self.transforms = transforms\n",
    "        if phase == 'train':\n",
    "            self.df = train_test_dict['train']\n",
    "        else:\n",
    "            self.df = train_test_dict['test']\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_path = self.df.loc[idx, 'img_path']\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        \n",
    "        if self.transforms:\n",
    "            if self.phase == 'train':\n",
    "                transformer = train_test_transformer['train']\n",
    "            else:\n",
    "                transformer = train_test_transformer['test']\n",
    "\n",
    "            img = transformer(img)\n",
    "        \n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TCT_Dataset('train')\n",
    "test_dataset = TCT_Dataset('test')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet34\n",
    "model = resnet34(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "fc_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(fc_features, CLASSES)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "bn1.weight\n",
      "bn1.bias\n",
      "layer1.0.conv1.weight\n",
      "layer1.0.bn1.weight\n",
      "layer1.0.bn1.bias\n",
      "layer1.0.conv2.weight\n",
      "layer1.0.bn2.weight\n",
      "layer1.0.bn2.bias\n",
      "layer1.1.conv1.weight\n",
      "layer1.1.bn1.weight\n",
      "layer1.1.bn1.bias\n",
      "layer1.1.conv2.weight\n",
      "layer1.1.bn2.weight\n",
      "layer1.1.bn2.bias\n",
      "layer1.2.conv1.weight\n",
      "layer1.2.bn1.weight\n",
      "layer1.2.bn1.bias\n",
      "layer1.2.conv2.weight\n",
      "layer1.2.bn2.weight\n",
      "layer1.2.bn2.bias\n",
      "layer2.0.conv1.weight\n",
      "layer2.0.bn1.weight\n",
      "layer2.0.bn1.bias\n",
      "layer2.0.conv2.weight\n",
      "layer2.0.bn2.weight\n",
      "layer2.0.bn2.bias\n",
      "layer2.0.downsample.0.weight\n",
      "layer2.0.downsample.1.weight\n",
      "layer2.0.downsample.1.bias\n",
      "layer2.1.conv1.weight\n",
      "layer2.1.bn1.weight\n",
      "layer2.1.bn1.bias\n",
      "layer2.1.conv2.weight\n",
      "layer2.1.bn2.weight\n",
      "layer2.1.bn2.bias\n",
      "layer2.2.conv1.weight\n",
      "layer2.2.bn1.weight\n",
      "layer2.2.bn1.bias\n",
      "layer2.2.conv2.weight\n",
      "layer2.2.bn2.weight\n",
      "layer2.2.bn2.bias\n",
      "layer2.3.conv1.weight\n",
      "layer2.3.bn1.weight\n",
      "layer2.3.bn1.bias\n",
      "layer2.3.conv2.weight\n",
      "layer2.3.bn2.weight\n",
      "layer2.3.bn2.bias\n",
      "layer3.0.conv1.weight\n",
      "layer3.0.bn1.weight\n",
      "layer3.0.bn1.bias\n",
      "layer3.0.conv2.weight\n",
      "layer3.0.bn2.weight\n",
      "layer3.0.bn2.bias\n",
      "layer3.0.downsample.0.weight\n",
      "layer3.0.downsample.1.weight\n",
      "layer3.0.downsample.1.bias\n",
      "layer3.1.conv1.weight\n",
      "layer3.1.bn1.weight\n",
      "layer3.1.bn1.bias\n",
      "layer3.1.conv2.weight\n",
      "layer3.1.bn2.weight\n",
      "layer3.1.bn2.bias\n",
      "layer3.2.conv1.weight\n",
      "layer3.2.bn1.weight\n",
      "layer3.2.bn1.bias\n",
      "layer3.2.conv2.weight\n",
      "layer3.2.bn2.weight\n",
      "layer3.2.bn2.bias\n",
      "layer3.3.conv1.weight\n",
      "layer3.3.bn1.weight\n",
      "layer3.3.bn1.bias\n",
      "layer3.3.conv2.weight\n",
      "layer3.3.bn2.weight\n",
      "layer3.3.bn2.bias\n",
      "layer3.4.conv1.weight\n",
      "layer3.4.bn1.weight\n",
      "layer3.4.bn1.bias\n",
      "layer3.4.conv2.weight\n",
      "layer3.4.bn2.weight\n",
      "layer3.4.bn2.bias\n",
      "layer3.5.conv1.weight\n",
      "layer3.5.bn1.weight\n",
      "layer3.5.bn1.bias\n",
      "layer3.5.conv2.weight\n",
      "layer3.5.bn2.weight\n",
      "layer3.5.bn2.bias\n",
      "layer4.0.conv1.weight\n",
      "layer4.0.bn1.weight\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.conv2.weight\n",
      "layer4.0.bn2.weight\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.downsample.0.weight\n",
      "layer4.0.downsample.1.weight\n",
      "layer4.0.downsample.1.bias\n",
      "layer4.1.conv1.weight\n",
      "layer4.1.bn1.weight\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.conv2.weight\n",
      "layer4.1.bn2.weight\n",
      "layer4.1.bn2.bias\n",
      "layer4.2.conv1.weight\n",
      "layer4.2.bn1.weight\n",
      "layer4.2.bn1.bias\n",
      "layer4.2.conv2.weight\n",
      "layer4.2.bn2.weight\n",
      "layer4.2.bn2.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for k, _ in model.named_parameters():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([{'params':model.fc.parameters(), 'lr':0.001}\n",
    "                      ])\n",
    "#                        \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Train Epoch: {}\\t Loss: {:.6f}\\n'.format(epoch,loss.item()))\n",
    "\n",
    "    \n",
    "def test(model, device, test_loader, optimizer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "#     pred_result = []\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):          \n",
    "            x,y= data\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            test_loss = criterion(y_hat, y).item() # sum up batch loss\n",
    "            pred = y_hat.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            \n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "#     test_loss /= len(test_loader.dataset)\n",
    "    acc = 100. * correct / len(train_test_dict['test'])\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(train_test_dict['test']),\n",
    "        acc))\n",
    "    \n",
    "#     print('-----------------------')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\t Loss: 1.413368\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9360, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  63.26129666011788\n",
      "-----------------------\n",
      "Train Epoch: 1\t Loss: 1.602119\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8586, Accuracy: 654/1018 (64%)\n",
      "\n",
      "current best acc:  64.24361493123772\n",
      "-----------------------\n",
      "Train Epoch: 2\t Loss: 1.101576\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9000, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.24361493123772\n",
      "-----------------------\n",
      "Train Epoch: 3\t Loss: 0.971072\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8944, Accuracy: 645/1018 (63%)\n",
      "\n",
      "current best acc:  64.24361493123772\n",
      "-----------------------\n",
      "Train Epoch: 4\t Loss: 2.525357\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9089, Accuracy: 632/1018 (62%)\n",
      "\n",
      "current best acc:  64.24361493123772\n",
      "-----------------------\n",
      "Train Epoch: 5\t Loss: 2.326964\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9259, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.24361493123772\n",
      "-----------------------\n",
      "Train Epoch: 6\t Loss: 1.073009\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8695, Accuracy: 620/1018 (61%)\n",
      "\n",
      "current best acc:  64.24361493123772\n",
      "-----------------------\n",
      "Train Epoch: 7\t Loss: 0.962947\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8185, Accuracy: 656/1018 (64%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 8\t Loss: 0.878646\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7545, Accuracy: 630/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 9\t Loss: 1.633870\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8534, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 10\t Loss: 1.712154\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8568, Accuracy: 640/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 11\t Loss: 0.743562\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9206, Accuracy: 637/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 12\t Loss: 1.403318\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8346, Accuracy: 634/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 13\t Loss: 1.482018\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8682, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 14\t Loss: 0.840547\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8597, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 15\t Loss: 2.143800\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8074, Accuracy: 650/1018 (64%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 16\t Loss: 1.415954\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8420, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 17\t Loss: 1.375839\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9145, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 18\t Loss: 0.979692\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8400, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 19\t Loss: 1.487416\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9458, Accuracy: 620/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 20\t Loss: 1.432016\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9087, Accuracy: 640/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 21\t Loss: 0.720066\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8441, Accuracy: 642/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 22\t Loss: 0.893668\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8226, Accuracy: 630/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 23\t Loss: 2.211385\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8363, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 24\t Loss: 1.015401\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9243, Accuracy: 619/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 25\t Loss: 1.093753\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8227, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 26\t Loss: 1.633794\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8927, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 27\t Loss: 1.200754\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9661, Accuracy: 620/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 28\t Loss: 1.584421\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8962, Accuracy: 633/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 29\t Loss: 0.673675\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8760, Accuracy: 651/1018 (64%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 30\t Loss: 1.122516\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8813, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 31\t Loss: 1.520181\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8781, Accuracy: 646/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 32\t Loss: 0.554630\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8760, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 33\t Loss: 0.657301\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8312, Accuracy: 636/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 34\t Loss: 1.321880\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8561, Accuracy: 637/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 35\t Loss: 1.058764\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7239, Accuracy: 639/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 36\t Loss: 1.708472\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9483, Accuracy: 611/1018 (60%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 37\t Loss: 1.262165\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9049, Accuracy: 617/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 38\t Loss: 0.972279\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9233, Accuracy: 624/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 39\t Loss: 1.525621\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8712, Accuracy: 633/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 40\t Loss: 1.318452\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8520, Accuracy: 656/1018 (64%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 41\t Loss: 0.607389\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7571, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 42\t Loss: 1.270043\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8821, Accuracy: 630/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 43\t Loss: 1.774182\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8451, Accuracy: 640/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 44\t Loss: 1.731498\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8743, Accuracy: 639/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 45\t Loss: 0.624931\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8817, Accuracy: 620/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 46\t Loss: 1.121072\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8535, Accuracy: 616/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 47\t Loss: 1.102063\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8694, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 48\t Loss: 0.720708\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8677, Accuracy: 633/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 49\t Loss: 0.957075\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9407, Accuracy: 630/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 50\t Loss: 0.958446\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8926, Accuracy: 651/1018 (64%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 51\t Loss: 1.033620\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8751, Accuracy: 621/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 52\t Loss: 0.872102\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9022, Accuracy: 625/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 53\t Loss: 1.148678\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9504, Accuracy: 629/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 54\t Loss: 1.854394\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8660, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 55\t Loss: 0.801446\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9212, Accuracy: 618/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 56\t Loss: 0.991275\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8842, Accuracy: 633/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 57\t Loss: 0.877420\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8775, Accuracy: 617/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 58\t Loss: 0.769791\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8869, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 59\t Loss: 1.243340\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9484, Accuracy: 626/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 60\t Loss: 1.024892\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8017, Accuracy: 639/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 61\t Loss: 2.817679\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8366, Accuracy: 653/1018 (64%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 62\t Loss: 1.053721\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8733, Accuracy: 646/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 63\t Loss: 0.978902\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8661, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 64\t Loss: 1.118672\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8581, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 65\t Loss: 1.511941\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9380, Accuracy: 637/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 66\t Loss: 1.085591\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9080, Accuracy: 612/1018 (60%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 67\t Loss: 0.929310\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8543, Accuracy: 647/1018 (64%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 68\t Loss: 1.461254\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8184, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 69\t Loss: 1.404560\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9058, Accuracy: 647/1018 (64%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 70\t Loss: 0.853841\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8900, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 71\t Loss: 0.678034\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8226, Accuracy: 642/1018 (63%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 72\t Loss: 1.015615\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8448, Accuracy: 635/1018 (62%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 73\t Loss: 0.922233\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8962, Accuracy: 623/1018 (61%)\n",
      "\n",
      "current best acc:  64.44007858546169\n",
      "-----------------------\n",
      "Train Epoch: 74\t Loss: 1.167606\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8946, Accuracy: 657/1018 (65%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 75\t Loss: 1.396414\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8630, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 76\t Loss: 1.730169\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8732, Accuracy: 618/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 77\t Loss: 1.661869\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8204, Accuracy: 647/1018 (64%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 78\t Loss: 1.507109\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9267, Accuracy: 633/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 79\t Loss: 1.416701\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8615, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 80\t Loss: 1.352801\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8764, Accuracy: 640/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 81\t Loss: 1.801938\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8877, Accuracy: 634/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 82\t Loss: 1.641993\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9037, Accuracy: 637/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 83\t Loss: 1.291614\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8219, Accuracy: 647/1018 (64%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 84\t Loss: 2.144521\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8663, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 85\t Loss: 0.822563\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9394, Accuracy: 622/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 86\t Loss: 1.141210\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8344, Accuracy: 627/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 87\t Loss: 1.369867\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8976, Accuracy: 634/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 88\t Loss: 1.771964\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8764, Accuracy: 614/1018 (60%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 89\t Loss: 1.283044\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9454, Accuracy: 608/1018 (60%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 90\t Loss: 1.989839\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9184, Accuracy: 625/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 91\t Loss: 0.703950\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9055, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 92\t Loss: 1.424214\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8295, Accuracy: 632/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 93\t Loss: 1.119435\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9235, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 94\t Loss: 2.102878\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8551, Accuracy: 634/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 95\t Loss: 1.662405\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8161, Accuracy: 623/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 96\t Loss: 1.166049\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8328, Accuracy: 627/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 97\t Loss: 1.633557\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8530, Accuracy: 624/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 98\t Loss: 1.096426\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9551, Accuracy: 627/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 99\t Loss: 1.484376\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8422, Accuracy: 629/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 100\t Loss: 2.219684\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7979, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 101\t Loss: 0.762609\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8956, Accuracy: 621/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 102\t Loss: 1.533947\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9336, Accuracy: 625/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 103\t Loss: 0.827607\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7994, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 104\t Loss: 0.699538\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8991, Accuracy: 613/1018 (60%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 105\t Loss: 0.878954\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8796, Accuracy: 635/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 106\t Loss: 1.031056\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8478, Accuracy: 642/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 107\t Loss: 0.617077\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9179, Accuracy: 618/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 108\t Loss: 1.016653\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8775, Accuracy: 640/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 109\t Loss: 1.686847\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8959, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 110\t Loss: 0.769294\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8717, Accuracy: 634/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 111\t Loss: 0.636922\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8488, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 112\t Loss: 0.580493\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8278, Accuracy: 646/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 113\t Loss: 1.098886\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8263, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 114\t Loss: 1.249960\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8265, Accuracy: 635/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 115\t Loss: 1.512882\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8014, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 116\t Loss: 0.922136\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8187, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 117\t Loss: 2.378013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8863, Accuracy: 627/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 118\t Loss: 0.671021\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8245, Accuracy: 642/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 119\t Loss: 1.732044\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8861, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 120\t Loss: 1.419921\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7566, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 121\t Loss: 0.791061\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8091, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 122\t Loss: 1.453999\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8618, Accuracy: 635/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 123\t Loss: 0.882976\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8777, Accuracy: 629/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 124\t Loss: 0.911694\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7986, Accuracy: 639/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 125\t Loss: 1.501959\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8504, Accuracy: 647/1018 (64%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 126\t Loss: 0.979490\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8778, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 127\t Loss: 1.108152\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8780, Accuracy: 619/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 128\t Loss: 1.357414\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9142, Accuracy: 621/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 129\t Loss: 1.028636\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8252, Accuracy: 632/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 130\t Loss: 0.833524\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8748, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 131\t Loss: 0.456359\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8600, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 132\t Loss: 0.982830\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8709, Accuracy: 627/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 133\t Loss: 1.185749\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9060, Accuracy: 626/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 134\t Loss: 2.401310\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8818, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 135\t Loss: 0.824266\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8520, Accuracy: 640/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 136\t Loss: 1.163385\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8161, Accuracy: 613/1018 (60%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 137\t Loss: 1.354843\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8195, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 138\t Loss: 1.384222\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7481, Accuracy: 635/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 139\t Loss: 0.834567\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9125, Accuracy: 616/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 140\t Loss: 1.913033\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8099, Accuracy: 640/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 141\t Loss: 1.245880\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8550, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 142\t Loss: 1.391686\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8030, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 143\t Loss: 1.670763\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8304, Accuracy: 632/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 144\t Loss: 1.209724\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7854, Accuracy: 653/1018 (64%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 145\t Loss: 1.633279\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8001, Accuracy: 640/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 146\t Loss: 1.078266\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8474, Accuracy: 651/1018 (64%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 147\t Loss: 2.266663\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8347, Accuracy: 645/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 148\t Loss: 0.618058\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8430, Accuracy: 645/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 149\t Loss: 1.272754\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8770, Accuracy: 623/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 150\t Loss: 3.062968\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8040, Accuracy: 639/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 151\t Loss: 1.614994\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8630, Accuracy: 640/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 152\t Loss: 1.934071\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8186, Accuracy: 646/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 153\t Loss: 1.152364\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8397, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 154\t Loss: 0.904538\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8337, Accuracy: 637/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 155\t Loss: 0.517973\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8039, Accuracy: 650/1018 (64%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 156\t Loss: 1.120636\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8001, Accuracy: 649/1018 (64%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 157\t Loss: 1.536900\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8307, Accuracy: 621/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 158\t Loss: 1.539714\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8164, Accuracy: 637/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 159\t Loss: 1.918464\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8732, Accuracy: 623/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 160\t Loss: 1.019070\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8994, Accuracy: 653/1018 (64%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 161\t Loss: 1.295317\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.8373, Accuracy: 631/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 162\t Loss: 0.992162\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8734, Accuracy: 630/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 163\t Loss: 1.918590\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8055, Accuracy: 645/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 164\t Loss: 1.420939\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8091, Accuracy: 635/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 165\t Loss: 1.307592\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8475, Accuracy: 623/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 166\t Loss: 0.783475\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8334, Accuracy: 647/1018 (64%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 167\t Loss: 1.276594\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8661, Accuracy: 620/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 168\t Loss: 0.951476\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8417, Accuracy: 610/1018 (60%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 169\t Loss: 1.725435\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8391, Accuracy: 616/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 170\t Loss: 1.370013\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8323, Accuracy: 626/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 171\t Loss: 1.292665\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7906, Accuracy: 635/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 172\t Loss: 1.568715\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8696, Accuracy: 633/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 173\t Loss: 1.086620\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8378, Accuracy: 637/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 174\t Loss: 1.321655\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8088, Accuracy: 630/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 175\t Loss: 1.976585\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8188, Accuracy: 651/1018 (64%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 176\t Loss: 0.892195\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8641, Accuracy: 621/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 177\t Loss: 1.398727\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8077, Accuracy: 651/1018 (64%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 178\t Loss: 1.400492\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8913, Accuracy: 637/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 179\t Loss: 1.750925\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9032, Accuracy: 633/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 180\t Loss: 0.759032\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8953, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 181\t Loss: 0.668962\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8157, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 182\t Loss: 0.771738\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8577, Accuracy: 634/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 183\t Loss: 1.383168\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8593, Accuracy: 645/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 184\t Loss: 1.244581\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9160, Accuracy: 638/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 185\t Loss: 0.654255\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8550, Accuracy: 630/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 186\t Loss: 1.686885\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8276, Accuracy: 632/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 187\t Loss: 2.223191\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8625, Accuracy: 621/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 188\t Loss: 0.940646\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8767, Accuracy: 637/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 189\t Loss: 1.108496\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8793, Accuracy: 630/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 190\t Loss: 1.503810\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8655, Accuracy: 630/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 191\t Loss: 1.020913\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8467, Accuracy: 644/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 192\t Loss: 0.870973\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.9141, Accuracy: 619/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 193\t Loss: 1.130029\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8238, Accuracy: 628/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 194\t Loss: 1.217973\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8186, Accuracy: 641/1018 (63%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 195\t Loss: 1.122117\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8266, Accuracy: 629/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 196\t Loss: 0.834572\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8806, Accuracy: 622/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 197\t Loss: 1.587188\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7571, Accuracy: 636/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 198\t Loss: 1.225277\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8472, Accuracy: 634/1018 (62%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Train Epoch: 199\t Loss: 0.808681\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.8661, Accuracy: 621/1018 (61%)\n",
      "\n",
      "current best acc:  64.53831041257368\n",
      "-----------------------\n",
      "Result: at 74 epoch, achieved best acc: 65\n"
     ]
    }
   ],
   "source": [
    "max_acc = 0\n",
    "max_epoch = 0\n",
    "max_acc = 0.6\n",
    "save_path = '/data/AlgProj/tct_yaoms/model/resnet-34_include_ascus_0722.pth'\n",
    "for epoch in range(EPOCH):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    acc = test(model, DEVICE, test_loader, optimizer)\n",
    "    if acc >= max_acc:\n",
    "        max_acc = acc\n",
    "        max_epoch = epoch\n",
    "        if os.path.exists(save_path):\n",
    "            os.remove(save_path)\n",
    "        torch.save(model, save_path)\n",
    "    print('current best acc: ', max_acc)\n",
    "    print('-----------------------')\n",
    "print('Result: at {} epoch, achieved best acc: {:.0f}'.format(max_epoch, max_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(model, test_loader, classes, DEVICE=DEVICE):\n",
    "    y_pred =[]\n",
    "    y_true = []\n",
    "    for i,data in enumerate(test_loader):\n",
    "        x, y = data\n",
    "        y = np.array(y.cpu())\n",
    "        y_true.append(y)\n",
    "\n",
    "        x = x.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        pred = y_hat.max(1, keepdim=True)[1]\n",
    "        pred = np.array(pred.cpu())\n",
    "        y_pred.append(pred)\n",
    "    \n",
    "    y_pred_list = []\n",
    "    y_true_list = []\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred_list += list(y_pred[i].ravel())\n",
    "    for i in range(len(y_true)):\n",
    "        y_true_list += list(y_true[i].ravel())\n",
    "        \n",
    "    plot_confusion_matrix(y_true_list, y_pred_list, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[ 71 123  13  27   7   8   4   0]\n",
      " [ 14 161   6  37   2   5   1   2]\n",
      " [  5  13  27   3  18   4  10   2]\n",
      " [  5  61   1  62   1   3   3   0]\n",
      " [  0  10  10   1  35   5  11   0]\n",
      " [  0   4   3   1   4  64  10   0]\n",
      " [  0   1   8   1   4   4  79   0]\n",
      " [  0   0   0   0   5   1   2  56]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = np.array(['0', '1', '2', '3', '4', '5', '6', '7'])\n",
    "error_analysis(model, test_loader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4764</th>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0513/tct_0513...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4765</th>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0513/tct_0513...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4766</th>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0513/tct_0513...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0513/tct_0513...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4768</th>\n",
       "      <td>/data/AlgProj/tct_yaoms/data/tct_0513/tct_0513...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               img_path  label\n",
       "4764  /data/AlgProj/tct_yaoms/data/tct_0513/tct_0513...      3\n",
       "4765  /data/AlgProj/tct_yaoms/data/tct_0513/tct_0513...      3\n",
       "4766  /data/AlgProj/tct_yaoms/data/tct_0513/tct_0513...      3\n",
       "4767  /data/AlgProj/tct_yaoms/data/tct_0513/tct_0513...      3\n",
       "4768  /data/AlgProj/tct_yaoms/data/tct_0513/tct_0513...      3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    2752\n",
       "6     480\n",
       "5     445\n",
       "2     426\n",
       "4     366\n",
       "7     300\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 23 14:13:46 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.37                 Driver Version: 396.37                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   25C    P8     8W / 250W |  10783MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 34%   59C    P2    79W / 250W |   8597MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 35%   61C    P2    70W / 250W |   6212MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 44%   76C    P2   226W / 250W |  10783MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 45%   76C    P2   247W / 250W |  11042MiB / 11178MiB |     76%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 36%   61C    P2    75W / 250W |   6039MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 23%   30C    P8    16W / 250W |  10753MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 23%   32C    P8    16W / 250W |  10757MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     37636      C   /opt/anaconda2/bin/python                  10773MiB |\n",
      "|    1     42602      C   python                                      8587MiB |\n",
      "|    2      9979      C   ...ms/anaconda3/envs/PytorchEnv/bin/python  2313MiB |\n",
      "|    2     32820      C   /opt/anaconda2/envs/py3.6/bin/python        3889MiB |\n",
      "|    3     17664      C   /opt/anaconda2/bin/python                  10773MiB |\n",
      "|    4     30646      C   ...ms/anaconda3/envs/PytorchEnv/bin/python  2061MiB |\n",
      "|    4     45652      C   /opt/anaconda2/bin/python                   8971MiB |\n",
      "|    5     34017      C   /opt/anaconda2/bin/python                   6029MiB |\n",
      "|    6     16015      C   /opt/anaconda2/bin/python                  10743MiB |\n",
      "|    7      6125      C   /opt/anaconda2/bin/python                  10743MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
