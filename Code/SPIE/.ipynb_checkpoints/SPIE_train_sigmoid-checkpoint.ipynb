{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch.utils.data as data\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pred import predprob\n",
    "from skimage import io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "paths = sys.path\n",
    "sys.path.append('/home/yuyue/yuyue/Synchronized-BatchNorm-PyTorch-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "#         RandomCrop((512, 512)),\n",
    "        transforms.RandomHorizontalFlip(),   # horizontal flip\n",
    "        transforms.RandomVerticalFlip(),   # vertival flip\n",
    "        transforms.ColorJitter(0.2,0.2,0.2,0.04),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # mean, std\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/data/Pathology/SPIE/training_set/breastpathq/datasets/train_labels.csv') \n",
    "df_val = pd.read_csv('/data/Pathology/SPIE/training_set/breastpathq/datasets/val_labels.csv') \n",
    "df = df_train.append(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide</th>\n",
       "      <th>rid</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99861</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99861</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99861</td>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99861</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99861</td>\n",
       "      <td>5</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slide  rid     y\n",
       "0  99861    1  0.40\n",
       "1  99861    2  0.40\n",
       "2  99861    3  0.15\n",
       "3  99861    4  0.10\n",
       "4  99861    5  0.07"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(paths, extension, df):\n",
    "    images = []\n",
    "    for p in paths:\n",
    "        if ('.'+extension) in p:\n",
    "            slide = p.split('/')[-1].split('_')[0]\n",
    "            slide = int(slide)\n",
    "            rid = p.split('/')[-1].split('_')[1].split('.')[0]\n",
    "            rid = int(rid)\n",
    "            score = df[(df['slide']==slide) & (df['rid']==rid)]['y'].tolist()[0]\n",
    "           #if score != 0:\n",
    "            #print(p,float(score))\n",
    "            images.append([p, float(score)])\n",
    "    shuffle(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPIE_dataset(data.Dataset):\n",
    "    def __init__(self, dirs, loader, extension, transform=None, train=True):\n",
    "        self.samples = make_dataset(dirs, extension, df)\n",
    "        if len(self.samples) == 0:\n",
    "            raise(RuntimeError(\"no files in %s\" % dirs))\n",
    "        self.loader = loader\n",
    "        self.transform = transform\n",
    "        self.train=train\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        sample = Image.fromarray(sample)\n",
    "        #target = torch.tensor(target).long()\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        if self.train:\n",
    "            return sample, target\n",
    "        else:\n",
    "            return sample, target, path\n",
    "        #print('target:',target)\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = glob(\"/data/Pathology/SPIE/training_set/breastpathq/datasets/train/*.tif\")\n",
    "val_samples = glob(\"/data/Pathology/SPIE/training_set/breastpathq/datasets/validation/*.tif\")\n",
    "#test_samples = torch.load( '/data/AlgProj/ydx/ydx/zhongshan/datapath/20190410_4_cls/test_444.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SPIE_dataset(train_samples, io.imread, 'tif', transform=data_transforms['train'])\n",
    "val_dataset = SPIE_dataset(val_samples, io.imread, 'tif', transform=data_transforms['val'])\n",
    "#test_dataset = Rose_dataset(test_samples, Image.open, 'jpg', transform=data_transforms['test'], train=False)\n",
    "image_datasets = {'train':train_dataset, 'val':val_dataset}\n",
    "dataloaders = {\"train\": torch.utils.data.DataLoader(image_datasets[\"train\"], batch_size=64,\n",
    "                                             shuffle=True, num_workers=16),\n",
    "               \"val\": torch.utils.data.DataLoader(image_datasets[\"val\"], batch_size=16,\n",
    "                                             shuffle=True, num_workers=4)}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, epoch):\n",
    "    save_dir = \"/data/yuyue/SPIE/model_weight/\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    state_dict = model.module.state_dict()\n",
    "    pth = os.path.join(save_dir, \"densenet121_256_0626_sigmoid.pth\")\n",
    "    torch.save(state_dict, pth)\n",
    "\n",
    "def train_model(model, criterion1,criterion2, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    model = DataParallel(model)\n",
    "   # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100.0\n",
    "    best_epoch = 0\n",
    "              \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            epoch_labels = []\n",
    "            epoch_outputs = []\n",
    "            # Iterate over data.\n",
    "#             count  = 0\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                #print('labels.type=',labels.type())\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                outputs = nn.Sigmoid()(outputs[:,0])\n",
    "                #outputs = outputs.unsqueeze(1)\n",
    "                #print(outputs.shape)\n",
    "                outputs_normalize = nn.Softmax(dim=0)(outputs)\n",
    "                label_normalize = nn.Softmax(dim=0)(labels)\n",
    "                log_outputs_normalize = torch.log(outputs_normalize)\n",
    "                \n",
    "                \n",
    "#                 labels_KL = torch.zeros((len(labels),2))\n",
    "#                 labels_KL[:,0] = labels\n",
    "#                 labels_KL[:,1] = 1-labels\n",
    "                \n",
    "                # _, preds = torch.max(outputs.data, 1) # pred值为output中最大值的位置（0是neg,1是pos）\n",
    "                labels = labels.float()                \n",
    "\n",
    "                loss1 = criterion1(outputs, labels)\n",
    "                loss2 = criterion2(log_outputs_normalize, label_normalize.float())\n",
    "                \n",
    "                loss = loss1+10*loss2\n",
    "                #print(\"outputs=\",outputs)\n",
    "                #print(\"labels=\",labels)\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                for n in range(len(labels)):\n",
    "                    #print(labels[n].data.cpu().item())\n",
    "                    pred_value = outputs[n].data.cpu().item()\n",
    "                    epoch_labels.append(labels[n].data.cpu().item())\n",
    "                    epoch_outputs.append(pred_value)\n",
    "                #print(epoch_labels)\n",
    "                # statistics\n",
    "                running_loss += loss.item()* inputs.size(0)\n",
    "                #running_corrects += torch.sum(preds == labels.data)\n",
    "#                 count += 1\n",
    "#                 if count%100 == 0:\n",
    "#                     print(\"batch %d:\" % count)\n",
    "#                     print(phase+\"_loss:\", loss.data[0])\n",
    "#                     print(phase+\"_acc:\", torch.sum(preds == labels.data)/len(labels.data))\n",
    "\n",
    "            p_k = predprob(np.array(epoch_labels),np.array(epoch_outputs))\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            #epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f}'.format(\n",
    "                phase, epoch_loss))\n",
    "            print('p_k = ',p_k)\n",
    "#             if phase == \"train\":\n",
    "#                 save_model(model, epoch)\n",
    "\n",
    "#             # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_epoch = epoch\n",
    "                save_model(model, epoch)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('Best val epoch: {:4f}'.format(best_epoch))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import DataParallel\n",
    "from densenet import densenet121\n",
    "model_ft = densenet121(pretrained=True)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, 1)\n",
    "#model_ft.add_module(\"sigmoid\", module=nn.Sigmoid())\n",
    "from sync_batchnorm import convert_model\n",
    "model_ft = convert_model(model_ft)\n",
    "\n",
    "# load pretrained model\n",
    "model_ft.load_state_dict(torch.load(\"/data/yuyue/SPIE/model_weight/densenet121_256_0626_sigmoid.pth\"))\n",
    "# print(\"pretrained model loaded\")\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.KLDivLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "# do not forget to change learning rate\n",
    "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9,weight_decay=1e-3)\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=1e-4,weight_decay=1e-4)\n",
    "# Decay LR by a factor of 0.1 every 5 epochs\n",
    "exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=10, eta_min=0, last_epoch=-1)\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.0099\n",
      "p_k =  0.9358456052498232\n",
      "val Loss: 0.0279\n",
      "p_k =  0.8774903548162671\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.0077\n",
      "p_k =  0.9466930538364152\n",
      "val Loss: 0.0317\n",
      "p_k =  0.8678135475302005\n",
      "Epoch 2/29\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion1,criterion2, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
