{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch.utils.data as data\n",
    "from glob import glob\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pred import predprob\n",
    "from skimage import io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "paths = sys.path\n",
    "sys.path.append('/home/yuyue/yuyue/Synchronized-BatchNorm-PyTorch-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "#         RandomCrop((512, 512)),\n",
    "        transforms.RandomHorizontalFlip(),   # horizontal flip\n",
    "        transforms.RandomVerticalFlip(),   # vertival flip\n",
    "        transforms.ColorJitter(0.2,0.2,0.2,0.04),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # mean, std\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/data/Pathology/SPIE/training_set/breastpathq/datasets/train_labels.csv') \n",
    "df_val = pd.read_csv('/data/Pathology/SPIE/training_set/breastpathq/datasets/val_labels.csv') \n",
    "df = df_train.append(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide</th>\n",
       "      <th>rid</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99861</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99861</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99861</td>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99861</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99861</td>\n",
       "      <td>5</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slide  rid     y\n",
       "0  99861    1  0.40\n",
       "1  99861    2  0.40\n",
       "2  99861    3  0.15\n",
       "3  99861    4  0.10\n",
       "4  99861    5  0.07"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_dataset(paths, extension, df):\n",
    "    images = []\n",
    "    for p in paths:\n",
    "        if ('.'+extension) in p:\n",
    "            slide = p.split('/')[-1].split('_')[0]\n",
    "            slide = int(slide)\n",
    "            rid = p.split('/')[-1].split('_')[1].split('.')[0]\n",
    "            rid = int(rid)\n",
    "            score = df[(df['slide']==slide) & (df['rid']==rid)]['y'].tolist()[0]\n",
    "           #if score != 0:\n",
    "            #print(p,float(score))\n",
    "            images.append([p, float(score)])\n",
    "    shuffle(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SPIE_dataset(data.Dataset):\n",
    "    def __init__(self, dirs, loader, extension, transform=None, train=True):\n",
    "        self.samples = make_dataset(dirs, extension, df)\n",
    "        if len(self.samples) == 0:\n",
    "            raise(RuntimeError(\"no files in %s\" % dirs))\n",
    "        self.loader = loader\n",
    "        self.transform = transform\n",
    "        self.train=train\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        sample = Image.fromarray(sample)\n",
    "        #target = torch.tensor(target).long()\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        if self.train:\n",
    "            return sample, target\n",
    "        else:\n",
    "            return sample, target, path\n",
    "        #print('target:',target)\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_samples = glob(\"/data/Pathology/SPIE/training_set/breastpathq/datasets/train/*.tif\")\n",
    "val_samples = glob(\"/data/Pathology/SPIE/training_set/breastpathq/datasets/validation/*.tif\")\n",
    "#test_samples = torch.load( '/data/AlgProj/ydx/ydx/zhongshan/datapath/20190410_4_cls/test_444.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SPIE_dataset(train_samples, io.imread, 'tif', transform=data_transforms['train'])\n",
    "val_dataset = SPIE_dataset(val_samples, io.imread, 'tif', transform=data_transforms['val'])\n",
    "#test_dataset = Rose_dataset(test_samples, Image.open, 'jpg', transform=data_transforms['test'], train=False)\n",
    "image_datasets = {'train':train_dataset, 'val':val_dataset}\n",
    "dataloaders = {\"train\": torch.utils.data.DataLoader(image_datasets[\"train\"], batch_size=32,\n",
    "                                             shuffle=True, num_workers=16),\n",
    "               \"val\": torch.utils.data.DataLoader(image_datasets[\"val\"], batch_size=8,\n",
    "                                             shuffle=True, num_workers=4)}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, epoch):\n",
    "    save_dir = \"/data/yuyue/SPIE/model_weight/\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    state_dict = model.module.state_dict()\n",
    "    pth = os.path.join(save_dir, \"densenet169_512_0625_cosine_stage2.pth\")\n",
    "    torch.save(state_dict, pth)\n",
    "\n",
    "def train_model(model, criterion1,criterion2, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    model = DataParallel(model)\n",
    "   # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100.0\n",
    "    best_epoch = 0\n",
    "              \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)  # Set model to training mode\n",
    "            else:\n",
    "                model.train(False)  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            epoch_labels = []\n",
    "            epoch_outputs = []\n",
    "            # Iterate over data.\n",
    "#             count  = 0\n",
    "            for data in dataloaders[phase]:\n",
    "                # get the inputs\n",
    "                inputs, labels = data\n",
    "                #print('labels.type=',labels.type())\n",
    "                # wrap them in Variable\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # forward\n",
    "                outputs = model(inputs)\n",
    "                outputs = nn.Softmax(dim=1)(outputs)\n",
    "                \n",
    "                # print(outputs.shape)\n",
    "                outputs_normalize = nn.Softmax(dim=0)(outputs[:,0])\n",
    "                label_normalize = nn.Softmax(dim=0)(labels)\n",
    "                log_outputs_normalize = torch.log(outputs_normalize)\n",
    "                \n",
    "                \n",
    "                labels_KL = torch.zeros((len(labels),2))\n",
    "                labels_KL[:,0] = labels\n",
    "                labels_KL[:,1] = 1-labels\n",
    "                \n",
    "                # _, preds = torch.max(outputs.data, 1) # pred值为output中最大值的位置（0是neg,1是pos）\n",
    "                labels = labels.float()                \n",
    "\n",
    "                loss1 = criterion1(outputs, labels_KL.cuda())\n",
    "                loss2 = criterion2(log_outputs_normalize, label_normalize.float())\n",
    "                \n",
    "                loss = loss1+10*loss2\n",
    "                #print(\"outputs=\",outputs)\n",
    "                #print(\"labels=\",labels)\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                for n in range(len(labels)):\n",
    "                    #print(labels[n].data.cpu().item())\n",
    "                    pred_value = outputs[n][0].data.cpu().item()\n",
    "                    epoch_labels.append(labels[n].data.cpu().item())\n",
    "                    epoch_outputs.append(pred_value)\n",
    "                #print(epoch_labels)\n",
    "                # statistics\n",
    "                running_loss += loss.item()* inputs.size(0)\n",
    "                #running_corrects += torch.sum(preds == labels.data)\n",
    "#                 count += 1\n",
    "#                 if count%100 == 0:\n",
    "#                     print(\"batch %d:\" % count)\n",
    "#                     print(phase+\"_loss:\", loss.data[0])\n",
    "#                     print(phase+\"_acc:\", torch.sum(preds == labels.data)/len(labels.data))\n",
    "\n",
    "            p_k = predprob(np.array(epoch_labels),np.array(epoch_outputs))\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            #epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f}'.format(\n",
    "                phase, epoch_loss))\n",
    "            print('p_k = ',p_k)\n",
    "#             if phase == \"train\":\n",
    "#                 save_model(model, epoch)\n",
    "\n",
    "#             # deep copy the model\n",
    "#             if phase == 'val' and epoch_acc > best_acc:\n",
    "#                 best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_epoch = epoch\n",
    "                save_model(model, epoch)\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('Best val epoch: {:4f}'.format(best_epoch))\n",
    "\n",
    "    # load best model weights\n",
    "#     model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import DataParallel\n",
    "from densenet import densenet169\n",
    "model_ft = densenet169(pretrained=True)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "#model_ft.add_module(\"sigmoid\", module=nn.Sigmoid())\n",
    "from sync_batchnorm import convert_model\n",
    "model_ft = convert_model(model_ft)\n",
    "\n",
    "# load pretrained model\n",
    "model_ft.load_state_dict(torch.load(\"/data/yuyue/SPIE/model_weight/densenet169_512_0625_cosine.pth\"))\n",
    "# print(\"pretrained model loaded\")\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.KLDivLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "# do not forget to change learning rate\n",
    "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9,weight_decay=1e-3)\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=1e-5,weight_decay=1e-4)\n",
    "# Decay LR by a factor of 0.1 every 5 epochs\n",
    "exp_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_ft, T_max=10, eta_min=0, last_epoch=-1)\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/torch/nn/functional.py:1906: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0061\n",
      "p_k =  0.9555336185406734\n",
      "val Loss: 0.0289\n",
      "p_k =  0.8972234520270698\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.0061\n",
      "p_k =  0.9583960852233417\n",
      "val Loss: 0.0439\n",
      "p_k =  0.8701536904686611\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.0052\n",
      "p_k =  0.9620731498781829\n",
      "val Loss: 0.0373\n",
      "p_k =  0.8786288027322751\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.0054\n",
      "p_k =  0.9606673114423365\n",
      "val Loss: 0.0260\n",
      "p_k =  0.9019669850104357\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.0052\n",
      "p_k =  0.9610589224559207\n",
      "val Loss: 0.0332\n",
      "p_k =  0.890203023211688\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.0050\n",
      "p_k =  0.9622919970945876\n",
      "val Loss: 0.0368\n",
      "p_k =  0.8836885712478655\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0050\n",
      "p_k =  0.9633827033827975\n",
      "val Loss: 0.0359\n",
      "p_k =  0.8867244323572196\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0051\n",
      "p_k =  0.9635999818019518\n",
      "val Loss: 0.0362\n",
      "p_k =  0.883372335715641\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0053\n",
      "p_k =  0.963020703417311\n",
      "val Loss: 0.0378\n",
      "p_k =  0.8797672506482828\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0052\n",
      "p_k =  0.9629010826269824\n",
      "val Loss: 0.0347\n",
      "p_k =  0.887040667889444\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0048\n",
      "p_k =  0.9635564476782585\n",
      "val Loss: 0.0435\n",
      "p_k =  0.8661058756561888\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0048\n",
      "p_k =  0.9639313902210592\n",
      "val Loss: 0.0437\n",
      "p_k =  0.8666750996141926\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0050\n",
      "p_k =  0.9637160727984676\n",
      "val Loss: 0.0433\n",
      "p_k =  0.8694579722977673\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0048\n",
      "p_k =  0.9653825276775054\n",
      "val Loss: 0.0405\n",
      "p_k =  0.8747707292391373\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0049\n",
      "p_k =  0.9637046990184035\n",
      "val Loss: 0.0421\n",
      "p_k =  0.8684460185946493\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0046\n",
      "p_k =  0.9654099816293842\n",
      "val Loss: 0.0467\n",
      "p_k =  0.8613623426728227\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0045\n",
      "p_k =  0.965533916612151\n",
      "val Loss: 0.0388\n",
      "p_k =  0.8745809879198027\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0047\n",
      "p_k =  0.9647961897052386\n",
      "val Loss: 0.0368\n",
      "p_k =  0.879134779583834\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0047\n",
      "p_k =  0.9649120846020981\n",
      "val Loss: 0.0466\n",
      "p_k =  0.863323002972614\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0048\n",
      "p_k =  0.9637815700836639\n",
      "val Loss: 0.0405\n",
      "p_k =  0.8699007020428815\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0045\n",
      "p_k =  0.9655786273337821\n",
      "val Loss: 0.0451\n",
      "p_k =  0.8646511922079565\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0049\n",
      "p_k =  0.9643212363377369\n",
      "val Loss: 0.0487\n",
      "p_k =  0.8591486939472519\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0046\n",
      "p_k =  0.9650283716982702\n",
      "val Loss: 0.0372\n",
      "p_k =  0.8738220226424641\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0051\n",
      "p_k =  0.9643953620078094\n",
      "val Loss: 0.0371\n",
      "p_k =  0.8745809879198027\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0043\n",
      "p_k =  0.9666356044811124\n",
      "val Loss: 0.0405\n",
      "p_k =  0.8697742078299917\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0044\n",
      "p_k =  0.9662606619383117\n",
      "val Loss: 0.0440\n",
      "p_k =  0.8668648409335273\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0041\n",
      "p_k =  0.9676666964738144\n",
      "val Loss: 0.0412\n",
      "p_k =  0.8700271962557713\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0042\n",
      "p_k =  0.9673717625907745\n",
      "val Loss: 0.0491\n",
      "p_k =  0.8608563658212637\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0043\n",
      "p_k =  0.9663496911822613\n",
      "val Loss: 0.0432\n",
      "p_k =  0.8668015938270823\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0042\n",
      "p_k =  0.9682738210096465\n",
      "val Loss: 0.0433\n",
      "p_k =  0.8663588640819683\n",
      "Training complete in 50m 45s\n",
      "Best val epoch: 3.000000\n"
     ]
    }
   ],
   "source": [
    "model_ft = train_model(model_ft, criterion1,criterion2, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def infer(model, use_gpu=True):\n",
    "    model.train(False)\n",
    "    running_labels = []\n",
    "    running_outputs = []\n",
    "    running_paths = []\n",
    "    for data in dataloaders['val']:\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "        #print(\"labels=\",labels)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        outputs = nn.Sigmoid()(outputs)\n",
    "        #print(\"outputs=\",outputs)\n",
    "#         probs, preds = torch.max(outputs.data, 1)\n",
    "        outputs = list(outputs.cpu().data.numpy())\n",
    "        labels = list(labels.cpu().data.numpy())\n",
    "        #paths = list(paths)\n",
    "        running_labels += labels\n",
    "        running_outputs += outputs\n",
    "        running_paths += paths\n",
    "        \n",
    "    return np.array(running_outputs), np.array(running_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "from densenet import densenet169\n",
    "model_infer = densenet169(pretrained=False)\n",
    "num_ftrs = model_infer.classifier.in_features\n",
    "model_infer.classifier = nn.Linear(num_ftrs, 2)\n",
    "#model_infer.add_module(\"sigmoid\", module=nn.Sigmoid())\n",
    "from sync_batchnorm import convert_model\n",
    "model_infer = convert_model(model_infer)\n",
    "model_infer.load_state_dict(torch.load('/data/yuyue/SPIE/model_weight/densenet169_512_0625_cosine.pth'))\n",
    "print(\"model loaded\")\n",
    "model = model_infer.cuda()\n",
    "model_infer.eval()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    model_infer = model_infer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs, labels = infer(model_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08737666, 0.9717301 ],\n",
       "       [0.5018973 , 0.5456253 ],\n",
       "       [0.46613047, 0.57655185],\n",
       "       [0.43398836, 0.5995543 ],\n",
       "       [0.26693392, 0.7436324 ],\n",
       "       [0.59045875, 0.4616059 ],\n",
       "       [0.39582422, 0.6377699 ],\n",
       "       [0.58409834, 0.46619937],\n",
       "       [0.5177472 , 0.5235158 ],\n",
       "       [0.4744006 , 0.57134223],\n",
       "       [0.4526722 , 0.5737431 ],\n",
       "       [0.29722965, 0.7211711 ],\n",
       "       [0.2832683 , 0.75427204],\n",
       "       [0.20744741, 0.81327325],\n",
       "       [0.31640187, 0.7140181 ],\n",
       "       [0.45058283, 0.5920787 ],\n",
       "       [0.49940228, 0.54769415],\n",
       "       [0.6863106 , 0.37225145],\n",
       "       [0.46591762, 0.57458323],\n",
       "       [0.7555738 , 0.29080614],\n",
       "       [0.8396333 , 0.2084296 ],\n",
       "       [0.47425613, 0.5688702 ],\n",
       "       [0.5310754 , 0.52051204],\n",
       "       [0.20148595, 0.80494434],\n",
       "       [0.46299163, 0.57899636],\n",
       "       [0.29405844, 0.74812305],\n",
       "       [0.65638644, 0.39570048],\n",
       "       [0.43461722, 0.63963205],\n",
       "       [0.5782485 , 0.46150598],\n",
       "       [0.59195423, 0.4629021 ],\n",
       "       [0.4532148 , 0.5833315 ],\n",
       "       [0.13345091, 0.9111461 ],\n",
       "       [0.30415374, 0.7266849 ],\n",
       "       [0.42036495, 0.65152586],\n",
       "       [0.49901512, 0.54421186],\n",
       "       [0.3100401 , 0.71307385],\n",
       "       [0.52177423, 0.51525277],\n",
       "       [0.5134102 , 0.549947  ],\n",
       "       [0.21311758, 0.82450426],\n",
       "       [0.79925364, 0.24977882],\n",
       "       [0.7889259 , 0.2606739 ],\n",
       "       [0.2974267 , 0.7239363 ],\n",
       "       [0.203888  , 0.8273002 ],\n",
       "       [0.48921677, 0.5500243 ],\n",
       "       [0.45423168, 0.58058625],\n",
       "       [0.27815473, 0.7314082 ],\n",
       "       [0.71783733, 0.3331961 ],\n",
       "       [0.05324798, 0.9778642 ],\n",
       "       [0.4613003 , 0.5826468 ],\n",
       "       [0.6890719 , 0.35799062],\n",
       "       [0.62692904, 0.4222338 ],\n",
       "       [0.33768725, 0.6988406 ],\n",
       "       [0.15735565, 0.8744498 ],\n",
       "       [0.65166885, 0.39822227],\n",
       "       [0.19862932, 0.826064  ],\n",
       "       [0.10981108, 0.924258  ],\n",
       "       [0.34633306, 0.68025774],\n",
       "       [0.63420653, 0.4130718 ],\n",
       "       [0.76728016, 0.2829623 ],\n",
       "       [0.41811493, 0.62668616],\n",
       "       [0.26537108, 0.7689289 ],\n",
       "       [0.10981108, 0.924258  ],\n",
       "       [0.12890925, 0.91646504],\n",
       "       [0.2655692 , 0.777215  ],\n",
       "       [0.2606938 , 0.759073  ],\n",
       "       [0.01754917, 0.99777657],\n",
       "       [0.76311904, 0.28531492],\n",
       "       [0.56299186, 0.5251801 ],\n",
       "       [0.48111492, 0.55905235],\n",
       "       [0.68785435, 0.36127278],\n",
       "       [0.5825398 , 0.46131682],\n",
       "       [0.4113367 , 0.6239462 ],\n",
       "       [0.45329213, 0.60561514],\n",
       "       [0.6524374 , 0.39703283],\n",
       "       [0.5700615 , 0.48318937],\n",
       "       [0.29843947, 0.71842283],\n",
       "       [0.70164067, 0.34678027],\n",
       "       [0.45038742, 0.6045381 ],\n",
       "       [0.26884797, 0.74940026],\n",
       "       [0.1951455 , 0.85051185],\n",
       "       [0.58419544, 0.46331862],\n",
       "       [0.34294027, 0.67999536],\n",
       "       [0.47997037, 0.5587512 ],\n",
       "       [0.17649376, 0.8417999 ],\n",
       "       [0.7427205 , 0.30920145],\n",
       "       [0.32760507, 0.7319785 ],\n",
       "       [0.67998713, 0.36532223],\n",
       "       [0.03533822, 0.9871464 ],\n",
       "       [0.3677175 , 0.66517836],\n",
       "       [0.64711577, 0.39793056],\n",
       "       [0.46814495, 0.5828987 ],\n",
       "       [0.49709475, 0.54147685],\n",
       "       [0.23999095, 0.77692187],\n",
       "       [0.25402978, 0.76153654],\n",
       "       [0.26637426, 0.7478884 ],\n",
       "       [0.21941644, 0.8260131 ],\n",
       "       [0.5999545 , 0.45073077],\n",
       "       [0.31889865, 0.72950107],\n",
       "       [0.2548292 , 0.76627177],\n",
       "       [0.15654412, 0.88294065],\n",
       "       [0.44203305, 0.6323125 ],\n",
       "       [0.50688154, 0.55262136],\n",
       "       [0.42384475, 0.6195356 ],\n",
       "       [0.34745473, 0.6792584 ],\n",
       "       [0.2681631 , 0.7745874 ],\n",
       "       [0.01025249, 0.99649197],\n",
       "       [0.2978007 , 0.7257408 ],\n",
       "       [0.42611453, 0.6090941 ],\n",
       "       [0.2780076 , 0.74001473],\n",
       "       [0.37579644, 0.66941035],\n",
       "       [0.52323323, 0.51057607],\n",
       "       [0.19087522, 0.8430517 ],\n",
       "       [0.220845  , 0.7987547 ],\n",
       "       [0.05864765, 0.97399604],\n",
       "       [0.7878169 , 0.2621519 ],\n",
       "       [0.23693503, 0.77253574],\n",
       "       [0.02681929, 0.9925424 ],\n",
       "       [0.6279982 , 0.42133203],\n",
       "       [0.6593086 , 0.38068685],\n",
       "       [0.4745592 , 0.56084675],\n",
       "       [0.2644913 , 0.7447164 ],\n",
       "       [0.35326618, 0.67334276],\n",
       "       [0.19900247, 0.82383513],\n",
       "       [0.16773224, 0.8833565 ],\n",
       "       [0.4994552 , 0.5490983 ],\n",
       "       [0.17757349, 0.8455717 ],\n",
       "       [0.45114204, 0.5841977 ],\n",
       "       [0.34427148, 0.6828157 ],\n",
       "       [0.32832682, 0.7138777 ],\n",
       "       [0.4569488 , 0.5835479 ],\n",
       "       [0.64445126, 0.40626782],\n",
       "       [0.8677265 , 0.17950837],\n",
       "       [0.03825344, 0.9919007 ],\n",
       "       [0.34161898, 0.678514  ],\n",
       "       [0.5166911 , 0.5276979 ],\n",
       "       [0.27938107, 0.7648718 ],\n",
       "       [0.5449788 , 0.4933866 ],\n",
       "       [0.2926205 , 0.72798616],\n",
       "       [0.40610582, 0.6115872 ],\n",
       "       [0.43133587, 0.6062521 ],\n",
       "       [0.19201352, 0.8792219 ],\n",
       "       [0.45401818, 0.57588005],\n",
       "       [0.19009097, 0.81232136],\n",
       "       [0.02949028, 0.9848343 ],\n",
       "       [0.47859344, 0.5615179 ],\n",
       "       [0.16456273, 0.86672246],\n",
       "       [0.46153206, 0.57902527],\n",
       "       [0.33023837, 0.6948557 ],\n",
       "       [0.47568348, 0.57359844],\n",
       "       [0.7223775 , 0.33341464],\n",
       "       [0.32183787, 0.715344  ],\n",
       "       [0.6496978 , 0.39350304],\n",
       "       [0.25116464, 0.7707535 ],\n",
       "       [0.5130937 , 0.5217121 ],\n",
       "       [0.5044819 , 0.54903793],\n",
       "       [0.3021338 , 0.71608   ],\n",
       "       [0.5389655 , 0.50535125],\n",
       "       [0.7202227 , 0.33270812],\n",
       "       [0.6423254 , 0.4089866 ],\n",
       "       [0.5023709 , 0.5385611 ],\n",
       "       [0.5014874 , 0.54729974],\n",
       "       [0.29293862, 0.7238038 ],\n",
       "       [0.45681554, 0.58322906],\n",
       "       [0.10892283, 0.92680484],\n",
       "       [0.2516094 , 0.7682811 ],\n",
       "       [0.5501454 , 0.49735993],\n",
       "       [0.28960794, 0.72556293],\n",
       "       [0.2712512 , 0.74486166],\n",
       "       [0.29490316, 0.7245499 ],\n",
       "       [0.7783407 , 0.2780261 ],\n",
       "       [0.44397396, 0.6021529 ],\n",
       "       [0.03194729, 0.9869551 ],\n",
       "       [0.22010908, 0.8011664 ],\n",
       "       [0.54774773, 0.49728388],\n",
       "       [0.67709035, 0.37090954],\n",
       "       [0.36322632, 0.669105  ],\n",
       "       [0.7002997 , 0.35211793],\n",
       "       [0.23953035, 0.79264486],\n",
       "       [0.4957611 , 0.545301  ],\n",
       "       [0.3649758 , 0.660982  ],\n",
       "       [0.23524854, 0.79133576],\n",
       "       [0.37430614, 0.6473112 ],\n",
       "       [0.25480577, 0.7553327 ],\n",
       "       [0.6593086 , 0.38068685],\n",
       "       [0.20330839, 0.825723  ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.4 , 0.5 , 0.35, 0.02, 0.7 , 0.35, 0.6 , 0.55, 0.5 , 0.5 ,\n",
       "       0.05, 0.  , 0.  , 0.2 , 0.2 , 0.7 , 0.8 , 0.15, 0.8 , 0.95, 0.4 ,\n",
       "       0.7 , 0.1 , 0.4 , 0.2 , 0.8 , 0.45, 0.7 , 0.5 , 0.5 , 0.  , 0.05,\n",
       "       0.4 , 0.5 , 0.1 , 0.5 , 0.4 , 0.  , 0.9 , 0.9 , 0.2 , 0.05, 0.55,\n",
       "       0.6 , 0.02, 0.8 , 0.  , 0.2 , 0.9 , 0.7 , 0.2 , 0.  , 0.7 , 0.  ,\n",
       "       0.  , 0.2 , 0.65, 0.8 , 0.15, 0.1 , 0.  , 0.  , 0.  , 0.03, 0.  ,\n",
       "       0.9 , 0.7 , 0.5 , 0.85, 0.6 , 0.35, 0.2 , 0.65, 0.6 , 0.03, 0.8 ,\n",
       "       0.6 , 0.05, 0.  , 0.6 , 0.15, 0.5 , 0.05, 0.9 , 0.15, 0.95, 0.  ,\n",
       "       0.15, 0.9 , 0.4 , 0.2 , 0.03, 0.15, 0.1 , 0.  , 0.8 , 0.25, 0.02,\n",
       "       0.  , 0.5 , 0.5 , 0.5 , 0.4 , 0.15, 0.  , 0.15, 0.25, 0.15, 0.25,\n",
       "       0.6 , 0.  , 0.1 , 0.  , 0.95, 0.2 , 0.  , 0.65, 0.7 , 0.4 , 0.03,\n",
       "       0.4 , 0.1 , 0.  , 0.3 , 0.05, 0.3 , 0.2 , 0.15, 0.35, 0.7 , 1.  ,\n",
       "       0.  , 0.5 , 0.5 , 0.07, 0.55, 0.2 , 0.5 , 0.4 , 0.  , 0.5 , 0.02,\n",
       "       0.  , 0.5 , 0.  , 0.65, 0.1 , 0.2 , 0.7 , 0.1 , 0.7 , 0.1 , 0.5 ,\n",
       "       0.25, 0.05, 0.4 , 0.9 , 0.7 , 0.25, 0.35, 0.2 , 0.35, 0.  , 0.1 ,\n",
       "       0.5 , 0.1 , 0.1 , 0.15, 0.9 , 0.  , 0.  , 0.07, 0.6 , 0.7 , 0.15,\n",
       "       0.8 , 0.1 , 0.25, 0.35, 0.  , 0.4 , 0.2 , 0.7 , 0.  ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pred import predprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9193599392827778"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predprob(labels,outputs[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
