{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters \n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "CLASSES = 1\n",
    "EPOCH = 100\n",
    "\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_csv_path = '/data/Pathology/SPIE/training_set/breastpathq/datasets/train_labels.csv'\n",
    "test_csv_path = '/data/Pathology/SPIE/training_set/breastpathq/datasets/val_labels.csv'\n",
    "train_csv = pd.read_csv(train_csv_path)\n",
    "test_csv = pd.read_csv(test_csv_path)\n",
    "train_test_dict = {'train':train_csv, 'test': test_csv}\n",
    "len(train_test_dict['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide</th>\n",
       "      <th>rid</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99861</td>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99861</td>\n",
       "      <td>2</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99861</td>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99861</td>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99861</td>\n",
       "      <td>5</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slide  rid     y\n",
       "0  99861    1  0.40\n",
       "1  99861    2  0.40\n",
       "2  99861    3  0.15\n",
       "3  99861    4  0.10\n",
       "4  99861    5  0.07"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                 transforms.RandomRotation((-180, 180)),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.RandomResizedCrop((224,224)),  \n",
    "                                 transforms.ToTensor(),\n",
    "                                       transforms.Normalize(IMG_MEAN,IMG_STD)]\n",
    "                                )\n",
    "test_transformer = transforms.Compose([transforms.Resize((256,256)),\n",
    "                                  transforms.CenterCrop((224,224)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                      transforms.Normalize(IMG_MEAN,IMG_STD)])\n",
    "train_test_transformer = {'train':train_transformer, 'test':test_transformer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/data/Pathology/SPIE/training_set/breastpathq/datasets/train/'\n",
    "val_dir = '/data/Pathology/SPIE/training_set/breastpathq/datasets/validation/'\n",
    "\n",
    "class SPIE(Dataset):\n",
    "    def __init__(self, phase, transforms=True):\n",
    "        self.phase = phase\n",
    "        self.transforms = transforms\n",
    "        if phase == 'train':\n",
    "            self.df = train_test_dict['train']\n",
    "            self.dir =  '/data/Pathology/SPIE/training_set/breastpathq/datasets/train/'\n",
    "            self.transformer = train_test_transformer['train']\n",
    "        else:\n",
    "            self.df = train_test_dict['test']\n",
    "            self.dir = '/data/Pathology/SPIE/training_set/breastpathq/datasets/validation/'\n",
    "            self.transformer = train_test_transformer['test']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        slide = self.df.loc[idx,'slide']\n",
    "        rid = self.df.loc[idx, 'rid']\n",
    "        img_path = self.dir + str(slide)+'_'+str(rid)+'.tif'\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label = self.df.loc[idx, 'y']\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transformer(img)\n",
    "        \n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SPIE('train')\n",
    "test_dataset = SPIE('test')\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DenseNet(\n",
       "    (features): Sequential(\n",
       "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu0): ReLU(inplace)\n",
       "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (denseblock1): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition1): _Transition(\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock2): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition2): _Transition(\n",
       "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock3): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer25): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer26): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer27): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer28): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer29): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer30): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer31): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer32): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition3): _Transition(\n",
       "        (norm): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock4): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1056, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1120, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1152, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1184, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1216, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1248, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1280, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1312, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1344, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1376, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1376, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer25): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1408, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1408, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer26): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1440, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer27): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1472, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1472, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer28): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1504, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1504, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer29): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1536, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer30): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1568, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1568, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer31): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1600, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer32): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace)\n",
       "          (conv1): Conv2d(1632, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (norm5): BatchNorm2d(1664, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (classifier): Linear(in_features=1664, out_features=1, bias=True)\n",
       "  )\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import densenet169\n",
    "model = densenet169(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "fc_features = model.classifier.in_features\n",
    "model.classifier = torch.nn.Linear(fc_features, CLASSES)\n",
    "model = torch.nn.Sequential(model, torch.nn.Sigmoid())\n",
    "model.to(DEVICE)\n",
    "\n",
    "# class Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.features.conv0.weight\n",
      "0.features.norm0.weight\n",
      "0.features.norm0.bias\n",
      "0.features.denseblock1.denselayer1.norm1.weight\n",
      "0.features.denseblock1.denselayer1.norm1.bias\n",
      "0.features.denseblock1.denselayer1.conv1.weight\n",
      "0.features.denseblock1.denselayer1.norm2.weight\n",
      "0.features.denseblock1.denselayer1.norm2.bias\n",
      "0.features.denseblock1.denselayer1.conv2.weight\n",
      "0.features.denseblock1.denselayer2.norm1.weight\n",
      "0.features.denseblock1.denselayer2.norm1.bias\n",
      "0.features.denseblock1.denselayer2.conv1.weight\n",
      "0.features.denseblock1.denselayer2.norm2.weight\n",
      "0.features.denseblock1.denselayer2.norm2.bias\n",
      "0.features.denseblock1.denselayer2.conv2.weight\n",
      "0.features.denseblock1.denselayer3.norm1.weight\n",
      "0.features.denseblock1.denselayer3.norm1.bias\n",
      "0.features.denseblock1.denselayer3.conv1.weight\n",
      "0.features.denseblock1.denselayer3.norm2.weight\n",
      "0.features.denseblock1.denselayer3.norm2.bias\n",
      "0.features.denseblock1.denselayer3.conv2.weight\n",
      "0.features.denseblock1.denselayer4.norm1.weight\n",
      "0.features.denseblock1.denselayer4.norm1.bias\n",
      "0.features.denseblock1.denselayer4.conv1.weight\n",
      "0.features.denseblock1.denselayer4.norm2.weight\n",
      "0.features.denseblock1.denselayer4.norm2.bias\n",
      "0.features.denseblock1.denselayer4.conv2.weight\n",
      "0.features.denseblock1.denselayer5.norm1.weight\n",
      "0.features.denseblock1.denselayer5.norm1.bias\n",
      "0.features.denseblock1.denselayer5.conv1.weight\n",
      "0.features.denseblock1.denselayer5.norm2.weight\n",
      "0.features.denseblock1.denselayer5.norm2.bias\n",
      "0.features.denseblock1.denselayer5.conv2.weight\n",
      "0.features.denseblock1.denselayer6.norm1.weight\n",
      "0.features.denseblock1.denselayer6.norm1.bias\n",
      "0.features.denseblock1.denselayer6.conv1.weight\n",
      "0.features.denseblock1.denselayer6.norm2.weight\n",
      "0.features.denseblock1.denselayer6.norm2.bias\n",
      "0.features.denseblock1.denselayer6.conv2.weight\n",
      "0.features.transition1.norm.weight\n",
      "0.features.transition1.norm.bias\n",
      "0.features.transition1.conv.weight\n",
      "0.features.denseblock2.denselayer1.norm1.weight\n",
      "0.features.denseblock2.denselayer1.norm1.bias\n",
      "0.features.denseblock2.denselayer1.conv1.weight\n",
      "0.features.denseblock2.denselayer1.norm2.weight\n",
      "0.features.denseblock2.denselayer1.norm2.bias\n",
      "0.features.denseblock2.denselayer1.conv2.weight\n",
      "0.features.denseblock2.denselayer2.norm1.weight\n",
      "0.features.denseblock2.denselayer2.norm1.bias\n",
      "0.features.denseblock2.denselayer2.conv1.weight\n",
      "0.features.denseblock2.denselayer2.norm2.weight\n",
      "0.features.denseblock2.denselayer2.norm2.bias\n",
      "0.features.denseblock2.denselayer2.conv2.weight\n",
      "0.features.denseblock2.denselayer3.norm1.weight\n",
      "0.features.denseblock2.denselayer3.norm1.bias\n",
      "0.features.denseblock2.denselayer3.conv1.weight\n",
      "0.features.denseblock2.denselayer3.norm2.weight\n",
      "0.features.denseblock2.denselayer3.norm2.bias\n",
      "0.features.denseblock2.denselayer3.conv2.weight\n",
      "0.features.denseblock2.denselayer4.norm1.weight\n",
      "0.features.denseblock2.denselayer4.norm1.bias\n",
      "0.features.denseblock2.denselayer4.conv1.weight\n",
      "0.features.denseblock2.denselayer4.norm2.weight\n",
      "0.features.denseblock2.denselayer4.norm2.bias\n",
      "0.features.denseblock2.denselayer4.conv2.weight\n",
      "0.features.denseblock2.denselayer5.norm1.weight\n",
      "0.features.denseblock2.denselayer5.norm1.bias\n",
      "0.features.denseblock2.denselayer5.conv1.weight\n",
      "0.features.denseblock2.denselayer5.norm2.weight\n",
      "0.features.denseblock2.denselayer5.norm2.bias\n",
      "0.features.denseblock2.denselayer5.conv2.weight\n",
      "0.features.denseblock2.denselayer6.norm1.weight\n",
      "0.features.denseblock2.denselayer6.norm1.bias\n",
      "0.features.denseblock2.denselayer6.conv1.weight\n",
      "0.features.denseblock2.denselayer6.norm2.weight\n",
      "0.features.denseblock2.denselayer6.norm2.bias\n",
      "0.features.denseblock2.denselayer6.conv2.weight\n",
      "0.features.denseblock2.denselayer7.norm1.weight\n",
      "0.features.denseblock2.denselayer7.norm1.bias\n",
      "0.features.denseblock2.denselayer7.conv1.weight\n",
      "0.features.denseblock2.denselayer7.norm2.weight\n",
      "0.features.denseblock2.denselayer7.norm2.bias\n",
      "0.features.denseblock2.denselayer7.conv2.weight\n",
      "0.features.denseblock2.denselayer8.norm1.weight\n",
      "0.features.denseblock2.denselayer8.norm1.bias\n",
      "0.features.denseblock2.denselayer8.conv1.weight\n",
      "0.features.denseblock2.denselayer8.norm2.weight\n",
      "0.features.denseblock2.denselayer8.norm2.bias\n",
      "0.features.denseblock2.denselayer8.conv2.weight\n",
      "0.features.denseblock2.denselayer9.norm1.weight\n",
      "0.features.denseblock2.denselayer9.norm1.bias\n",
      "0.features.denseblock2.denselayer9.conv1.weight\n",
      "0.features.denseblock2.denselayer9.norm2.weight\n",
      "0.features.denseblock2.denselayer9.norm2.bias\n",
      "0.features.denseblock2.denselayer9.conv2.weight\n",
      "0.features.denseblock2.denselayer10.norm1.weight\n",
      "0.features.denseblock2.denselayer10.norm1.bias\n",
      "0.features.denseblock2.denselayer10.conv1.weight\n",
      "0.features.denseblock2.denselayer10.norm2.weight\n",
      "0.features.denseblock2.denselayer10.norm2.bias\n",
      "0.features.denseblock2.denselayer10.conv2.weight\n",
      "0.features.denseblock2.denselayer11.norm1.weight\n",
      "0.features.denseblock2.denselayer11.norm1.bias\n",
      "0.features.denseblock2.denselayer11.conv1.weight\n",
      "0.features.denseblock2.denselayer11.norm2.weight\n",
      "0.features.denseblock2.denselayer11.norm2.bias\n",
      "0.features.denseblock2.denselayer11.conv2.weight\n",
      "0.features.denseblock2.denselayer12.norm1.weight\n",
      "0.features.denseblock2.denselayer12.norm1.bias\n",
      "0.features.denseblock2.denselayer12.conv1.weight\n",
      "0.features.denseblock2.denselayer12.norm2.weight\n",
      "0.features.denseblock2.denselayer12.norm2.bias\n",
      "0.features.denseblock2.denselayer12.conv2.weight\n",
      "0.features.transition2.norm.weight\n",
      "0.features.transition2.norm.bias\n",
      "0.features.transition2.conv.weight\n",
      "0.features.denseblock3.denselayer1.norm1.weight\n",
      "0.features.denseblock3.denselayer1.norm1.bias\n",
      "0.features.denseblock3.denselayer1.conv1.weight\n",
      "0.features.denseblock3.denselayer1.norm2.weight\n",
      "0.features.denseblock3.denselayer1.norm2.bias\n",
      "0.features.denseblock3.denselayer1.conv2.weight\n",
      "0.features.denseblock3.denselayer2.norm1.weight\n",
      "0.features.denseblock3.denselayer2.norm1.bias\n",
      "0.features.denseblock3.denselayer2.conv1.weight\n",
      "0.features.denseblock3.denselayer2.norm2.weight\n",
      "0.features.denseblock3.denselayer2.norm2.bias\n",
      "0.features.denseblock3.denselayer2.conv2.weight\n",
      "0.features.denseblock3.denselayer3.norm1.weight\n",
      "0.features.denseblock3.denselayer3.norm1.bias\n",
      "0.features.denseblock3.denselayer3.conv1.weight\n",
      "0.features.denseblock3.denselayer3.norm2.weight\n",
      "0.features.denseblock3.denselayer3.norm2.bias\n",
      "0.features.denseblock3.denselayer3.conv2.weight\n",
      "0.features.denseblock3.denselayer4.norm1.weight\n",
      "0.features.denseblock3.denselayer4.norm1.bias\n",
      "0.features.denseblock3.denselayer4.conv1.weight\n",
      "0.features.denseblock3.denselayer4.norm2.weight\n",
      "0.features.denseblock3.denselayer4.norm2.bias\n",
      "0.features.denseblock3.denselayer4.conv2.weight\n",
      "0.features.denseblock3.denselayer5.norm1.weight\n",
      "0.features.denseblock3.denselayer5.norm1.bias\n",
      "0.features.denseblock3.denselayer5.conv1.weight\n",
      "0.features.denseblock3.denselayer5.norm2.weight\n",
      "0.features.denseblock3.denselayer5.norm2.bias\n",
      "0.features.denseblock3.denselayer5.conv2.weight\n",
      "0.features.denseblock3.denselayer6.norm1.weight\n",
      "0.features.denseblock3.denselayer6.norm1.bias\n",
      "0.features.denseblock3.denselayer6.conv1.weight\n",
      "0.features.denseblock3.denselayer6.norm2.weight\n",
      "0.features.denseblock3.denselayer6.norm2.bias\n",
      "0.features.denseblock3.denselayer6.conv2.weight\n",
      "0.features.denseblock3.denselayer7.norm1.weight\n",
      "0.features.denseblock3.denselayer7.norm1.bias\n",
      "0.features.denseblock3.denselayer7.conv1.weight\n",
      "0.features.denseblock3.denselayer7.norm2.weight\n",
      "0.features.denseblock3.denselayer7.norm2.bias\n",
      "0.features.denseblock3.denselayer7.conv2.weight\n",
      "0.features.denseblock3.denselayer8.norm1.weight\n",
      "0.features.denseblock3.denselayer8.norm1.bias\n",
      "0.features.denseblock3.denselayer8.conv1.weight\n",
      "0.features.denseblock3.denselayer8.norm2.weight\n",
      "0.features.denseblock3.denselayer8.norm2.bias\n",
      "0.features.denseblock3.denselayer8.conv2.weight\n",
      "0.features.denseblock3.denselayer9.norm1.weight\n",
      "0.features.denseblock3.denselayer9.norm1.bias\n",
      "0.features.denseblock3.denselayer9.conv1.weight\n",
      "0.features.denseblock3.denselayer9.norm2.weight\n",
      "0.features.denseblock3.denselayer9.norm2.bias\n",
      "0.features.denseblock3.denselayer9.conv2.weight\n",
      "0.features.denseblock3.denselayer10.norm1.weight\n",
      "0.features.denseblock3.denselayer10.norm1.bias\n",
      "0.features.denseblock3.denselayer10.conv1.weight\n",
      "0.features.denseblock3.denselayer10.norm2.weight\n",
      "0.features.denseblock3.denselayer10.norm2.bias\n",
      "0.features.denseblock3.denselayer10.conv2.weight\n",
      "0.features.denseblock3.denselayer11.norm1.weight\n",
      "0.features.denseblock3.denselayer11.norm1.bias\n",
      "0.features.denseblock3.denselayer11.conv1.weight\n",
      "0.features.denseblock3.denselayer11.norm2.weight\n",
      "0.features.denseblock3.denselayer11.norm2.bias\n",
      "0.features.denseblock3.denselayer11.conv2.weight\n",
      "0.features.denseblock3.denselayer12.norm1.weight\n",
      "0.features.denseblock3.denselayer12.norm1.bias\n",
      "0.features.denseblock3.denselayer12.conv1.weight\n",
      "0.features.denseblock3.denselayer12.norm2.weight\n",
      "0.features.denseblock3.denselayer12.norm2.bias\n",
      "0.features.denseblock3.denselayer12.conv2.weight\n",
      "0.features.denseblock3.denselayer13.norm1.weight\n",
      "0.features.denseblock3.denselayer13.norm1.bias\n",
      "0.features.denseblock3.denselayer13.conv1.weight\n",
      "0.features.denseblock3.denselayer13.norm2.weight\n",
      "0.features.denseblock3.denselayer13.norm2.bias\n",
      "0.features.denseblock3.denselayer13.conv2.weight\n",
      "0.features.denseblock3.denselayer14.norm1.weight\n",
      "0.features.denseblock3.denselayer14.norm1.bias\n",
      "0.features.denseblock3.denselayer14.conv1.weight\n",
      "0.features.denseblock3.denselayer14.norm2.weight\n",
      "0.features.denseblock3.denselayer14.norm2.bias\n",
      "0.features.denseblock3.denselayer14.conv2.weight\n",
      "0.features.denseblock3.denselayer15.norm1.weight\n",
      "0.features.denseblock3.denselayer15.norm1.bias\n",
      "0.features.denseblock3.denselayer15.conv1.weight\n",
      "0.features.denseblock3.denselayer15.norm2.weight\n",
      "0.features.denseblock3.denselayer15.norm2.bias\n",
      "0.features.denseblock3.denselayer15.conv2.weight\n",
      "0.features.denseblock3.denselayer16.norm1.weight\n",
      "0.features.denseblock3.denselayer16.norm1.bias\n",
      "0.features.denseblock3.denselayer16.conv1.weight\n",
      "0.features.denseblock3.denselayer16.norm2.weight\n",
      "0.features.denseblock3.denselayer16.norm2.bias\n",
      "0.features.denseblock3.denselayer16.conv2.weight\n",
      "0.features.denseblock3.denselayer17.norm1.weight\n",
      "0.features.denseblock3.denselayer17.norm1.bias\n",
      "0.features.denseblock3.denselayer17.conv1.weight\n",
      "0.features.denseblock3.denselayer17.norm2.weight\n",
      "0.features.denseblock3.denselayer17.norm2.bias\n",
      "0.features.denseblock3.denselayer17.conv2.weight\n",
      "0.features.denseblock3.denselayer18.norm1.weight\n",
      "0.features.denseblock3.denselayer18.norm1.bias\n",
      "0.features.denseblock3.denselayer18.conv1.weight\n",
      "0.features.denseblock3.denselayer18.norm2.weight\n",
      "0.features.denseblock3.denselayer18.norm2.bias\n",
      "0.features.denseblock3.denselayer18.conv2.weight\n",
      "0.features.denseblock3.denselayer19.norm1.weight\n",
      "0.features.denseblock3.denselayer19.norm1.bias\n",
      "0.features.denseblock3.denselayer19.conv1.weight\n",
      "0.features.denseblock3.denselayer19.norm2.weight\n",
      "0.features.denseblock3.denselayer19.norm2.bias\n",
      "0.features.denseblock3.denselayer19.conv2.weight\n",
      "0.features.denseblock3.denselayer20.norm1.weight\n",
      "0.features.denseblock3.denselayer20.norm1.bias\n",
      "0.features.denseblock3.denselayer20.conv1.weight\n",
      "0.features.denseblock3.denselayer20.norm2.weight\n",
      "0.features.denseblock3.denselayer20.norm2.bias\n",
      "0.features.denseblock3.denselayer20.conv2.weight\n",
      "0.features.denseblock3.denselayer21.norm1.weight\n",
      "0.features.denseblock3.denselayer21.norm1.bias\n",
      "0.features.denseblock3.denselayer21.conv1.weight\n",
      "0.features.denseblock3.denselayer21.norm2.weight\n",
      "0.features.denseblock3.denselayer21.norm2.bias\n",
      "0.features.denseblock3.denselayer21.conv2.weight\n",
      "0.features.denseblock3.denselayer22.norm1.weight\n",
      "0.features.denseblock3.denselayer22.norm1.bias\n",
      "0.features.denseblock3.denselayer22.conv1.weight\n",
      "0.features.denseblock3.denselayer22.norm2.weight\n",
      "0.features.denseblock3.denselayer22.norm2.bias\n",
      "0.features.denseblock3.denselayer22.conv2.weight\n",
      "0.features.denseblock3.denselayer23.norm1.weight\n",
      "0.features.denseblock3.denselayer23.norm1.bias\n",
      "0.features.denseblock3.denselayer23.conv1.weight\n",
      "0.features.denseblock3.denselayer23.norm2.weight\n",
      "0.features.denseblock3.denselayer23.norm2.bias\n",
      "0.features.denseblock3.denselayer23.conv2.weight\n",
      "0.features.denseblock3.denselayer24.norm1.weight\n",
      "0.features.denseblock3.denselayer24.norm1.bias\n",
      "0.features.denseblock3.denselayer24.conv1.weight\n",
      "0.features.denseblock3.denselayer24.norm2.weight\n",
      "0.features.denseblock3.denselayer24.norm2.bias\n",
      "0.features.denseblock3.denselayer24.conv2.weight\n",
      "0.features.denseblock3.denselayer25.norm1.weight\n",
      "0.features.denseblock3.denselayer25.norm1.bias\n",
      "0.features.denseblock3.denselayer25.conv1.weight\n",
      "0.features.denseblock3.denselayer25.norm2.weight\n",
      "0.features.denseblock3.denselayer25.norm2.bias\n",
      "0.features.denseblock3.denselayer25.conv2.weight\n",
      "0.features.denseblock3.denselayer26.norm1.weight\n",
      "0.features.denseblock3.denselayer26.norm1.bias\n",
      "0.features.denseblock3.denselayer26.conv1.weight\n",
      "0.features.denseblock3.denselayer26.norm2.weight\n",
      "0.features.denseblock3.denselayer26.norm2.bias\n",
      "0.features.denseblock3.denselayer26.conv2.weight\n",
      "0.features.denseblock3.denselayer27.norm1.weight\n",
      "0.features.denseblock3.denselayer27.norm1.bias\n",
      "0.features.denseblock3.denselayer27.conv1.weight\n",
      "0.features.denseblock3.denselayer27.norm2.weight\n",
      "0.features.denseblock3.denselayer27.norm2.bias\n",
      "0.features.denseblock3.denselayer27.conv2.weight\n",
      "0.features.denseblock3.denselayer28.norm1.weight\n",
      "0.features.denseblock3.denselayer28.norm1.bias\n",
      "0.features.denseblock3.denselayer28.conv1.weight\n",
      "0.features.denseblock3.denselayer28.norm2.weight\n",
      "0.features.denseblock3.denselayer28.norm2.bias\n",
      "0.features.denseblock3.denselayer28.conv2.weight\n",
      "0.features.denseblock3.denselayer29.norm1.weight\n",
      "0.features.denseblock3.denselayer29.norm1.bias\n",
      "0.features.denseblock3.denselayer29.conv1.weight\n",
      "0.features.denseblock3.denselayer29.norm2.weight\n",
      "0.features.denseblock3.denselayer29.norm2.bias\n",
      "0.features.denseblock3.denselayer29.conv2.weight\n",
      "0.features.denseblock3.denselayer30.norm1.weight\n",
      "0.features.denseblock3.denselayer30.norm1.bias\n",
      "0.features.denseblock3.denselayer30.conv1.weight\n",
      "0.features.denseblock3.denselayer30.norm2.weight\n",
      "0.features.denseblock3.denselayer30.norm2.bias\n",
      "0.features.denseblock3.denselayer30.conv2.weight\n",
      "0.features.denseblock3.denselayer31.norm1.weight\n",
      "0.features.denseblock3.denselayer31.norm1.bias\n",
      "0.features.denseblock3.denselayer31.conv1.weight\n",
      "0.features.denseblock3.denselayer31.norm2.weight\n",
      "0.features.denseblock3.denselayer31.norm2.bias\n",
      "0.features.denseblock3.denselayer31.conv2.weight\n",
      "0.features.denseblock3.denselayer32.norm1.weight\n",
      "0.features.denseblock3.denselayer32.norm1.bias\n",
      "0.features.denseblock3.denselayer32.conv1.weight\n",
      "0.features.denseblock3.denselayer32.norm2.weight\n",
      "0.features.denseblock3.denselayer32.norm2.bias\n",
      "0.features.denseblock3.denselayer32.conv2.weight\n",
      "0.features.transition3.norm.weight\n",
      "0.features.transition3.norm.bias\n",
      "0.features.transition3.conv.weight\n",
      "0.features.denseblock4.denselayer1.norm1.weight\n",
      "0.features.denseblock4.denselayer1.norm1.bias\n",
      "0.features.denseblock4.denselayer1.conv1.weight\n",
      "0.features.denseblock4.denselayer1.norm2.weight\n",
      "0.features.denseblock4.denselayer1.norm2.bias\n",
      "0.features.denseblock4.denselayer1.conv2.weight\n",
      "0.features.denseblock4.denselayer2.norm1.weight\n",
      "0.features.denseblock4.denselayer2.norm1.bias\n",
      "0.features.denseblock4.denselayer2.conv1.weight\n",
      "0.features.denseblock4.denselayer2.norm2.weight\n",
      "0.features.denseblock4.denselayer2.norm2.bias\n",
      "0.features.denseblock4.denselayer2.conv2.weight\n",
      "0.features.denseblock4.denselayer3.norm1.weight\n",
      "0.features.denseblock4.denselayer3.norm1.bias\n",
      "0.features.denseblock4.denselayer3.conv1.weight\n",
      "0.features.denseblock4.denselayer3.norm2.weight\n",
      "0.features.denseblock4.denselayer3.norm2.bias\n",
      "0.features.denseblock4.denselayer3.conv2.weight\n",
      "0.features.denseblock4.denselayer4.norm1.weight\n",
      "0.features.denseblock4.denselayer4.norm1.bias\n",
      "0.features.denseblock4.denselayer4.conv1.weight\n",
      "0.features.denseblock4.denselayer4.norm2.weight\n",
      "0.features.denseblock4.denselayer4.norm2.bias\n",
      "0.features.denseblock4.denselayer4.conv2.weight\n",
      "0.features.denseblock4.denselayer5.norm1.weight\n",
      "0.features.denseblock4.denselayer5.norm1.bias\n",
      "0.features.denseblock4.denselayer5.conv1.weight\n",
      "0.features.denseblock4.denselayer5.norm2.weight\n",
      "0.features.denseblock4.denselayer5.norm2.bias\n",
      "0.features.denseblock4.denselayer5.conv2.weight\n",
      "0.features.denseblock4.denselayer6.norm1.weight\n",
      "0.features.denseblock4.denselayer6.norm1.bias\n",
      "0.features.denseblock4.denselayer6.conv1.weight\n",
      "0.features.denseblock4.denselayer6.norm2.weight\n",
      "0.features.denseblock4.denselayer6.norm2.bias\n",
      "0.features.denseblock4.denselayer6.conv2.weight\n",
      "0.features.denseblock4.denselayer7.norm1.weight\n",
      "0.features.denseblock4.denselayer7.norm1.bias\n",
      "0.features.denseblock4.denselayer7.conv1.weight\n",
      "0.features.denseblock4.denselayer7.norm2.weight\n",
      "0.features.denseblock4.denselayer7.norm2.bias\n",
      "0.features.denseblock4.denselayer7.conv2.weight\n",
      "0.features.denseblock4.denselayer8.norm1.weight\n",
      "0.features.denseblock4.denselayer8.norm1.bias\n",
      "0.features.denseblock4.denselayer8.conv1.weight\n",
      "0.features.denseblock4.denselayer8.norm2.weight\n",
      "0.features.denseblock4.denselayer8.norm2.bias\n",
      "0.features.denseblock4.denselayer8.conv2.weight\n",
      "0.features.denseblock4.denselayer9.norm1.weight\n",
      "0.features.denseblock4.denselayer9.norm1.bias\n",
      "0.features.denseblock4.denselayer9.conv1.weight\n",
      "0.features.denseblock4.denselayer9.norm2.weight\n",
      "0.features.denseblock4.denselayer9.norm2.bias\n",
      "0.features.denseblock4.denselayer9.conv2.weight\n",
      "0.features.denseblock4.denselayer10.norm1.weight\n",
      "0.features.denseblock4.denselayer10.norm1.bias\n",
      "0.features.denseblock4.denselayer10.conv1.weight\n",
      "0.features.denseblock4.denselayer10.norm2.weight\n",
      "0.features.denseblock4.denselayer10.norm2.bias\n",
      "0.features.denseblock4.denselayer10.conv2.weight\n",
      "0.features.denseblock4.denselayer11.norm1.weight\n",
      "0.features.denseblock4.denselayer11.norm1.bias\n",
      "0.features.denseblock4.denselayer11.conv1.weight\n",
      "0.features.denseblock4.denselayer11.norm2.weight\n",
      "0.features.denseblock4.denselayer11.norm2.bias\n",
      "0.features.denseblock4.denselayer11.conv2.weight\n",
      "0.features.denseblock4.denselayer12.norm1.weight\n",
      "0.features.denseblock4.denselayer12.norm1.bias\n",
      "0.features.denseblock4.denselayer12.conv1.weight\n",
      "0.features.denseblock4.denselayer12.norm2.weight\n",
      "0.features.denseblock4.denselayer12.norm2.bias\n",
      "0.features.denseblock4.denselayer12.conv2.weight\n",
      "0.features.denseblock4.denselayer13.norm1.weight\n",
      "0.features.denseblock4.denselayer13.norm1.bias\n",
      "0.features.denseblock4.denselayer13.conv1.weight\n",
      "0.features.denseblock4.denselayer13.norm2.weight\n",
      "0.features.denseblock4.denselayer13.norm2.bias\n",
      "0.features.denseblock4.denselayer13.conv2.weight\n",
      "0.features.denseblock4.denselayer14.norm1.weight\n",
      "0.features.denseblock4.denselayer14.norm1.bias\n",
      "0.features.denseblock4.denselayer14.conv1.weight\n",
      "0.features.denseblock4.denselayer14.norm2.weight\n",
      "0.features.denseblock4.denselayer14.norm2.bias\n",
      "0.features.denseblock4.denselayer14.conv2.weight\n",
      "0.features.denseblock4.denselayer15.norm1.weight\n",
      "0.features.denseblock4.denselayer15.norm1.bias\n",
      "0.features.denseblock4.denselayer15.conv1.weight\n",
      "0.features.denseblock4.denselayer15.norm2.weight\n",
      "0.features.denseblock4.denselayer15.norm2.bias\n",
      "0.features.denseblock4.denselayer15.conv2.weight\n",
      "0.features.denseblock4.denselayer16.norm1.weight\n",
      "0.features.denseblock4.denselayer16.norm1.bias\n",
      "0.features.denseblock4.denselayer16.conv1.weight\n",
      "0.features.denseblock4.denselayer16.norm2.weight\n",
      "0.features.denseblock4.denselayer16.norm2.bias\n",
      "0.features.denseblock4.denselayer16.conv2.weight\n",
      "0.features.denseblock4.denselayer17.norm1.weight\n",
      "0.features.denseblock4.denselayer17.norm1.bias\n",
      "0.features.denseblock4.denselayer17.conv1.weight\n",
      "0.features.denseblock4.denselayer17.norm2.weight\n",
      "0.features.denseblock4.denselayer17.norm2.bias\n",
      "0.features.denseblock4.denselayer17.conv2.weight\n",
      "0.features.denseblock4.denselayer18.norm1.weight\n",
      "0.features.denseblock4.denselayer18.norm1.bias\n",
      "0.features.denseblock4.denselayer18.conv1.weight\n",
      "0.features.denseblock4.denselayer18.norm2.weight\n",
      "0.features.denseblock4.denselayer18.norm2.bias\n",
      "0.features.denseblock4.denselayer18.conv2.weight\n",
      "0.features.denseblock4.denselayer19.norm1.weight\n",
      "0.features.denseblock4.denselayer19.norm1.bias\n",
      "0.features.denseblock4.denselayer19.conv1.weight\n",
      "0.features.denseblock4.denselayer19.norm2.weight\n",
      "0.features.denseblock4.denselayer19.norm2.bias\n",
      "0.features.denseblock4.denselayer19.conv2.weight\n",
      "0.features.denseblock4.denselayer20.norm1.weight\n",
      "0.features.denseblock4.denselayer20.norm1.bias\n",
      "0.features.denseblock4.denselayer20.conv1.weight\n",
      "0.features.denseblock4.denselayer20.norm2.weight\n",
      "0.features.denseblock4.denselayer20.norm2.bias\n",
      "0.features.denseblock4.denselayer20.conv2.weight\n",
      "0.features.denseblock4.denselayer21.norm1.weight\n",
      "0.features.denseblock4.denselayer21.norm1.bias\n",
      "0.features.denseblock4.denselayer21.conv1.weight\n",
      "0.features.denseblock4.denselayer21.norm2.weight\n",
      "0.features.denseblock4.denselayer21.norm2.bias\n",
      "0.features.denseblock4.denselayer21.conv2.weight\n",
      "0.features.denseblock4.denselayer22.norm1.weight\n",
      "0.features.denseblock4.denselayer22.norm1.bias\n",
      "0.features.denseblock4.denselayer22.conv1.weight\n",
      "0.features.denseblock4.denselayer22.norm2.weight\n",
      "0.features.denseblock4.denselayer22.norm2.bias\n",
      "0.features.denseblock4.denselayer22.conv2.weight\n",
      "0.features.denseblock4.denselayer23.norm1.weight\n",
      "0.features.denseblock4.denselayer23.norm1.bias\n",
      "0.features.denseblock4.denselayer23.conv1.weight\n",
      "0.features.denseblock4.denselayer23.norm2.weight\n",
      "0.features.denseblock4.denselayer23.norm2.bias\n",
      "0.features.denseblock4.denselayer23.conv2.weight\n",
      "0.features.denseblock4.denselayer24.norm1.weight\n",
      "0.features.denseblock4.denselayer24.norm1.bias\n",
      "0.features.denseblock4.denselayer24.conv1.weight\n",
      "0.features.denseblock4.denselayer24.norm2.weight\n",
      "0.features.denseblock4.denselayer24.norm2.bias\n",
      "0.features.denseblock4.denselayer24.conv2.weight\n",
      "0.features.denseblock4.denselayer25.norm1.weight\n",
      "0.features.denseblock4.denselayer25.norm1.bias\n",
      "0.features.denseblock4.denselayer25.conv1.weight\n",
      "0.features.denseblock4.denselayer25.norm2.weight\n",
      "0.features.denseblock4.denselayer25.norm2.bias\n",
      "0.features.denseblock4.denselayer25.conv2.weight\n",
      "0.features.denseblock4.denselayer26.norm1.weight\n",
      "0.features.denseblock4.denselayer26.norm1.bias\n",
      "0.features.denseblock4.denselayer26.conv1.weight\n",
      "0.features.denseblock4.denselayer26.norm2.weight\n",
      "0.features.denseblock4.denselayer26.norm2.bias\n",
      "0.features.denseblock4.denselayer26.conv2.weight\n",
      "0.features.denseblock4.denselayer27.norm1.weight\n",
      "0.features.denseblock4.denselayer27.norm1.bias\n",
      "0.features.denseblock4.denselayer27.conv1.weight\n",
      "0.features.denseblock4.denselayer27.norm2.weight\n",
      "0.features.denseblock4.denselayer27.norm2.bias\n",
      "0.features.denseblock4.denselayer27.conv2.weight\n",
      "0.features.denseblock4.denselayer28.norm1.weight\n",
      "0.features.denseblock4.denselayer28.norm1.bias\n",
      "0.features.denseblock4.denselayer28.conv1.weight\n",
      "0.features.denseblock4.denselayer28.norm2.weight\n",
      "0.features.denseblock4.denselayer28.norm2.bias\n",
      "0.features.denseblock4.denselayer28.conv2.weight\n",
      "0.features.denseblock4.denselayer29.norm1.weight\n",
      "0.features.denseblock4.denselayer29.norm1.bias\n",
      "0.features.denseblock4.denselayer29.conv1.weight\n",
      "0.features.denseblock4.denselayer29.norm2.weight\n",
      "0.features.denseblock4.denselayer29.norm2.bias\n",
      "0.features.denseblock4.denselayer29.conv2.weight\n",
      "0.features.denseblock4.denselayer30.norm1.weight\n",
      "0.features.denseblock4.denselayer30.norm1.bias\n",
      "0.features.denseblock4.denselayer30.conv1.weight\n",
      "0.features.denseblock4.denselayer30.norm2.weight\n",
      "0.features.denseblock4.denselayer30.norm2.bias\n",
      "0.features.denseblock4.denselayer30.conv2.weight\n",
      "0.features.denseblock4.denselayer31.norm1.weight\n",
      "0.features.denseblock4.denselayer31.norm1.bias\n",
      "0.features.denseblock4.denselayer31.conv1.weight\n",
      "0.features.denseblock4.denselayer31.norm2.weight\n",
      "0.features.denseblock4.denselayer31.norm2.bias\n",
      "0.features.denseblock4.denselayer31.conv2.weight\n",
      "0.features.denseblock4.denselayer32.norm1.weight\n",
      "0.features.denseblock4.denselayer32.norm1.bias\n",
      "0.features.denseblock4.denselayer32.conv1.weight\n",
      "0.features.denseblock4.denselayer32.norm2.weight\n",
      "0.features.denseblock4.denselayer32.norm2.bias\n",
      "0.features.denseblock4.denselayer32.conv2.weight\n",
      "0.features.norm5.weight\n",
      "0.features.norm5.bias\n",
      "0.classifier.weight\n",
      "0.classifier.bias\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([{'params':model[0].classifier.parameters(), 'lr':0.0004}])\n",
    "#                        {'params':model.layer4.parameters(),'lr':0.00001}\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Train Epoch: {}\\t Loss: {:.6f}\\n'.format(epoch,loss.item()))\n",
    "\n",
    "    \n",
    "# def test(model, device, test_loader, optimizer):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "# #     pred_result = []\n",
    "#     with torch.no_grad():\n",
    "#         for i,data in enumerate(test_loader):          \n",
    "#             x,y= data\n",
    "#             x=x.to(device)\n",
    "#             y=y.float().to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             y_hat = model(x)\n",
    "#             test_loss = criterion(y_hat, y).item() # sum up batch loss\n",
    "#             pred = y_hat.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            \n",
    "#             correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "# #     test_loss /= len(test_loader.dataset)\n",
    "#     acc = 100. * correct / len(train_test_dict['test'])\n",
    "#     print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(train_test_dict['test']),\n",
    "#         acc))\n",
    "    \n",
    "# #     print('-----------------------')\n",
    "#     return acc\n",
    "\n",
    "#!/usr/bin/env python\n",
    "def error_analysis(model, test_loader, DEVICE=DEVICE):\n",
    "    y_pred =[]\n",
    "    y_true = []\n",
    "    for i,data in enumerate(test_loader):\n",
    "        x, y = data\n",
    "        y = np.array(y.cpu())\n",
    "        y_true.append(y)\n",
    "\n",
    "        x = x.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        pred = y_hat.max(1, keepdim=True)[1]\n",
    "        pred = np.array(pred.cpu())\n",
    "        y_pred.append(pred)\n",
    "    \n",
    "    y_pred_list = []\n",
    "    y_true_list = []\n",
    "    for i in range(len(y_pred)):\n",
    "        y_pred_list += list(y_pred[i].ravel())\n",
    "    for i in range(len(y_true)):\n",
    "        y_true_list += list(y_true[i].ravel())\n",
    "    return np.array(y_true_list), np.array(y_pred_list)\n",
    "\n",
    "def predprob(x, y, initial_lexsort=True):\n",
    "    \"\"\"\n",
    "    Calculates the prediction probability. Adapted from scipy's implementation of Kendall's Tau\n",
    "\n",
    "    Note: x should be the truth labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array_like\n",
    "        Arrays of rankings, of the same shape. If arrays are not 1-D, they will\n",
    "        be flattened to 1-D.\n",
    "    initial_lexsort : bool, optional\n",
    "        Whether to use lexsort or quicksort as the sorting method for the\n",
    "        initial sort of the inputs. Default is lexsort (True), for which\n",
    "        `predprob` is of complexity O(n log(n)). If False, the complexity is\n",
    "        O(n^2), but with a smaller pre-factor (so quicksort may be faster for\n",
    "        small arrays).\n",
    "    Returns\n",
    "    -------\n",
    "    Prediction probability : float\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The definition of prediction probability that is used is:\n",
    "      p_k = (((P - Q) / (P + Q + T)) + 1)/2\n",
    "    where P is the number of concordant pairs, Q the number of discordant\n",
    "    pairs, and T the number of ties only in `y`.\n",
    "    References\n",
    "    ----------\n",
    "    Smith W.D, Dutton R.C, Smith N.T. (1996) A measure of association for assessing prediction accuracy\n",
    "    that is a generalization of non-parametric ROC area. Stat Med. Jun 15;15(11):1199-215\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.asarray(x).ravel()\n",
    "    y = np.asarray(y).ravel()\n",
    "\n",
    "    if not x.size or not y.size:\n",
    "        return (np.nan, np.nan)  # Return NaN if arrays are empty\n",
    "\n",
    "    n = np.int64(len(x))\n",
    "    temp = list(range(n))  # support structure used by mergesort\n",
    "    # this closure recursively sorts sections of perm[] by comparing\n",
    "    # elements of y[perm[]] using temp[] as support\n",
    "    # returns the number of swaps required by an equivalent bubble sort\n",
    "\n",
    "    def mergesort(offs, length):\n",
    "        exchcnt = 0\n",
    "        if length == 1:\n",
    "            return 0\n",
    "        if length == 2:\n",
    "            if y[perm[offs]] <= y[perm[offs+1]]:\n",
    "                return 0\n",
    "            t = perm[offs]\n",
    "            perm[offs] = perm[offs+1]\n",
    "            perm[offs+1] = t\n",
    "            return 1\n",
    "        length0 = length // 2\n",
    "        length1 = length - length0\n",
    "        middle = offs + length0\n",
    "        exchcnt += mergesort(offs, length0)\n",
    "        exchcnt += mergesort(middle, length1)\n",
    "        if y[perm[middle - 1]] < y[perm[middle]]:\n",
    "            return exchcnt\n",
    "        # merging\n",
    "        i = j = k = 0\n",
    "        while j < length0 or k < length1:\n",
    "            if k >= length1 or (j < length0 and y[perm[offs + j]] <=\n",
    "                                                y[perm[middle + k]]):\n",
    "                temp[i] = perm[offs + j]\n",
    "                d = i - j\n",
    "                j += 1\n",
    "            else:\n",
    "                temp[i] = perm[middle + k]\n",
    "                d = (offs + i) - (middle + k)\n",
    "                k += 1\n",
    "            if d > 0:\n",
    "                exchcnt += d\n",
    "            i += 1\n",
    "        perm[offs:offs+length] = temp[0:length]\n",
    "        return exchcnt\n",
    "\n",
    "    # initial sort on values of x and, if tied, on values of y\n",
    "    if initial_lexsort:\n",
    "        # sort implemented as mergesort, worst case: O(n log(n))\n",
    "        perm = np.lexsort((y, x))\n",
    "    else:\n",
    "        # sort implemented as quicksort, 30% faster but with worst case: O(n^2)\n",
    "        perm = list(range(n))\n",
    "        perm.sort(key=lambda a: (x[a], y[a]))\n",
    "\n",
    "    # compute joint ties\n",
    "    first = 0\n",
    "    t = 0\n",
    "    for i in xrange(1, n):\n",
    "        if x[perm[first]] != x[perm[i]] or y[perm[first]] != y[perm[i]]:\n",
    "            t += ((i - first) * (i - first - 1)) // 2\n",
    "            first = i\n",
    "    t += ((n - first) * (n - first - 1)) // 2\n",
    "\n",
    "    # compute ties in x\n",
    "    first = 0\n",
    "    u = 0\n",
    "    for i in xrange(1,n):\n",
    "        if x[perm[first]] != x[perm[i]]:\n",
    "            u += ((i - first) * (i - first - 1)) // 2\n",
    "            first = i\n",
    "    u += ((n - first) * (n - first - 1)) // 2\n",
    "\n",
    "    # count exchanges\n",
    "    exchanges = mergesort(0, n)\n",
    "    # compute ties in y after mergesort with counting\n",
    "    first = 0\n",
    "    v = 0\n",
    "    for i in xrange(1,n):\n",
    "        if y[perm[first]] != y[perm[i]]:\n",
    "            v += ((i - first) * (i - first - 1)) // 2\n",
    "            first = i\n",
    "    v += ((n - first) * (n - first - 1)) // 2\n",
    "\n",
    "    tot = (n * (n - 1)) // 2\n",
    "    if tot == u or tot == v:\n",
    "        return (np.nan, np.nan)    # Special case for all ties in both ranks\n",
    "\n",
    "    p_k = (((tot - (v + u - t)) - 2.0 * exchanges) / (tot - u) + 1)/2\n",
    "\n",
    "    return p_k\n",
    "\n",
    "\n",
    "def test(model, test_loader, DEVICE=DEVICE):\n",
    "    \n",
    "    x, y = error_analysis(model, test_loader, DEVICE=DEVICE)\n",
    "    p_k = predprob(x, y)\n",
    "    print('current p_k value: ', p_k, '\\n')\n",
    "#     print('------------------------------')\n",
    "    return p_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\t Loss: 0.109785\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 1\t Loss: 0.143600\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 2\t Loss: 0.101962\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 3\t Loss: 0.095097\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 4\t Loss: 0.116265\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 5\t Loss: 0.111675\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 6\t Loss: 0.129345\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 7\t Loss: 0.085280\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 8\t Loss: 0.113740\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 9\t Loss: 0.112257\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 10\t Loss: 0.065024\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 11\t Loss: 0.109519\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 12\t Loss: 0.106800\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 13\t Loss: 0.163977\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 14\t Loss: 0.094903\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 15\t Loss: 0.130754\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 16\t Loss: 0.100727\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 17\t Loss: 0.154788\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 18\t Loss: 0.101122\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 19\t Loss: 0.109706\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 20\t Loss: 0.130759\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 21\t Loss: 0.149107\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 22\t Loss: 0.113679\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 23\t Loss: 0.124565\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 24\t Loss: 0.131816\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 25\t Loss: 0.104534\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 26\t Loss: 0.115992\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 27\t Loss: 0.118787\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 28\t Loss: 0.114874\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 29\t Loss: 0.100590\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 30\t Loss: 0.120231\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 31\t Loss: 0.108454\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 32\t Loss: 0.101247\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 33\t Loss: 0.112482\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 34\t Loss: 0.126234\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 35\t Loss: 0.115986\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 36\t Loss: 0.135130\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 37\t Loss: 0.128284\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 38\t Loss: 0.109709\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 39\t Loss: 0.117004\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 40\t Loss: 0.140901\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 41\t Loss: 0.124524\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 42\t Loss: 0.140652\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 43\t Loss: 0.095931\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 44\t Loss: 0.112550\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 45\t Loss: 0.111957\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 46\t Loss: 0.106600\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 47\t Loss: 0.073958\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 48\t Loss: 0.117079\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 49\t Loss: 0.113923\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 50\t Loss: 0.125801\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 51\t Loss: 0.148531\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 52\t Loss: 0.119507\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 53\t Loss: 0.130666\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 54\t Loss: 0.082998\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 55\t Loss: 0.110975\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 56\t Loss: 0.125290\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 57\t Loss: 0.144433\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 58\t Loss: 0.096099\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 59\t Loss: 0.096604\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 60\t Loss: 0.098161\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 61\t Loss: 0.112604\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 62\t Loss: 0.140902\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 63\t Loss: 0.114357\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 64\t Loss: 0.089655\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 65\t Loss: 0.115903\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 66\t Loss: 0.132157\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 67\t Loss: 0.093256\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 68\t Loss: 0.106426\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 69\t Loss: 0.101856\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 70\t Loss: 0.133268\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 71\t Loss: 0.094711\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 72\t Loss: 0.102953\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 73\t Loss: 0.095019\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 74\t Loss: 0.108818\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 75\t Loss: 0.141683\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 76\t Loss: 0.108930\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 77\t Loss: 0.132417\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 78\t Loss: 0.116066\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 79\t Loss: 0.099473\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 80\t Loss: 0.120355\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 81\t Loss: 0.109532\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 82\t Loss: 0.121577\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 83\t Loss: 0.120881\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 84\t Loss: 0.112205\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 85\t Loss: 0.115266\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 86\t Loss: 0.163436\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 87\t Loss: 0.082041\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 88\t Loss: 0.096182\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 89\t Loss: 0.103429\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 90\t Loss: 0.116870\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 91\t Loss: 0.122098\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 92\t Loss: 0.131406\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 93\t Loss: 0.093423\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 94\t Loss: 0.090443\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 95\t Loss: 0.117888\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 96\t Loss: 0.115957\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 97\t Loss: 0.104751\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 98\t Loss: 0.101671\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n",
      "Train Epoch: 99\t Loss: 0.123670\n",
      "\n",
      "('current p_k value: ', (nan, nan), '\\n')\n",
      "('current best p_k: ', (nan, nan))\n",
      "-----------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown format code 'f' for object of type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e595ed08476d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'current best p_k: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_p_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Result: at {} epoch, achieved best acc: {:.0f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_p_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: Unknown format code 'f' for object of type 'str'"
     ]
    }
   ],
   "source": [
    "max_p_k = 0\n",
    "max_epoch = 0\n",
    "\n",
    "save_path = '/data/yaoms/model/densenet-169_0723.pth'\n",
    "for epoch in range(EPOCH):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    p_k = test(model, test_loader, DEVICE)\n",
    "    if p_k >= max_p_k:\n",
    "        max_p_k = p_k\n",
    "        max_epoch = epoch\n",
    "        if os.path.exists(save_path):\n",
    "            os.remove(save_path)\n",
    "        torch.save(model, save_path)\n",
    "    print('current best p_k: ', max_p_k)\n",
    "    print('-----------------------')\n",
    "print('Result: at {} epoch, achieved best acc: {:.0f}'.format(max_epoch, max_p_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
